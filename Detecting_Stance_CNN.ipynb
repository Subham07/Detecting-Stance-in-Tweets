{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting_Stance_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPg094n7lr4k",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q-Zj-rZUpv6",
        "colab_type": "code",
        "outputId": "5e2b7b82-7a72-4354-9156-97bb527f742a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Apr 22 09:57:27 2020\n",
        "\n",
        "@author: Subham\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding, Conv2D, MaxPool2D\n",
        "from keras.models import Model\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "\n",
        "import keras.regularizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJuYOVPkLr_U",
        "colab_type": "code",
        "outputId": "544731e9-68a0-4ad3-92f1-01eac0887af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJZ07lD0l1-F",
        "colab_type": "text"
      },
      "source": [
        "Importing Training and Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9MKepxyYlDi",
        "colab_type": "code",
        "outputId": "2f747838-f707-476d-d773-42c5f0c9eb2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_train=pd.read_csv('drive/My Drive/dataset_train.csv',encoding = \"ISO-8859-1\")\n",
        "data_train_target1=data_train[data_train[\"Target\"]==\"Atheism\"]\n",
        "data_train_target2=data_train[data_train[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "data_train_target3=data_train[data_train[\"Target\"]==\"Feminist Movement\"]\n",
        "data_train_target4=data_train[data_train[\"Target\"]==\"Hillary Clinton\"]\n",
        "data_train_target5=data_train[data_train[\"Target\"]==\"Legalization of Abortion\"]\n",
        "\n",
        "data_test=pd.read_csv('drive/My Drive/dataset_test.csv',encoding = \"ISO-8859-1\")\n",
        "data_test_target1=data_test[data_test[\"Target\"]==\"Atheism\"]\n",
        "data_test_target2=data_test[data_test[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "data_test_target3=data_test[data_test[\"Target\"]==\"Feminist Movement\"]\n",
        "data_test_target4=data_test[data_test[\"Target\"]==\"Hillary Clinton\"]\n",
        "data_test_target5=data_test[data_test[\"Target\"]==\"Legalization of Abortion\"]\n",
        "\n",
        "\n",
        "target1_test_len=len(data_test_target1)\n",
        "target2_test_len=len(data_test_target2)\n",
        "target3_test_len=len(data_test_target3)\n",
        "target4_test_len=len(data_test_target4)\n",
        "target5_test_len=len(data_test_target5)\n",
        "\n",
        "target1_train_len=len(data_train_target1)\n",
        "target2_train_len=len(data_train_target2)\n",
        "target3_train_len=len(data_train_target3)\n",
        "target4_train_len=len(data_train_target4)\n",
        "target5_train_len=len(data_train_target5)\n",
        "\n",
        "print(target4_train_len)\n",
        "print(target4_test_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "639\n",
            "295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmbGK3fmTmi",
        "colab_type": "text"
      },
      "source": [
        "Defining Functions for Pre-processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBsOk3mX8Zot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuations(docs): #list of strings\n",
        "    punctuations = '''!()[]{};:\"\\,<>'./?@#$%^&*_~-'''\n",
        "    docs2=[];\n",
        "    i=0;\n",
        "    for sent in docs:\n",
        "        s=\"\"\n",
        "        for x in sent:\n",
        "            if(x not in punctuations):\n",
        "                s=s+x;\n",
        "        docs2.append(s);\n",
        "\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def convert_lowercase(docs): #list of strings\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        sent=sent.lower()\n",
        "        docs2.append(sent);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_data(docs): #list of strings\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        sent=word_tokenize(sent)\n",
        "        docs2.append(sent);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "def remove_stopwords(docs): #list of list of words as param\n",
        "    stop_words=set(stopwords.words(\"english\"));\n",
        "\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        s=[];\n",
        "        for word in sent:\n",
        "            if(word not in stop_words):\n",
        "                s.append(word);\n",
        "        docs2.append(s);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def make_string(docs): #list of list of words as param\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        s=\"\"\n",
        "        s=' '.join(sent)\n",
        "        docs2.append(s);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def lemmatize(docs): #list of list of words as param\n",
        "    lemmatizer=WordNetLemmatizer();\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        s=[];\n",
        "        for word in sent:\n",
        "            s.append(lemmatizer.lemmatize(word));\n",
        "        docs2.append(s);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def remove_digits(docs): #list of strings\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        sent2=sent.split(' ');\n",
        "        words=[]\n",
        "        for x in sent2:\n",
        "            flag=0;\n",
        "            for c in x:\n",
        "                if(c>='0' and c<='9'):\n",
        "                    flag=1;\n",
        "                    break;\n",
        "                else:\n",
        "                    pass;\n",
        "            if(flag==0):\n",
        "                words.append(x);\n",
        "        words=' '.join(words);\n",
        "        docs2.append(words)\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Sj-rGLmhJs",
        "colab_type": "text"
      },
      "source": [
        "Pre-processing of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBWKlTcMZa3C",
        "colab_type": "code",
        "outputId": "eb813803-13c4-4d9d-864c-e6a5b81d3f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "target1_train_data=[]\n",
        "for i in range(0,target1_train_len):\n",
        "    target1_train_data.append(data_train_target1[\"Tweet\"][i])\n",
        "    \n",
        "\n",
        "print(len(target1_train_data))\n",
        "\n",
        "target1_train_data=convert_lowercase(target1_train_data)\n",
        "target1_train_data=remove_digits(target1_train_data)\n",
        "target1_train_data=remove_punctuations(target1_train_data)\n",
        "target1_train_data=tokenize_data(target1_train_data)\n",
        "target1_train_data=remove_stopwords(target1_train_data)\n",
        "target1_train_data=lemmatize(target1_train_data)\n",
        "target1_train_data=make_string(target1_train_data)\n",
        "\n",
        "\n",
        "data_test=pd.read_csv('drive/My Drive/dataset_test.csv',encoding = \"ISO-8859-1\")\n",
        "data_test.head()\n",
        "data_test_target1=data_test[data_test[\"Target\"]==\"Atheism\"]\n",
        "\n",
        "target1_test_len=len(data_test_target1)\n",
        "\n",
        "target1_test_data=[]\n",
        "for i in range(0,target1_test_len):\n",
        "    target1_test_data.append(data_test_target1[\"Tweet\"][i])\n",
        "    \n",
        "target1_test_data=convert_lowercase(target1_test_data)\n",
        "target1_test_data=remove_digits(target1_test_data)\n",
        "target1_test_data=remove_punctuations(target1_test_data)\n",
        "target1_test_data=tokenize_data(target1_test_data)\n",
        "target1_test_data=remove_stopwords(target1_test_data)\n",
        "target1_test_data=lemmatize(target1_test_data)\n",
        "target1_test_data=make_string(target1_test_data)\n",
        "\n",
        "\n",
        "y1=[]\n",
        "for i in range(0,target1_train_len):\n",
        "    y1.append(data_train_target1[\"Stance\"][i])\n",
        "    \n",
        "\n",
        "target1_full_data=[]\n",
        "target1_full_data.extend(target1_train_data)\n",
        "target1_full_data.extend(target1_test_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88wV_QClm1xE",
        "colab_type": "text"
      },
      "source": [
        "Loading Pre-Trained Word2Vec Model of dimension 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15Byb7mqS4Cf",
        "colab_type": "code",
        "outputId": "04cd13b7-81bc-4f96-91a4-cd68515f58a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format('./drive/My Drive/GoogleNews-vectors-negative300.bin', binary=True)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJw0uw5Tpsa",
        "colab_type": "code",
        "outputId": "f7232687-9f11-4d79-f66c-6e2aed57c39d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "len(word2vec.wv[\"stop\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRky9vronNia",
        "colab_type": "text"
      },
      "source": [
        "Creating Dictionary for mapping Words to indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVBmDgwYTy0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the words in the texts\n",
        "max_nb_words=2000\n",
        "tokenizer = Tokenizer(num_words = max_nb_words) \n",
        "tokenizer.fit_on_texts(target1_full_data) \n",
        "# convert each review text into a sequence of word-indices\n",
        "matrix_word_indices = tokenizer.texts_to_sequences(target1_full_data)\n",
        "# the dictionary for mapping a word to an index\n",
        "dictionary_word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUDbTkPMXJH1",
        "colab_type": "code",
        "outputId": "11e8357b-a0f1-44f0-bc1f-41333315687a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(dictionary_word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzMgjElPWCnR",
        "colab_type": "code",
        "outputId": "3e7ee0fe-2729-48ac-93c7-6c0f8044feb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(matrix_word_indices))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWON8-Ldncz4",
        "colab_type": "text"
      },
      "source": [
        "Padding sentences to a fixed length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8TLnuCGWOyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad each review text to a fixed length of word sequence\n",
        "num_words_per_review=20\n",
        "matrix_word_indices_fixed_length = pad_sequences(matrix_word_indices, maxlen = num_words_per_review)\n",
        "# convert to numpy arrays \n",
        "data = np.array(matrix_word_indices_fixed_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgTdwDawWc5p",
        "colab_type": "code",
        "outputId": "ed18db27-46c5-4d18-e50a-97bb3d6d0287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0 282   7 150   4 283 363 364  98   7  39 228 922 365  15 923 112\n",
            "  40   1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhYwTAXlYZZy",
        "colab_type": "code",
        "outputId": "43dc6b3e-992c-4e6d-cc83-8bb2f9a99619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(matrix_word_indices_fixed_length.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(733, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K84bG-HLWqUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# allocation of training data and validation data\n",
        "x_train = data[:len(data_train_target1)]\n",
        "x_test = data[len(data_train_target1):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVD1G1nhnyYA",
        "colab_type": "text"
      },
      "source": [
        "Creating One-hot encoding of Target, Against- 100, Favor- 010 , None- 001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax3W57Axdc1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=np.zeros(shape=(len(data_train_target1),3))\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  if(y1[i]=='AGAINST'):\n",
        "    y_train[i][0]=1;\n",
        "  elif(y1[i]=='FAVOR'):\n",
        "    y_train[i][1]=1;\n",
        "  else:\n",
        "    y_train[i][2]=1;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUe7J4wDoX2e",
        "colab_type": "text"
      },
      "source": [
        "Seperation of Training and Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AExs50xWW22Z",
        "colab_type": "code",
        "outputId": "803ac26a-adc6-4aa3-f0e1-2f1750b12fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(x_train))\n",
        "print(len(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "513\n",
            "220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7vsS7VJYMSJ",
        "colab_type": "code",
        "outputId": "4698d653-a804-464a-da49-2f0838925c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(513, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TD_4l-goliz",
        "colab_type": "text"
      },
      "source": [
        "Creating Word Embedding Matrix of dimension N X 300, N is the no. of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d46Qn4FMXCQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare embedding matrix\n",
        "num_words = len(dictionary_word_index)\n",
        "# embedding_matrix[0] is a all-zero vector representing no word\n",
        "embedding_matrix = np.zeros((num_words+1, 300)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2lql8ZHXsj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_vector=np.zeros(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xljJMHGXTSM",
        "colab_type": "code",
        "outputId": "49def462-7aa1-468a-8847-71599d479a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "unknown_words=[]\n",
        "for word, index in dictionary_word_index.items():\n",
        "    if index > max_nb_words:\n",
        "        continue \n",
        "    # get the glove vector for the word\n",
        "    try:\n",
        "      word_vector = model.wv[word]\n",
        "      if word_vector is not None: \n",
        "          embedding_matrix[index] = word_vector\n",
        "    except:\n",
        "      unknown_words.append(word)\n",
        "      embedding_matrix[index] = init_vector\n",
        "  \n",
        "print(\"The no. of unknown words: \", len(unknown_words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The no. of unknown words:  352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiZyqdSZX0pG",
        "colab_type": "code",
        "outputId": "7a16d447-13b1-45c0-f1c3-b18efd49d94d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embedding_matrix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfmbp-HTo31c",
        "colab_type": "text"
      },
      "source": [
        "Defining and Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpgJhloUdqiR",
        "colab_type": "code",
        "outputId": "22cc9aaf-2e34-4b59-b9b7-7dce28408196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define the model\n",
        "# layer 0: the input layer\n",
        "num_words_per_tweet=20\n",
        "sequence_input = Input(shape=(num_words_per_tweet,), dtype='int32')\n",
        "# layer-1: the embedding layer\n",
        "embedding_layer = Embedding(num_words+1, 300, weights=[embedding_matrix], input_length=num_words_per_tweet, trainable=True)\n",
        "embedded_output = embedding_layer(sequence_input)\n",
        "# layer-2: the first convolution layer\n",
        "x = Conv1D(nb_filter=128, filter_length=2, activation='relu')(embedded_output)\n",
        "# layer-3: the first pooling layer\n",
        "x = MaxPooling1D(pool_length=2)(x)\n",
        "# layer-4: the second convolution layer\n",
        "x = Conv1D(128, 2, activation='relu')(x)\n",
        "# layer-5: the second pooling layer\n",
        "x = MaxPooling1D(pool_length = 2)(x)\n",
        "# flatten layer\n",
        "x = Flatten()(x)\n",
        "# layer-6: the first dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-7: the second dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-8: the output layer\n",
        "final_output = Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "# define the model\n",
        "model = Model(input=sequence_input, output=final_output)\n",
        "\n",
        "#view model\n",
        "print(model.summary())\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
        "# training and validation\n",
        "print('Training the model ...')\n",
        "model.fit(x=x_train, y=y_train, nb_epoch=15, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 20, 300)           867900    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 19, 128)           76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 8, 128)            32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,060,287\n",
            "Trainable params: 1,060,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "513/513 [==============================] - 1s 1ms/step - loss: 1.0341 - acc: 0.5010\n",
            "Epoch 2/15\n",
            "513/513 [==============================] - 0s 445us/step - loss: 1.2105 - acc: 0.5926\n",
            "Epoch 3/15\n",
            "513/513 [==============================] - 0s 459us/step - loss: 0.8099 - acc: 0.6745\n",
            "Epoch 4/15\n",
            "513/513 [==============================] - 0s 472us/step - loss: 0.6174 - acc: 0.7563\n",
            "Epoch 5/15\n",
            "513/513 [==============================] - 0s 471us/step - loss: 0.4738 - acc: 0.7778\n",
            "Epoch 6/15\n",
            "513/513 [==============================] - 0s 500us/step - loss: 0.7012 - acc: 0.7251\n",
            "Epoch 7/15\n",
            "513/513 [==============================] - 0s 450us/step - loss: 0.3257 - acc: 0.8187\n",
            "Epoch 8/15\n",
            "513/513 [==============================] - 0s 442us/step - loss: 0.2479 - acc: 0.8246\n",
            "Epoch 9/15\n",
            "513/513 [==============================] - 0s 457us/step - loss: 0.1796 - acc: 0.8772\n",
            "Epoch 10/15\n",
            "513/513 [==============================] - 0s 480us/step - loss: 0.0796 - acc: 0.9883\n",
            "Epoch 11/15\n",
            "513/513 [==============================] - 0s 479us/step - loss: 0.0263 - acc: 0.9961\n",
            "Epoch 12/15\n",
            "513/513 [==============================] - 0s 474us/step - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 13/15\n",
            "513/513 [==============================] - 0s 476us/step - loss: 0.0051 - acc: 1.0000\n",
            "Epoch 14/15\n",
            "513/513 [==============================] - 0s 470us/step - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 15/15\n",
            "513/513 [==============================] - 0s 437us/step - loss: 0.0026 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fbb4b997dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O2yGVgVpcl-",
        "colab_type": "text"
      },
      "source": [
        "Storing the Ground Truth value for final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xlvUAD3wtJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test_answers=pd.read_csv('drive/My Drive/dataset_test_answers.csv')\n",
        "data_test_target1_answers=data_test_answers[data_test_answers[\"Target\"]==\"Atheism\"]\n",
        "y_ground_truth=data_test_target1_answers[\"Stance\"].values;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FarUgcEk0iOf",
        "colab_type": "code",
        "outputId": "29201de2-3d6d-4c04-ee43-d92ecf2ce8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "print(y_ground_truth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'FAVOR' 'NONE' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'FAVOR' 'AGAINST' 'AGAINST' 'AGAINST' 'FAVOR'\n",
            " 'AGAINST' 'AGAINST' 'NONE' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'NONE'\n",
            " 'NONE' 'AGAINST' 'NONE' 'NONE' 'NONE' 'NONE' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'FAVOR' 'NONE' 'NONE' 'NONE' 'AGAINST' 'FAVOR' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'NONE' 'AGAINST'\n",
            " 'AGAINST' 'NONE' 'AGAINST' 'FAVOR' 'AGAINST' 'FAVOR' 'FAVOR' 'FAVOR'\n",
            " 'AGAINST' 'AGAINST' 'FAVOR' 'NONE' 'AGAINST' 'AGAINST' 'NONE' 'FAVOR'\n",
            " 'AGAINST' 'AGAINST' 'NONE' 'FAVOR' 'AGAINST' 'AGAINST' 'FAVOR' 'AGAINST'\n",
            " 'FAVOR' 'FAVOR' 'AGAINST' 'AGAINST' 'FAVOR' 'FAVOR' 'FAVOR' 'AGAINST'\n",
            " 'FAVOR' 'AGAINST' 'FAVOR' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'NONE'\n",
            " 'AGAINST' 'NONE' 'FAVOR' 'NONE' 'AGAINST' 'NONE' 'AGAINST' 'FAVOR'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'NONE' 'FAVOR' 'FAVOR'\n",
            " 'FAVOR' 'NONE' 'AGAINST' 'NONE' 'NONE' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST'\n",
            " 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'AGAINST' 'FAVOR' 'NONE' 'FAVOR'\n",
            " 'AGAINST' 'FAVOR' 'AGAINST' 'FAVOR' 'FAVOR' 'NONE' 'AGAINST' 'AGAINST'\n",
            " 'NONE' 'AGAINST' 'AGAINST' 'AGAINST' 'NONE' 'AGAINST' 'AGAINST' 'FAVOR'\n",
            " 'AGAINST' 'FAVOR' 'AGAINST']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQD1HsklpwQy",
        "colab_type": "text"
      },
      "source": [
        "Mapping targets to indices, Against - 0, Favor - 1, None -2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8aU0FatxJmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=np.zeros(len(data_test_target1))\n",
        "\n",
        "for i in range(len(y_ground_truth)):\n",
        "  if(y_ground_truth[i]=='AGAINST'):\n",
        "    y_test[i]=0;\n",
        "  elif(y_ground_truth[i]=='FAVOR'):\n",
        "    y_test[i]=1;\n",
        "  else:\n",
        "    y_test[i]=2;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrQ3lYYpp3-x",
        "colab_type": "text"
      },
      "source": [
        "Prediction of Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhJ6E-EQy26x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou9P4UHXz-qz",
        "colab_type": "code",
        "outputId": "54e66607-df2a-48d6-83ec-31a5d0a2f93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.10786152e-01 1.60637796e-02 2.02181041e-02]\n",
            " [2.90657133e-01 4.93154330e-05 1.38823384e-06]\n",
            " [6.96861863e-01 2.33717983e-05 4.19936578e-06]\n",
            " [1.75553858e-01 1.49313509e-02 2.73184087e-05]\n",
            " [1.28371358e-01 2.45370567e-02 3.55809927e-04]\n",
            " [2.02653110e-02 2.80261040e-04 1.77979469e-03]\n",
            " [4.33236361e-03 3.25621188e-01 2.01311707e-03]\n",
            " [3.58386278e-01 2.19821930e-04 3.87542605e-05]\n",
            " [1.46240592e-02 1.15836859e-02 2.86225021e-01]\n",
            " [6.66997731e-02 1.11630950e-04 7.57686469e-10]\n",
            " [3.17097008e-01 3.49792838e-03 1.22957528e-02]\n",
            " [4.40665317e-05 5.77410901e-05 3.83785099e-01]\n",
            " [3.68267745e-01 3.17305326e-04 1.27106905e-04]\n",
            " [9.84281301e-04 5.99261820e-02 5.54996729e-03]\n",
            " [7.45049119e-03 5.71787357e-03 1.22929432e-05]\n",
            " [6.97539330e-01 1.11922622e-03 1.24543905e-04]\n",
            " [9.40428019e-01 1.00303043e-06 1.04864206e-09]\n",
            " [8.69690776e-02 1.03363395e-03 5.04293052e-10]\n",
            " [9.08427477e-01 1.83969736e-04 1.81388987e-05]\n",
            " [4.09312010e-01 8.08417899e-05 7.34684290e-05]\n",
            " [7.61620700e-01 1.57013535e-03 6.91860914e-04]\n",
            " [3.02468449e-01 1.63279176e-02 3.59999537e-02]\n",
            " [7.87943602e-04 2.56419182e-04 1.93336517e-01]\n",
            " [4.22305882e-01 3.78632545e-03 1.40814781e-02]\n",
            " [1.70874596e-03 8.10879469e-03 3.27387452e-03]\n",
            " [9.54625010e-01 3.03733468e-05 3.75444210e-06]\n",
            " [1.42237544e-03 5.95623255e-03 1.35660768e-01]\n",
            " [8.81221175e-01 2.68249823e-06 3.57307925e-08]\n",
            " [3.31312418e-04 6.60268664e-02 7.10088352e-06]\n",
            " [5.81803024e-02 1.25825405e-04 1.70379162e-11]\n",
            " [1.04410142e-01 5.34772873e-04 3.72476134e-05]\n",
            " [4.90969419e-03 1.22413039e-03 2.82106754e-07]\n",
            " [7.49334514e-01 1.41610253e-05 1.42265662e-07]\n",
            " [2.67426670e-01 5.11306534e-05 3.69053743e-09]\n",
            " [6.65041804e-03 6.52683079e-02 1.53032839e-02]\n",
            " [7.14391470e-04 5.68428338e-02 4.01210785e-03]\n",
            " [1.61184013e-01 3.00902128e-02 3.07500362e-04]\n",
            " [9.23078656e-02 1.29312277e-04 2.36147642e-03]\n",
            " [8.13882828e-01 1.36412327e-05 6.44793374e-08]\n",
            " [9.23056901e-01 2.85147835e-05 2.81010557e-06]\n",
            " [4.06693459e-01 1.88767910e-04 4.95374422e-07]\n",
            " [3.91149759e-01 8.69452953e-03 2.16518641e-02]\n",
            " [2.74941325e-03 7.02878833e-02 3.05092708e-05]\n",
            " [7.27069259e-01 5.56975603e-04 6.26275869e-05]\n",
            " [1.17588460e-01 2.32613087e-03 4.16780267e-06]\n",
            " [2.29145444e-05 4.15861607e-04 1.17116302e-01]\n",
            " [1.81633234e-03 3.70720029e-03 2.90640026e-01]\n",
            " [2.87174791e-01 7.72893429e-04 1.88738108e-04]\n",
            " [7.11542368e-03 7.58413970e-02 2.86752880e-02]\n",
            " [8.35868716e-02 4.68572378e-02 1.50948763e-04]\n",
            " [1.84086330e-05 1.57716274e-02 2.90930271e-04]\n",
            " [6.71803951e-04 3.55324149e-03 2.17755735e-02]\n",
            " [4.54306602e-04 2.54571140e-02 2.17193365e-03]\n",
            " [2.61032581e-03 2.47479081e-02 5.98375627e-05]\n",
            " [3.83234024e-03 9.57944867e-05 5.61743975e-04]\n",
            " [3.17276716e-02 1.16378397e-01 1.53183937e-04]\n",
            " [4.30258214e-02 5.53274155e-03 7.52702726e-06]\n",
            " [5.32686591e-01 2.23374367e-03 3.28087807e-03]\n",
            " [1.95767492e-01 7.78913498e-04 9.17711816e-07]\n",
            " [2.66548634e-01 3.70949507e-04 1.76399946e-04]\n",
            " [9.65228379e-02 1.10411346e-02 1.12472117e-01]\n",
            " [9.82884467e-01 6.27989039e-08 3.63371746e-12]\n",
            " [3.09705734e-04 8.58676434e-03 7.06053376e-02]\n",
            " [7.32153058e-01 4.54328256e-06 3.24115207e-10]\n",
            " [1.28530860e-01 9.26911831e-04 5.15639782e-04]\n",
            " [8.93940985e-01 7.66711892e-05 3.17359991e-05]\n",
            " [1.49515271e-03 7.49945641e-04 9.90489125e-03]\n",
            " [3.66547108e-02 8.72761011e-04 2.43851542e-03]\n",
            " [3.31922770e-02 2.63655186e-03 5.99466002e-05]\n",
            " [9.06711340e-01 4.19658727e-06 7.56427720e-09]\n",
            " [9.50040936e-01 1.50271808e-05 1.96923565e-06]\n",
            " [1.05431676e-03 2.32953399e-01 7.79777765e-04]\n",
            " [6.37333453e-01 5.28752804e-04 4.77880239e-04]\n",
            " [3.47742736e-02 1.94901824e-02 3.75414491e-01]\n",
            " [6.62147403e-01 4.18865675e-05 3.82691297e-07]\n",
            " [7.48073280e-01 2.67590494e-05 5.72864451e-07]\n",
            " [1.78362221e-01 3.13758850e-04 1.43986171e-07]\n",
            " [7.31301367e-01 8.04368174e-05 3.20321633e-05]\n",
            " [3.23736131e-01 1.43900514e-03 3.97503376e-04]\n",
            " [5.40733337e-04 3.91143560e-03 8.31009529e-05]\n",
            " [8.84860754e-04 5.59270382e-04 1.69354677e-03]\n",
            " [8.83928120e-01 1.49604039e-05 1.10791326e-07]\n",
            " [7.53156424e-01 2.31998929e-05 1.58572891e-06]\n",
            " [2.58418918e-02 1.41276121e-02 1.78518206e-01]\n",
            " [1.15915298e-01 8.38190317e-04 1.91599131e-03]\n",
            " [1.37247413e-01 9.57471784e-05 4.78045123e-08]\n",
            " [6.73872650e-01 6.19444327e-05 1.75088644e-04]\n",
            " [3.39826345e-02 7.83331394e-02 9.08136368e-04]\n",
            " [2.41569191e-01 2.05921829e-02 9.39252973e-03]\n",
            " [3.30497265e-01 2.95844674e-03 1.81072950e-03]\n",
            " [3.86531770e-01 1.12442016e-04 2.05851375e-05]\n",
            " [4.35879827e-03 6.96504116e-03 3.95640135e-02]\n",
            " [4.47183847e-03 1.05601549e-03 1.51199192e-01]\n",
            " [5.08532166e-01 9.39339399e-04 3.39486396e-05]\n",
            " [1.70004874e-01 1.78098679e-04 8.75443220e-04]\n",
            " [7.38127530e-02 8.92877579e-04 1.29193068e-03]\n",
            " [4.18618023e-02 3.24507952e-02 3.07121754e-01]\n",
            " [9.24658775e-03 1.92487240e-03 8.69005919e-04]\n",
            " [7.18134046e-02 5.17427921e-04 3.17645073e-03]\n",
            " [4.43247825e-01 1.12441182e-03 1.09097033e-04]\n",
            " [3.69668007e-04 3.31076384e-02 6.98109798e-05]\n",
            " [5.90607762e-01 5.34415245e-04 5.71601668e-05]\n",
            " [6.06358051e-04 3.15636396e-04 1.55901819e-01]\n",
            " [5.75785875e-01 3.82840633e-04 2.35676765e-04]\n",
            " [1.32000446e-03 2.25940347e-03 1.56492501e-01]\n",
            " [7.13508666e-01 1.94817781e-04 7.37117080e-06]\n",
            " [2.47544050e-03 1.83809817e-01 1.19000673e-03]\n",
            " [1.27985209e-01 5.36191463e-03 2.57793436e-05]\n",
            " [8.14221144e-01 3.21656466e-04 3.17004560e-05]\n",
            " [9.41787779e-01 2.83946235e-07 5.42281664e-10]\n",
            " [5.54143012e-01 1.30192866e-05 9.40247810e-06]\n",
            " [8.94499660e-01 2.21619957e-05 2.36517963e-06]\n",
            " [9.81372714e-01 5.88140132e-08 2.89069074e-10]\n",
            " [7.11382627e-02 1.91204250e-02 4.46514189e-02]\n",
            " [6.01328671e-01 3.79835619e-05 7.40717283e-08]\n",
            " [9.05894041e-01 3.19146602e-06 6.34128838e-08]\n",
            " [2.31027961e-01 1.94646120e-02 7.40205944e-02]\n",
            " [6.18809462e-01 1.12784983e-05 1.94758286e-07]\n",
            " [1.94877386e-04 8.88462961e-02 2.65419483e-04]\n",
            " [2.20421255e-02 1.22225285e-03 1.03066192e-07]\n",
            " [1.20403725e-04 5.81729412e-03 2.63675153e-02]\n",
            " [5.67569911e-01 2.59548426e-04 2.80857086e-04]\n",
            " [1.81911290e-01 7.13795424e-04 3.60954942e-07]\n",
            " [7.67170906e-01 1.67105827e-06 1.36733099e-11]\n",
            " [9.43015218e-01 2.16623266e-05 4.21783852e-07]\n",
            " [4.92522120e-03 2.42360532e-02 3.81877944e-05]\n",
            " [5.22172451e-03 8.31374526e-03 2.28180945e-01]\n",
            " [1.20942384e-01 1.90299749e-03 1.01328194e-02]\n",
            " [1.52215958e-02 6.29028380e-02 9.05928318e-05]\n",
            " [3.46468842e-05 4.68522310e-04 8.78255963e-02]\n",
            " [3.91283631e-03 1.28387868e-01 1.49298030e-05]\n",
            " [5.69690168e-02 3.83671522e-02 5.50895929e-04]\n",
            " [6.89840198e-01 5.46552656e-06 1.02086389e-07]\n",
            " [1.50648564e-01 5.35410643e-03 4.41503525e-03]\n",
            " [5.39065003e-02 5.66303730e-04 2.27199326e-08]\n",
            " [9.43593979e-02 3.87299061e-03 2.49501169e-02]\n",
            " [1.68370932e-01 2.60651112e-04 6.31738217e-09]\n",
            " [6.61760569e-04 1.94108486e-03 1.12620592e-02]\n",
            " [6.39597416e-01 8.03049772e-07 6.13808310e-11]\n",
            " [5.18043637e-02 1.58497691e-02 2.00872000e-05]\n",
            " [7.13613093e-01 4.37110662e-04 1.33574009e-04]\n",
            " [7.70640373e-01 1.29474720e-05 1.30375319e-08]\n",
            " [1.48825943e-02 6.08147681e-02 2.70744363e-06]\n",
            " [1.87513232e-03 7.29499161e-02 7.49254227e-03]\n",
            " [1.30087435e-02 1.97653174e-02 7.72893327e-05]\n",
            " [1.30194426e-03 3.24521959e-02 3.41025591e-02]\n",
            " [3.58662367e-01 2.11477280e-04 2.82412955e-08]\n",
            " [2.51710713e-02 4.01894748e-02 7.50780106e-04]\n",
            " [3.61787707e-01 1.28450990e-03 7.40230083e-04]\n",
            " [1.17811054e-01 9.13780928e-03 1.50498748e-03]\n",
            " [8.10921192e-04 5.38227177e-05 4.29004431e-04]\n",
            " [8.73989999e-01 1.39240785e-06 8.86926266e-09]\n",
            " [6.97037458e-01 1.75834305e-06 4.05115985e-09]\n",
            " [2.87532896e-01 6.66996639e-05 9.90925582e-06]\n",
            " [2.08933949e-02 1.35981739e-02 3.04385900e-01]\n",
            " [7.42065907e-03 6.86025620e-03 4.16845083e-04]\n",
            " [9.93925333e-03 5.76436520e-03 1.94272697e-02]\n",
            " [6.10351562e-04 1.28282011e-02 5.52029610e-02]\n",
            " [3.14295292e-04 7.51078129e-04 2.46239305e-01]\n",
            " [9.30624187e-01 3.08358767e-06 6.28226289e-08]\n",
            " [3.45781446e-03 3.96254659e-03 5.16295433e-04]\n",
            " [9.34503913e-01 5.28968883e-07 3.14963361e-10]\n",
            " [8.87423754e-04 1.33216083e-01 8.40546272e-05]\n",
            " [3.88551325e-01 1.47819519e-04 5.70723046e-07]\n",
            " [4.65360284e-02 7.22242892e-02 3.15895975e-02]\n",
            " [9.73199666e-01 4.62292693e-09 2.60834038e-14]\n",
            " [6.29322708e-01 6.81772235e-07 3.99479720e-11]\n",
            " [7.44545460e-02 7.32620974e-05 4.44558391e-05]\n",
            " [1.53748691e-02 1.95617974e-02 4.20921743e-02]\n",
            " [1.01578236e-03 5.83702028e-02 1.97035074e-03]\n",
            " [1.17248446e-01 1.34736300e-04 3.31779738e-05]\n",
            " [8.17248344e-01 2.19166279e-04 4.07127118e-06]\n",
            " [1.28178199e-05 9.77056625e-05 2.50682235e-01]\n",
            " [1.01165622e-01 1.28173530e-02 3.91410504e-06]\n",
            " [1.51856542e-02 2.70131826e-02 9.54641104e-02]\n",
            " [2.21595168e-03 1.80196762e-03 2.49946415e-02]\n",
            " [6.88705981e-01 6.25000530e-06 1.83061104e-07]\n",
            " [5.40933549e-01 7.11410466e-05 1.62981735e-08]\n",
            " [1.60753161e-01 2.56679058e-02 3.63524556e-02]\n",
            " [1.95831060e-04 1.25712156e-03 3.53364944e-02]\n",
            " [8.59856129e-01 2.17109919e-04 1.16515133e-04]\n",
            " [3.50585580e-03 8.30680132e-04 7.56696172e-05]\n",
            " [1.30820870e-02 1.12968683e-02 2.80755685e-05]\n",
            " [3.64840031e-03 1.56518817e-02 2.63959290e-08]\n",
            " [7.44837284e-01 2.38705138e-06 4.74658424e-10]\n",
            " [1.22176111e-02 8.55684280e-04 1.09404624e-02]\n",
            " [4.95170534e-01 4.30199504e-03 2.38639116e-03]\n",
            " [1.01185977e-01 9.11623240e-04 2.13543139e-08]\n",
            " [5.64051390e-01 2.84272432e-03 1.08047119e-04]\n",
            " [7.34301805e-01 5.46425581e-04 1.57803297e-04]\n",
            " [1.78294361e-01 1.62518024e-03 1.61389410e-02]\n",
            " [7.19768763e-01 1.90881165e-05 1.56243502e-07]\n",
            " [3.86762410e-01 1.97728550e-05 6.20161256e-09]\n",
            " [2.08240062e-01 1.02138519e-03 4.89610613e-07]\n",
            " [8.88581514e-01 1.04060819e-04 1.86712714e-06]\n",
            " [6.33704543e-01 3.42151523e-03 3.01837921e-04]\n",
            " [5.21438122e-02 2.14245915e-02 6.23464584e-04]\n",
            " [9.19714570e-01 1.44711521e-05 9.15319561e-07]\n",
            " [1.40130460e-05 5.17243147e-03 2.91299820e-03]\n",
            " [9.75203514e-03 1.85430050e-04 7.06556439e-03]\n",
            " [1.99394822e-02 1.41974479e-01 5.43856621e-03]\n",
            " [8.01817358e-01 5.61833382e-04 7.59400646e-05]\n",
            " [5.90112805e-03 3.52072716e-03 4.08495180e-05]\n",
            " [7.20629156e-01 1.53397814e-05 1.45713869e-07]\n",
            " [2.70450413e-02 2.74398923e-03 2.03085673e-08]\n",
            " [1.36435032e-02 2.88193822e-02 1.16261731e-06]\n",
            " [1.80122942e-01 1.86591148e-02 4.61067259e-02]\n",
            " [3.18793595e-01 3.56775522e-03 1.67801976e-03]\n",
            " [2.39142776e-02 2.27817893e-03 4.02774569e-09]\n",
            " [6.32035732e-03 8.10521841e-03 2.24599570e-01]\n",
            " [9.08193231e-01 2.54905940e-11 1.54605753e-13]\n",
            " [8.53527427e-01 4.08828259e-04 2.29388475e-04]\n",
            " [8.38723183e-02 1.80110335e-03 5.49436606e-07]\n",
            " [2.16770679e-01 6.82860613e-04 4.49649679e-06]\n",
            " [2.30136216e-02 1.13156438e-03 1.62255764e-03]\n",
            " [2.85173059e-02 1.66755915e-03 2.93050061e-06]\n",
            " [1.75684243e-01 2.54738331e-03 1.54680014e-03]\n",
            " [9.85820293e-01 3.75083822e-08 1.72459564e-11]\n",
            " [3.64651084e-01 6.54691458e-03 2.45666178e-03]\n",
            " [4.80780721e-01 5.95458143e-04 1.19696073e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqt3UwMbzEbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=np.zeros(len(y_pred))\n",
        "for i in range(len(y_pred)):\n",
        "  y[i]=np.argmax(y_pred[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSt33U3J0c4_",
        "colab_type": "code",
        "outputId": "cbefe8fe-23b3-416f-c6ca-868d4a0aea4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(y_test)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 0. 2. 2. 0. 2. 2.\n",
            " 2. 2. 0. 0. 0. 1. 2. 2. 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 1. 0.\n",
            " 1. 1. 1. 0. 0. 1. 2. 0. 0. 2. 1. 0. 0. 2. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 2. 0. 2. 1. 2. 0. 2. 0. 1. 0. 0. 0. 0. 0.\n",
            " 2. 1. 1. 1. 2. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 2. 1. 0. 1. 0. 1. 1. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0.\n",
            " 1. 0. 1. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n",
            " 1. 0. 2. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 0.\n",
            " 1. 0. 1. 2. 1. 1. 0. 1. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 1.\n",
            " 0. 2. 0. 0. 0. 0. 0. 1. 2. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 2. 2. 0. 0. 0.\n",
            " 2. 0. 0. 0. 1. 0. 2. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 2. 0. 0. 0. 0. 1. 2. 0. 1. 2. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 1.\n",
            " 1. 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 2. 2. 2. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
            " 2. 1. 0. 0. 2. 0. 2. 2. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Dyr4erp924",
        "colab_type": "text"
      },
      "source": [
        "Finding F1_Score , Precision_score, Recall_score, Accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFhklikVz6nX",
        "colab_type": "code",
        "outputId": "9718f118-4735-493b-e142-4a87aff6ad44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "print(f1_score(y,y_test,average='macro'))\n",
        "print(precision_score(y,y_test,average='macro'))\n",
        "print(recall_score(y,y_test,average='macro'))\n",
        "print(accuracy_score(y,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5814095201377232\n",
            "0.5931547619047618\n",
            "0.5721500721500722\n",
            "0.7181818181818181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qpTfl3NqMVf",
        "colab_type": "text"
      },
      "source": [
        "Repeating Training and Testing for other 4 Targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNMUkZGNOsPk",
        "colab_type": "code",
        "outputId": "85edb169-747e-4c2d-c17e-259902078e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#2nd model\n",
        "\n",
        "\n",
        "\n",
        "# define the model\n",
        "# layer 0: the input layer\n",
        "num_words_per_tweet=20\n",
        "sequence_input = Input(shape=(num_words_per_tweet,), dtype='int32')\n",
        "# layer-1: the embedding layer\n",
        "embedding_layer = Embedding(num_words+1, 300, weights=[embedding_matrix], input_length=num_words_per_tweet, trainable=True)\n",
        "embedded_output = embedding_layer(sequence_input)\n",
        "# layer-2: the first convolution layer\n",
        "x = Conv1D(nb_filter=128, filter_length=2, activation='relu')(embedded_output)\n",
        "# layer-3: the first pooling layer\n",
        "x = MaxPooling1D(pool_length=2)(x)\n",
        "# layer-4: the second convolution layer\n",
        "x = Conv1D(128, 2, activation='relu')(x)\n",
        "# layer-5: the second pooling layer\n",
        "x = MaxPooling1D(pool_length = 2)(x)\n",
        "# flatten layer\n",
        "x = Flatten()(x)\n",
        "# layer-6: the first dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-7: the second dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-8: the output layer\n",
        "final_output = Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "# define the model\n",
        "model = Model(input=sequence_input, output=final_output)\n",
        "\n",
        "#view model\n",
        "print(model.summary())\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
        "# training and validation\n",
        "print('Training the model ...')\n",
        "model.fit(x=x_train, y=y_train, nb_epoch=15, batch_size=128, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred=model.predict(x_test)\n",
        "\n",
        "y=np.zeros(len(y_pred))\n",
        "for i in range(len(y_pred)):\n",
        "  y[i]=np.argmax(y_pred[i])\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "print(f1_score(y,y_test,average='macro'))\n",
        "print(precision_score(y,y_test,average='macro'))\n",
        "print(recall_score(y,y_test,average='macro'))\n",
        "print(accuracy_score(y,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 20, 300)           867900    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 19, 128)           76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 8, 128)            32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,060,287\n",
            "Trainable params: 1,060,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "513/513 [==============================] - 0s 704us/step - loss: 1.0824 - acc: 0.6043\n",
            "Epoch 2/15\n",
            "513/513 [==============================] - 0s 429us/step - loss: 0.9360 - acc: 0.5926\n",
            "Epoch 3/15\n",
            "513/513 [==============================] - 0s 447us/step - loss: 0.7729 - acc: 0.6179\n",
            "Epoch 4/15\n",
            "513/513 [==============================] - 0s 478us/step - loss: 0.5540 - acc: 0.8031\n",
            "Epoch 5/15\n",
            "513/513 [==============================] - 0s 484us/step - loss: 0.4173 - acc: 0.8012\n",
            "Epoch 6/15\n",
            "513/513 [==============================] - 0s 448us/step - loss: 0.2124 - acc: 0.8538\n",
            "Epoch 7/15\n",
            "513/513 [==============================] - 0s 431us/step - loss: 0.0825 - acc: 0.9766\n",
            "Epoch 8/15\n",
            "513/513 [==============================] - 0s 403us/step - loss: 0.6135 - acc: 0.7758\n",
            "Epoch 9/15\n",
            "513/513 [==============================] - 0s 471us/step - loss: 0.1169 - acc: 0.9864\n",
            "Epoch 10/15\n",
            "513/513 [==============================] - 0s 436us/step - loss: 0.0376 - acc: 0.9981\n",
            "Epoch 11/15\n",
            "513/513 [==============================] - 0s 465us/step - loss: 0.0109 - acc: 1.0000\n",
            "Epoch 12/15\n",
            "513/513 [==============================] - 0s 461us/step - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 13/15\n",
            "513/513 [==============================] - 0s 428us/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 14/15\n",
            "513/513 [==============================] - 0s 452us/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 15/15\n",
            "513/513 [==============================] - 0s 462us/step - loss: 0.0015 - acc: 1.0000\n",
            "0.5730333969312016\n",
            "0.5931547619047618\n",
            "0.561860049905352\n",
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcDwOWqfArc5",
        "colab_type": "code",
        "outputId": "4fb3d416-db10-40ba-89c1-6058e9006f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# for Target 2\n",
        "\n",
        "data_train=pd.read_csv('drive/My Drive/dataset_train.csv',encoding = \"ISO-8859-1\")\n",
        "data_train_target2=data_train[data_train[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "\n",
        "\n",
        "target2_train_len=len(data_train_target2)\n",
        "\n",
        "\n",
        "target2_train_data=[]\n",
        "for i in range(target1_train_len,target1_train_len+target2_train_len):\n",
        "    target2_train_data.append(data_train_target2[\"Tweet\"][i])\n",
        "    \n",
        "    \n",
        "print(len(target2_train_data))\n",
        "\n",
        "target2_train_data=convert_lowercase(target2_train_data)\n",
        "target2_train_data=remove_digits(target2_train_data)\n",
        "target2_train_data=remove_punctuations(target2_train_data)\n",
        "target2_train_data=tokenize_data(target2_train_data)\n",
        "target2_train_data=remove_stopwords(target2_train_data)\n",
        "target2_train_data=lemmatize(target2_train_data)\n",
        "target2_train_data=make_string(target2_train_data)\n",
        "\n",
        "\n",
        "data_test=pd.read_csv('drive/My Drive/dataset_test.csv',encoding = \"ISO-8859-1\")\n",
        "data_test.head()\n",
        "data_test_target2=data_test[data_test[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "\n",
        "target2_test_len=len(data_test_target2)\n",
        "\n",
        "target2_test_data=[]\n",
        "for i in range(target1_test_len,target1_test_len+target2_test_len):\n",
        "    target2_test_data.append(data_test_target2[\"Tweet\"][i])\n",
        "    \n",
        "target2_test_data=convert_lowercase(target2_test_data)\n",
        "target2_test_data=remove_digits(target2_test_data)\n",
        "target2_test_data=remove_punctuations(target2_test_data)\n",
        "target2_test_data=tokenize_data(target2_test_data)\n",
        "target2_test_data=remove_stopwords(target2_test_data)\n",
        "target2_test_data=lemmatize(target2_test_data)\n",
        "target2_test_data=make_string(target2_test_data)\n",
        "\n",
        "\n",
        "y1=[]\n",
        "for i in range(target1_train_len,target1_train_len+target2_train_len):\n",
        "    y1.append(data_train_target2[\"Stance\"][i])\n",
        "    \n",
        "\n",
        "target2_full_data=[]\n",
        "target2_full_data.extend(target2_train_data)\n",
        "target2_full_data.extend(target2_test_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70PLrzSAB5Lw",
        "colab_type": "code",
        "outputId": "e439b085-9f6d-443f-fa53-49c4f0db5d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tokenize the words in the texts\n",
        "max_nb_words=2000\n",
        "tokenizer = Tokenizer(num_words = max_nb_words) \n",
        "tokenizer.fit_on_texts(target2_full_data) \n",
        "# convert each review text into a sequence of word-indices\n",
        "matrix_word_indices = tokenizer.texts_to_sequences(target2_full_data)\n",
        "# the dictionary for mapping a word to an index\n",
        "dictionary_word_index = tokenizer.word_index\n",
        "\n",
        "print(len(dictionary_word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17FS2edoCZKk",
        "colab_type": "code",
        "outputId": "41ceaccb-d064-4031-a5f3-f1143b8350a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# pad each review text to a fixed length of word sequence\n",
        "num_words_per_review=20\n",
        "matrix_word_indices_fixed_length = pad_sequences(matrix_word_indices, maxlen = num_words_per_review)\n",
        "# convert to numpy arrays \n",
        "data = np.array(matrix_word_indices_fixed_length)\n",
        "\n",
        "print(matrix_word_indices_fixed_length.shape)\n",
        "\n",
        "# allocation of training data and validation data\n",
        "x_train = data[:len(data_train_target2)]\n",
        "x_test = data[len(data_train_target2):]\n",
        "\n",
        "y_train=np.zeros(shape=(len(data_train_target2),3))\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  if(y1[i]=='AGAINST'):\n",
        "    y_train[i][0]=1;\n",
        "  elif(y1[i]=='FAVOR'):\n",
        "    y_train[i][1]=1;\n",
        "  else:\n",
        "    y_train[i][2]=1;\n",
        "\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "\n",
        "\n",
        "# prepare embedding matrix\n",
        "num_words = len(dictionary_word_index)\n",
        "# embedding_matrix[0] is a all-zero vector representing no word\n",
        "embedding_matrix = np.zeros((num_words+1, 300)) \n",
        "\n",
        "init_vector=np.zeros(300)\n",
        "\n",
        "\n",
        "unknown_words=[]\n",
        "for word, index in dictionary_word_index.items():\n",
        "    if index > max_nb_words:\n",
        "        continue \n",
        "    # get the glove vector for the word\n",
        "    try:\n",
        "      word_vector = word2vec.wv[word]\n",
        "      if word_vector is not None: \n",
        "          embedding_matrix[index] = word_vector\n",
        "    except:\n",
        "      unknown_words.append(word)\n",
        "      #print(word)\n",
        "      embedding_matrix[index] = init_vector\n",
        "  \n",
        "print(\"The no. of unknown words: \", len(unknown_words))\n",
        "\n",
        "print(len(embedding_matrix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(564, 20)\n",
            "395\n",
            "169\n",
            "The no. of unknown words:  416\n",
            "2682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bA6VqqtD0tW",
        "colab_type": "code",
        "outputId": "3691db42-6ebb-4114-e4e6-494866618bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define the model\n",
        "# layer 0: the input layer\n",
        "num_words_per_tweet=20\n",
        "sequence_input = Input(shape=(num_words_per_tweet,), dtype='int32')\n",
        "# layer-1: the embedding layer\n",
        "embedding_layer = Embedding(num_words+1, 300, weights=[embedding_matrix], input_length=num_words_per_tweet, trainable=True)\n",
        "embedded_output = embedding_layer(sequence_input)\n",
        "# layer-2: the first convolution layer\n",
        "x = Conv1D(nb_filter=128, filter_length=2, activation='relu')(embedded_output)\n",
        "# layer-3: the first pooling layer\n",
        "x = MaxPooling1D(pool_length=2)(x)\n",
        "# layer-4: the second convolution layer\n",
        "x = Conv1D(128, 2, activation='relu')(x)\n",
        "# layer-5: the second pooling layer\n",
        "x = MaxPooling1D(pool_length = 2)(x)\n",
        "# flatten layer\n",
        "x = Flatten()(x)\n",
        "# layer-6: the first dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-7: the second dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-8: the output layer\n",
        "final_output = Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "# define the model\n",
        "model2 = Model(input=sequence_input, output=final_output)\n",
        "\n",
        "#view model\n",
        "print(model2.summary())\n",
        "\n",
        "# compile the model\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
        "# training and validation\n",
        "print('Training the model ...')\n",
        "model2.fit(x=x_train, y=y_train, nb_epoch=15, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 20, 300)           804600    \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 19, 128)           76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 8, 128)            32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 996,987\n",
            "Trainable params: 996,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "395/395 [==============================] - 0s 707us/step - loss: 0.9573 - acc: 0.5570\n",
            "Epoch 2/15\n",
            "395/395 [==============================] - 0s 424us/step - loss: 0.8368 - acc: 0.5367\n",
            "Epoch 3/15\n",
            "395/395 [==============================] - 0s 435us/step - loss: 0.8077 - acc: 0.5013\n",
            "Epoch 4/15\n",
            "395/395 [==============================] - 0s 406us/step - loss: 0.7851 - acc: 0.5772\n",
            "Epoch 5/15\n",
            "395/395 [==============================] - 0s 418us/step - loss: 0.7205 - acc: 0.6127\n",
            "Epoch 6/15\n",
            "395/395 [==============================] - 0s 440us/step - loss: 0.5467 - acc: 0.7519\n",
            "Epoch 7/15\n",
            "395/395 [==============================] - 0s 426us/step - loss: 0.5882 - acc: 0.7620\n",
            "Epoch 8/15\n",
            "395/395 [==============================] - 0s 475us/step - loss: 0.2010 - acc: 0.9418\n",
            "Epoch 9/15\n",
            "395/395 [==============================] - 0s 417us/step - loss: 0.0559 - acc: 0.9873\n",
            "Epoch 10/15\n",
            "395/395 [==============================] - 0s 439us/step - loss: 0.0188 - acc: 0.9949\n",
            "Epoch 11/15\n",
            "395/395 [==============================] - 0s 420us/step - loss: 0.0078 - acc: 1.0000\n",
            "Epoch 12/15\n",
            "395/395 [==============================] - 0s 433us/step - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 13/15\n",
            "395/395 [==============================] - 0s 440us/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 14/15\n",
            "395/395 [==============================] - 0s 468us/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 15/15\n",
            "395/395 [==============================] - 0s 409us/step - loss: 0.0013 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fbb09a5c6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu5TLZdhE1qP",
        "colab_type": "code",
        "outputId": "45f327ae-6420-4ff5-f146-53c6feb21e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_test_answers=pd.read_csv('drive/My Drive/dataset_test_answers.csv')\n",
        "data_test_target1_answers=data_test_answers[data_test_answers[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "y_ground_truth=data_test_target1_answers[\"Stance\"].values;\n",
        "\n",
        "\n",
        "y_test=np.zeros(len(data_test_target2))\n",
        "\n",
        "for i in range(len(y_ground_truth)):\n",
        "  if(y_ground_truth[i]=='AGAINST'):\n",
        "    y_test[i]=0;\n",
        "  elif(y_ground_truth[i]=='FAVOR'):\n",
        "    y_test[i]=1;\n",
        "  else:\n",
        "    y_test[i]=2;\n",
        "\n",
        "\n",
        "y_pred=model2.predict(x_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y=np.zeros(len(y_pred))\n",
        "for i in range(len(y_pred)):\n",
        "  y[i]=np.argmax(y_pred[i])\n",
        "\n",
        "print(y_test)\n",
        "print(y)\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "print(f1_score(y,y_test,average='macro'))\n",
        "print(precision_score(y,y_test,average='macro'))\n",
        "print(recall_score(y,y_test,average='macro'))\n",
        "print(accuracy_score(y,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.58610046e-02 9.91029739e-02 3.75779152e-01]\n",
            " [4.64370847e-03 1.70566440e-02 6.75544143e-01]\n",
            " [1.63763762e-04 5.71032941e-01 1.08551979e-03]\n",
            " [4.59671021e-04 3.09045911e-02 2.02993870e-01]\n",
            " [2.45493484e-05 8.83932233e-01 2.57506435e-05]\n",
            " [2.03228865e-06 4.83223557e-01 1.05995799e-08]\n",
            " [2.55960226e-03 2.35084504e-01 2.60790586e-02]\n",
            " [1.28477812e-04 1.03536010e-01 8.65608454e-03]\n",
            " [4.54217196e-04 7.38176703e-03 6.37118459e-01]\n",
            " [6.28687758e-06 9.16883945e-01 5.94154335e-06]\n",
            " [7.34723153e-06 3.38228464e-01 4.78833914e-04]\n",
            " [7.63707764e-10 1.11084762e-06 9.71298337e-01]\n",
            " [1.71124935e-04 2.15690762e-01 7.44652748e-03]\n",
            " [3.95681345e-05 9.16492224e-01 2.00496888e-05]\n",
            " [2.19872594e-03 1.29851103e-02 6.33762598e-01]\n",
            " [3.08215618e-04 6.12463593e-01 6.10649586e-04]\n",
            " [2.87738442e-03 5.10182083e-02 1.26247314e-05]\n",
            " [5.12554398e-05 6.72774434e-01 3.41355801e-04]\n",
            " [1.49220228e-04 7.83922851e-01 5.67695097e-05]\n",
            " [8.02433169e-06 5.77841103e-02 2.64931619e-02]\n",
            " [1.17772818e-03 9.33566093e-02 1.25070810e-01]\n",
            " [1.01023950e-07 6.17747843e-01 5.04801710e-06]\n",
            " [1.91680343e-07 9.12921667e-01 5.62804701e-07]\n",
            " [5.27251977e-05 1.62891150e-02 1.15992427e-01]\n",
            " [8.97596419e-06 9.14046884e-01 2.52148584e-06]\n",
            " [3.92882839e-06 7.07928956e-01 1.43587589e-04]\n",
            " [5.95526274e-07 9.41035032e-01 4.45580895e-07]\n",
            " [1.92133684e-05 8.08701992e-01 6.71758517e-06]\n",
            " [8.71209886e-06 8.01070929e-01 9.12560893e-07]\n",
            " [3.45860099e-05 6.71938062e-02 1.12140179e-03]\n",
            " [1.64470475e-05 7.49320745e-01 3.02151129e-05]\n",
            " [8.70004296e-03 6.71646297e-02 3.42671722e-01]\n",
            " [1.00119710e-02 2.59937793e-01 1.00396305e-01]\n",
            " [2.90086865e-03 5.50437987e-01 1.21357143e-02]\n",
            " [2.25593150e-02 4.32253420e-01 3.98809910e-02]\n",
            " [2.95249333e-06 3.74223292e-01 8.13692808e-04]\n",
            " [3.67203247e-05 8.95493507e-01 5.42943853e-05]\n",
            " [3.99313308e-07 9.13959384e-01 5.73759735e-06]\n",
            " [1.12271309e-03 6.11325502e-02 1.97115809e-01]\n",
            " [1.78364515e-02 2.87739575e-01 1.01423264e-03]\n",
            " [1.12153557e-05 8.00003111e-02 1.35987997e-02]\n",
            " [4.71845351e-06 9.44807768e-01 3.15752277e-06]\n",
            " [5.48884273e-03 5.49951732e-01 6.24167919e-03]\n",
            " [1.26600266e-04 1.20272428e-01 1.55251324e-02]\n",
            " [4.17798758e-04 3.15895915e-01 1.39383146e-05]\n",
            " [2.88128795e-05 8.03859234e-01 4.67246318e-05]\n",
            " [2.71246918e-05 8.86556625e-01 1.13565220e-05]\n",
            " [1.09834473e-04 8.71045589e-02 3.03262254e-07]\n",
            " [5.70041720e-06 9.49848592e-02 1.06865168e-03]\n",
            " [1.56891346e-03 4.90362704e-01 4.99173999e-03]\n",
            " [1.51640177e-03 5.31147420e-02 2.45567471e-01]\n",
            " [6.85207033e-06 5.74784279e-01 4.48661058e-06]\n",
            " [1.04111336e-06 9.07340288e-01 1.34801979e-07]\n",
            " [2.83310583e-05 8.34350467e-01 2.77003710e-06]\n",
            " [4.52699032e-06 4.04084682e-01 6.73872419e-05]\n",
            " [4.39205766e-02 3.38327199e-01 1.33249521e-01]\n",
            " [5.35804284e-05 2.02310234e-01 4.64660310e-08]\n",
            " [6.90311193e-04 5.52558899e-03 7.03845978e-01]\n",
            " [2.95778215e-02 1.51963085e-01 2.83209443e-01]\n",
            " [5.30874729e-03 3.50352168e-01 5.95408380e-02]\n",
            " [1.12420403e-05 8.90569329e-01 3.13650798e-06]\n",
            " [5.79455786e-07 9.18331742e-03 6.40109181e-03]\n",
            " [7.60387320e-06 9.18350756e-01 1.36874678e-05]\n",
            " [2.62230635e-04 1.17427558e-01 1.23631954e-03]\n",
            " [2.16317177e-03 5.64150631e-01 8.87900591e-04]\n",
            " [1.08170509e-03 1.45307928e-01 8.41080844e-02]\n",
            " [7.57860398e-05 7.54777789e-02 4.41149175e-02]\n",
            " [8.63406785e-06 1.79025918e-01 1.26323557e-05]\n",
            " [1.69058785e-05 1.21618539e-01 1.50117278e-03]\n",
            " [1.85299905e-05 8.43300939e-01 4.16449302e-06]\n",
            " [5.32368995e-06 5.51161170e-03 8.94245803e-02]\n",
            " [1.23798847e-03 6.16637588e-01 5.50904870e-03]\n",
            " [8.11730570e-05 2.53558218e-01 7.55286217e-03]\n",
            " [5.69590993e-05 1.87638700e-01 1.16178393e-03]\n",
            " [3.72855339e-07 1.74555182e-02 1.37561858e-02]\n",
            " [1.26749277e-04 1.89566612e-03 7.86045551e-01]\n",
            " [7.91459684e-07 9.62665558e-01 7.62569925e-07]\n",
            " [1.59960389e-02 2.17474788e-01 8.94703567e-02]\n",
            " [3.98967313e-05 6.92988396e-01 5.53578138e-04]\n",
            " [6.68466091e-04 1.60749853e-02 5.43686748e-01]\n",
            " [1.14281681e-06 9.19957876e-01 8.52867345e-07]\n",
            " [7.49146938e-03 2.65499771e-01 9.56233442e-02]\n",
            " [4.30840913e-07 8.83073092e-01 1.13123271e-08]\n",
            " [1.45593503e-06 6.10649586e-04 7.20192134e-01]\n",
            " [1.53979690e-05 1.53190911e-01 6.20040298e-03]\n",
            " [1.26862526e-03 8.62227380e-02 6.30747974e-02]\n",
            " [9.09096003e-03 1.07969642e-01 2.14691222e-01]\n",
            " [1.90153718e-02 8.84072185e-02 2.96729624e-01]\n",
            " [7.75551796e-03 5.49736619e-02 4.05733883e-01]\n",
            " [4.73852742e-05 8.07169139e-01 2.71946192e-04]\n",
            " [5.08850189e-06 3.39438796e-01 1.83245540e-03]\n",
            " [1.51187181e-04 4.86868292e-01 6.88552856e-04]\n",
            " [7.35908747e-03 5.20834744e-01 2.25878060e-02]\n",
            " [4.85855341e-03 3.35008740e-01 1.51411295e-02]\n",
            " [3.09541821e-03 2.89152265e-02 4.76258397e-02]\n",
            " [6.80818484e-05 1.26967728e-02 5.66937103e-07]\n",
            " [3.70080769e-02 1.49600059e-01 3.22021276e-01]\n",
            " [4.95160464e-07 8.82693172e-01 2.65761656e-07]\n",
            " [1.00013614e-03 8.44701231e-02 1.39981210e-01]\n",
            " [2.40147114e-04 7.05479980e-01 1.15929135e-04]\n",
            " [7.76085926e-06 4.56457436e-01 1.60026550e-03]\n",
            " [1.32777661e-01 2.58743376e-01 2.60846019e-01]\n",
            " [8.22784557e-07 1.87009573e-04 7.86238849e-01]\n",
            " [4.61149838e-08 9.34557915e-01 2.74714633e-08]\n",
            " [1.95121652e-06 7.15163350e-01 1.32927798e-05]\n",
            " [8.92872995e-05 8.38795185e-01 2.08318233e-04]\n",
            " [5.60332069e-07 5.48690557e-04 5.26047111e-01]\n",
            " [5.40638121e-06 8.93785179e-01 3.53991868e-06]\n",
            " [2.40490840e-06 9.24206495e-01 1.08804431e-06]\n",
            " [7.16042519e-03 3.02106559e-01 4.39223647e-03]\n",
            " [9.92812274e-05 1.71151757e-03 7.92968988e-01]\n",
            " [3.86348367e-03 6.33779287e-01 8.27947259e-03]\n",
            " [5.09290066e-06 7.93683887e-01 6.84761176e-07]\n",
            " [8.07732344e-04 2.11554855e-01 2.57039964e-02]\n",
            " [7.27851293e-05 1.51479691e-01 1.25291049e-02]\n",
            " [7.04714967e-06 5.18467903e-01 2.55977611e-05]\n",
            " [5.71343571e-06 7.79081225e-01 5.34472520e-06]\n",
            " [3.96274991e-05 8.78047049e-02 2.79418528e-02]\n",
            " [7.33703375e-03 8.54855180e-02 2.69840240e-01]\n",
            " [9.80401019e-05 5.46061695e-01 5.71519136e-04]\n",
            " [9.28819180e-04 4.00079906e-01 1.66101158e-02]\n",
            " [2.21669674e-04 7.38586187e-01 3.65406275e-04]\n",
            " [5.70969951e-06 8.98730516e-01 4.53812527e-06]\n",
            " [2.36582382e-05 1.23636484e-01 1.27729024e-07]\n",
            " [6.05326891e-03 6.09042823e-01 1.80955827e-02]\n",
            " [4.74082808e-05 5.92978120e-01 1.19656324e-03]\n",
            " [4.45303321e-03 4.48709726e-03 2.61099125e-08]\n",
            " [1.01113319e-03 6.58258796e-03 7.44161129e-01]\n",
            " [2.22238898e-03 4.20783877e-01 4.48766351e-03]\n",
            " [7.52268243e-05 7.95659125e-01 1.65045261e-04]\n",
            " [2.16249264e-05 7.24732757e-01 1.16707415e-04]\n",
            " [7.04497099e-04 4.26187456e-01 9.01454687e-03]\n",
            " [3.81497145e-02 3.52007478e-01 9.47391391e-02]\n",
            " [9.29095947e-08 8.66174102e-01 2.06915773e-09]\n",
            " [2.03044829e-06 3.29305172e-01 1.25030075e-09]\n",
            " [5.82993031e-04 1.09196007e-02 4.21715617e-01]\n",
            " [1.22376689e-04 7.93715179e-01 2.48860561e-05]\n",
            " [1.45433987e-05 8.87609661e-01 1.21496914e-05]\n",
            " [3.54043696e-05 8.62479210e-04 5.25416195e-01]\n",
            " [1.02484226e-03 5.98775864e-01 1.33532286e-03]\n",
            " [5.52747110e-07 1.69804573e-01 1.77417157e-08]\n",
            " [4.36758637e-06 7.80536056e-01 4.18705531e-05]\n",
            " [4.13961221e-09 1.20288134e-03 2.53043473e-02]\n",
            " [5.19990921e-04 6.35833442e-01 3.49283218e-04]\n",
            " [4.18671966e-03 5.01694679e-01 2.55070925e-02]\n",
            " [1.42505765e-03 3.38419974e-02 2.30043948e-01]\n",
            " [5.19344553e-07 5.18318951e-01 1.18830641e-04]\n",
            " [1.05044135e-04 4.73675132e-02 4.36212718e-02]\n",
            " [1.80392744e-05 8.82641673e-02 4.51916456e-03]\n",
            " [5.29064982e-06 6.85387731e-01 1.46031380e-04]\n",
            " [3.93627852e-05 9.06887650e-03 2.40045369e-01]\n",
            " [7.23140911e-05 7.95240879e-01 2.97713614e-05]\n",
            " [3.30074581e-05 4.56788003e-01 2.91755305e-06]\n",
            " [1.28313899e-03 4.06972766e-01 3.61314416e-03]\n",
            " [3.39746475e-04 7.83524752e-01 4.28110361e-04]\n",
            " [3.12883458e-05 4.52634096e-02 6.28250539e-02]\n",
            " [1.32471323e-04 6.66555166e-01 3.05473804e-04]\n",
            " [1.08370185e-03 3.44578624e-01 3.42726707e-04]\n",
            " [7.08267976e-07 5.13663530e-01 1.71514017e-07]\n",
            " [1.19715078e-05 7.85396874e-01 3.54437252e-05]\n",
            " [2.34842300e-04 7.67224073e-01 4.71025705e-04]\n",
            " [6.64693117e-03 1.51712865e-01 2.35671252e-01]\n",
            " [4.30226326e-04 2.72971392e-03 7.53584266e-01]\n",
            " [1.85936689e-04 6.60696030e-01 3.77744436e-04]\n",
            " [3.43618376e-06 1.73389912e-04 8.59711766e-01]\n",
            " [9.84716462e-06 7.71866083e-01 1.02513572e-04]\n",
            " [7.44054432e-07 1.76787376e-04 1.89320207e-01]\n",
            " [4.42730015e-06 9.37973559e-01 2.58029672e-06]\n",
            " [1.57177487e-06 6.57647073e-01 1.99979446e-08]]\n",
            "[2. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1.\n",
            " 1. 2. 2. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 1.\n",
            " 1. 1. 2. 0. 1. 1. 2. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 2. 2. 1. 1. 2. 2. 1.\n",
            " 0. 1. 2. 1. 1. 1. 1. 0. 1. 1. 1. 1. 2. 1. 1. 2. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 2. 1. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 1.\n",
            " 1.]\n",
            "[2. 2. 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2.\n",
            " 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1.\n",
            " 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1.\n",
            " 2. 1. 2. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 2. 1.\n",
            " 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 2. 1. 2. 1. 2. 1.\n",
            " 1.]\n",
            "0.47113912331303637\n",
            "0.4899728997289972\n",
            "0.45384615384615384\n",
            "0.757396449704142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOJDQXiiRxlN",
        "colab_type": "code",
        "outputId": "9be6dfca-fb6f-4281-c697-d62c892455da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# for Target 3\n",
        "\n",
        "\n",
        "target3_train_data=[]\n",
        "for i in range(target1_train_len+target2_train_len,target1_train_len+target2_train_len+target3_train_len):\n",
        "    target3_train_data.append(data_train_target3[\"Tweet\"][i])\n",
        "    \n",
        "    \n",
        "print(len(target3_train_data))\n",
        "\n",
        "target3_train_data=convert_lowercase(target3_train_data)\n",
        "target3_train_data=remove_digits(target3_train_data)\n",
        "target3_train_data=remove_punctuations(target3_train_data)\n",
        "target3_train_data=tokenize_data(target3_train_data)\n",
        "target3_train_data=remove_stopwords(target3_train_data)\n",
        "target3_train_data=lemmatize(target3_train_data)\n",
        "target3_train_data=make_string(target3_train_data)\n",
        "\n",
        "\n",
        "target3_test_data=[]\n",
        "for i in range(target1_test_len+target2_test_len,target1_test_len+target2_test_len+target3_test_len):\n",
        "    target3_test_data.append(data_test_target3[\"Tweet\"][i])\n",
        "    \n",
        "target3_test_data=convert_lowercase(target3_test_data)\n",
        "target3_test_data=remove_digits(target3_test_data)\n",
        "target3_test_data=remove_punctuations(target3_test_data)\n",
        "target3_test_data=tokenize_data(target3_test_data)\n",
        "target3_test_data=remove_stopwords(target3_test_data)\n",
        "target3_test_data=lemmatize(target3_test_data)\n",
        "target3_test_data=make_string(target3_test_data)\n",
        "\n",
        "\n",
        "y1=[]\n",
        "for i in range(target1_train_len+target2_train_len,target1_train_len+target2_train_len+target3_train_len):\n",
        "    y1.append(data_train_target3[\"Stance\"][i])\n",
        "  \n",
        "print(\"Y1: \",len(y1))\n",
        "\n",
        "target3_full_data=[]\n",
        "target3_full_data.extend(target3_train_data)\n",
        "target3_full_data.extend(target3_test_data)\n",
        "\n",
        "\n",
        "# tokenize the words in the texts\n",
        "max_nb_words=2000\n",
        "tokenizer = Tokenizer(num_words = max_nb_words) \n",
        "tokenizer.fit_on_texts(target3_full_data) \n",
        "# convert each review text into a sequence of word-indices\n",
        "matrix_word_indices = tokenizer.texts_to_sequences(target3_full_data)\n",
        "# the dictionary for mapping a word to an index\n",
        "dictionary_word_index = tokenizer.word_index\n",
        "\n",
        "print(len(dictionary_word_index))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# pad each review text to a fixed length of word sequence\n",
        "num_words_per_review=20\n",
        "matrix_word_indices_fixed_length = pad_sequences(matrix_word_indices, maxlen = num_words_per_review)\n",
        "# convert to numpy arrays \n",
        "data = np.array(matrix_word_indices_fixed_length)\n",
        "\n",
        "print(matrix_word_indices_fixed_length.shape)\n",
        "\n",
        "# allocation of training data and validation data\n",
        "x_train = data[:len(data_train_target3)]\n",
        "x_test = data[len(data_train_target3):]\n",
        "\n",
        "y_train=np.zeros(shape=(target3_train_len,3))\n",
        "\n",
        "print(\"y_train: \",len(y_train))\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  if(y1[i]=='AGAINST'):\n",
        "    y_train[i][0]=1;\n",
        "  elif(y1[i]=='FAVOR'):\n",
        "    y_train[i][1]=1;\n",
        "  else:\n",
        "    y_train[i][2]=1;\n",
        "\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "\n",
        "\n",
        "# prepare embedding matrix\n",
        "num_words = len(dictionary_word_index)\n",
        "# embedding_matrix[0] is a all-zero vector representing no word\n",
        "embedding_matrix = np.zeros((num_words+1, 300)) \n",
        "\n",
        "init_vector=np.zeros(300)\n",
        "\n",
        "\n",
        "unknown_words=[]\n",
        "for word, index in dictionary_word_index.items():\n",
        "    if index > max_nb_words:\n",
        "        continue \n",
        "    # get the glove vector for the word\n",
        "    try:\n",
        "      word_vector = word2vec.wv[word]\n",
        "      if word_vector is not None: \n",
        "          embedding_matrix[index] = word_vector\n",
        "    except:\n",
        "      unknown_words.append(word)\n",
        "      #print(word)\n",
        "      embedding_matrix[index] = init_vector\n",
        "  \n",
        "print(\"The no. of unknown words: \", len(unknown_words))\n",
        "\n",
        "print(len(embedding_matrix))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "664\n",
            "Y1:  664\n",
            "3564\n",
            "(949, 20)\n",
            "y_train:  664\n",
            "664\n",
            "285\n",
            "The no. of unknown words:  392\n",
            "3565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCVmVeEOUFTN",
        "colab_type": "code",
        "outputId": "41eccc31-2c63-4e30-a148-cab02e059e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define the model\n",
        "# layer 0: the input layer\n",
        "num_words_per_tweet=20\n",
        "sequence_input = Input(shape=(num_words_per_tweet,), dtype='int32')\n",
        "# layer-1: the embedding layer\n",
        "embedding_layer = Embedding(num_words+1, 300, weights=[embedding_matrix], input_length=num_words_per_tweet, trainable=True)\n",
        "embedded_output = embedding_layer(sequence_input)\n",
        "# layer-2: the first convolution layer\n",
        "x = Conv1D(nb_filter=128, filter_length=2, activation='relu')(embedded_output)\n",
        "# layer-3: the first pooling layer\n",
        "x = MaxPooling1D(pool_length=2)(x)\n",
        "# layer-4: the second convolution layer\n",
        "x = Conv1D(128, 2, activation='relu')(x)\n",
        "# layer-5: the second pooling layer\n",
        "x = MaxPooling1D(pool_length = 2)(x)\n",
        "# flatten layer\n",
        "x = Flatten()(x)\n",
        "# layer-6: the first dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-7: the second dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-8: the output layer\n",
        "final_output = Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "# define the model\n",
        "model2 = Model(input=sequence_input, output=final_output)\n",
        "\n",
        "#view model\n",
        "print(model2.summary())\n",
        "\n",
        "# compile the model\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
        "# training and validation\n",
        "print('Training the model ...')\n",
        "model2.fit(x=x_train, y=y_train, nb_epoch=10, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 20, 300)           1069500   \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 19, 128)           76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 8, 128)            32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,261,887\n",
            "Trainable params: 1,261,887\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "664/664 [==============================] - 0s 564us/step - loss: 1.1683 - acc: 0.4940\n",
            "Epoch 2/10\n",
            "664/664 [==============================] - 0s 407us/step - loss: 0.9272 - acc: 0.4955\n",
            "Epoch 3/10\n",
            "664/664 [==============================] - 0s 398us/step - loss: 0.8240 - acc: 0.5331\n",
            "Epoch 4/10\n",
            "664/664 [==============================] - 0s 389us/step - loss: 0.6683 - acc: 0.7696\n",
            "Epoch 5/10\n",
            "664/664 [==============================] - 0s 387us/step - loss: 0.4405 - acc: 0.8178\n",
            "Epoch 6/10\n",
            "664/664 [==============================] - 0s 408us/step - loss: 0.3642 - acc: 0.8660\n",
            "Epoch 7/10\n",
            "664/664 [==============================] - 0s 401us/step - loss: 0.1086 - acc: 0.9669\n",
            "Epoch 8/10\n",
            "664/664 [==============================] - 0s 388us/step - loss: 0.0334 - acc: 0.9880\n",
            "Epoch 9/10\n",
            "664/664 [==============================] - 0s 399us/step - loss: 0.0137 - acc: 0.9985\n",
            "Epoch 10/10\n",
            "664/664 [==============================] - 0s 415us/step - loss: 0.0065 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2e7d368c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR0hFXHNUI5n",
        "colab_type": "code",
        "outputId": "7ee45560-39d7-431f-9f18-828d8b0aabba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_test_answers=pd.read_csv('drive/My Drive/dataset_test_answers.csv')\n",
        "data_test_target3_answers=data_test_answers[data_test_answers[\"Target\"]==\"Feminist Movement\"]\n",
        "y_ground_truth=data_test_target3_answers[\"Stance\"].values;\n",
        "\n",
        "\n",
        "y_test=np.zeros(len(data_test_target3))\n",
        "\n",
        "for i in range(len(y_ground_truth)):\n",
        "  if(y_ground_truth[i]=='AGAINST'):\n",
        "    y_test[i]=0;\n",
        "  elif(y_ground_truth[i]=='FAVOR'):\n",
        "    y_test[i]=1;\n",
        "  else:\n",
        "    y_test[i]=2;\n",
        "\n",
        "\n",
        "y_pred=model2.predict(x_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y=np.zeros(len(y_pred))\n",
        "for i in range(len(y_pred)):\n",
        "  y[i]=np.argmax(y_pred[i])\n",
        "\n",
        "print(y_test)\n",
        "print(y)\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "print(f1_score(y,y_test,average='macro'))\n",
        "print(precision_score(y,y_test,average='macro'))\n",
        "print(recall_score(y,y_test,average='macro'))\n",
        "print(accuracy_score(y,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.40152669e-01 7.31378794e-04 4.44587022e-06]\n",
            " [9.31704044e-01 4.60159617e-06 1.20612484e-07]\n",
            " [1.21366978e-03 6.56044483e-02 1.61850452e-03]\n",
            " [3.83973122e-04 2.89767981e-04 1.52915716e-04]\n",
            " [9.74312425e-01 6.53620009e-05 3.44804903e-07]\n",
            " [9.72890973e-01 1.34506822e-03 4.30535536e-08]\n",
            " [9.60862637e-03 2.67920659e-05 1.95205212e-04]\n",
            " [7.07274675e-03 1.78423584e-01 3.14652920e-04]\n",
            " [2.38484144e-03 5.05742431e-03 1.76292658e-03]\n",
            " [2.25779414e-03 8.69610429e-01 3.73928633e-05]\n",
            " [2.07187802e-01 3.41367722e-03 3.79413366e-03]\n",
            " [3.94731760e-04 4.99039888e-04 1.49857642e-05]\n",
            " [2.52896547e-02 4.97771180e-05 6.02618602e-05]\n",
            " [1.89149380e-03 9.34213400e-04 2.24536652e-05]\n",
            " [1.67713583e-01 6.91139698e-03 2.95996666e-04]\n",
            " [7.78257847e-04 1.48447752e-02 2.95096636e-03]\n",
            " [8.77995014e-01 2.62463618e-05 1.25437975e-04]\n",
            " [2.95006335e-02 2.11578012e-02 4.81158495e-04]\n",
            " [8.82627249e-01 5.28221790e-05 2.36699492e-07]\n",
            " [1.09701527e-04 2.61966765e-01 1.40277807e-05]\n",
            " [2.03448534e-03 2.55218148e-03 8.86085629e-02]\n",
            " [4.21929359e-03 1.13725662e-03 1.26594305e-03]\n",
            " [2.69412994e-04 3.30752134e-02 2.96086073e-03]\n",
            " [6.82136416e-03 1.43422484e-02 4.88721728e-02]\n",
            " [2.44444609e-03 2.20666826e-02 1.24990940e-04]\n",
            " [1.52197480e-03 6.63435459e-03 2.37676501e-03]\n",
            " [8.18184853e-01 1.12447215e-05 1.92210746e-06]\n",
            " [2.77918577e-03 1.97477043e-02 3.63236666e-03]\n",
            " [9.78508830e-01 1.08682376e-04 5.79312973e-06]\n",
            " [6.13719225e-04 5.60300350e-02 1.12524629e-03]\n",
            " [1.84804201e-03 4.78389263e-02 1.13731623e-03]\n",
            " [2.98979878e-03 1.59972351e-05 9.83083248e-03]\n",
            " [3.60227525e-02 1.52390897e-02 7.95960426e-04]\n",
            " [1.98930502e-04 2.24562585e-02 1.08068883e-02]\n",
            " [5.88382185e-01 5.76049089e-04 2.22107768e-03]\n",
            " [1.40231848e-03 1.18292570e-02 1.53157489e-05]\n",
            " [2.03579664e-04 4.88044322e-02 2.70059705e-03]\n",
            " [3.74168158e-04 2.96026468e-04 1.57403409e-01]\n",
            " [4.38737869e-03 4.12255526e-04 1.62190199e-03]\n",
            " [4.72286344e-03 2.35319138e-04 1.63424611e-02]\n",
            " [9.59103823e-01 1.52569119e-05 1.25376719e-05]\n",
            " [1.06418782e-04 4.03058529e-03 5.37706683e-06]\n",
            " [1.62499845e-02 6.65754080e-04 1.27196312e-03]\n",
            " [2.47234106e-03 2.37505847e-05 1.15702242e-01]\n",
            " [8.69891346e-01 3.12179327e-04 6.06841809e-07]\n",
            " [4.12067771e-02 1.38878822e-04 1.38729811e-04]\n",
            " [4.03905213e-02 3.93629074e-04 3.19123268e-03]\n",
            " [3.55067253e-02 5.95152378e-04 8.42422247e-03]\n",
            " [1.49302781e-02 3.21400762e-02 6.84414863e-06]\n",
            " [3.61924469e-02 4.00808131e-05 1.42656565e-02]\n",
            " [5.05093932e-02 1.04028583e-02 1.55540228e-01]\n",
            " [5.08673787e-02 1.11870170e-02 1.18253971e-04]\n",
            " [6.80491328e-02 1.08447559e-04 5.27858734e-04]\n",
            " [3.33619118e-03 1.12009048e-03 3.09739232e-01]\n",
            " [7.72828221e-01 1.19012493e-05 5.21630341e-07]\n",
            " [4.67700958e-02 2.53576636e-02 2.05363721e-01]\n",
            " [4.58957693e-05 4.47991788e-02 2.31981277e-04]\n",
            " [8.07339549e-02 9.64760780e-04 1.19323493e-04]\n",
            " [8.00251961e-04 4.19113785e-05 2.51678575e-05]\n",
            " [2.19738483e-02 5.97246799e-05 2.82177031e-02]\n",
            " [2.04503536e-03 4.14004922e-03 6.31685543e-06]\n",
            " [7.86602497e-04 1.63932443e-01 8.06272030e-04]\n",
            " [2.40030885e-03 2.01537311e-02 6.14965538e-05]\n",
            " [1.60670877e-02 1.47842169e-02 4.97199437e-07]\n",
            " [2.10628510e-02 5.56573272e-03 3.01751413e-07]\n",
            " [1.22361064e-01 3.69957685e-02 8.90064836e-02]\n",
            " [1.02824092e-01 8.98957253e-04 6.05612993e-04]\n",
            " [5.41305900e-01 1.63653493e-03 1.65597212e-05]\n",
            " [9.80508447e-01 2.73453452e-06 9.86890541e-07]\n",
            " [9.82673287e-01 2.34298113e-06 1.60853142e-06]\n",
            " [6.73723221e-02 2.60889530e-04 1.26012401e-05]\n",
            " [6.88743591e-03 4.86406684e-03 9.06644800e-07]\n",
            " [9.00802970e-01 1.37304814e-05 3.85223575e-06]\n",
            " [6.08983636e-02 4.54861522e-02 3.28123569e-04]\n",
            " [9.46024060e-03 4.96268272e-04 4.92793322e-03]\n",
            " [2.73475644e-06 1.44943893e-02 2.67995783e-05]\n",
            " [9.59128141e-04 1.80264115e-02 1.74330771e-02]\n",
            " [1.00828423e-04 5.13211780e-05 1.21112108e-01]\n",
            " [2.77561426e-01 3.65112282e-05 1.68677821e-06]\n",
            " [6.73606873e-01 1.32817040e-05 7.05290802e-07]\n",
            " [7.31426477e-03 3.14629674e-02 1.98364258e-04]\n",
            " [5.95854402e-01 9.37163830e-04 2.26914883e-04]\n",
            " [6.47657156e-01 2.78627872e-03 1.81165338e-03]\n",
            " [5.33571064e-01 5.60104847e-04 5.94666199e-06]\n",
            " [1.67672932e-02 7.52340555e-02 3.10868025e-04]\n",
            " [1.99724734e-02 3.95187676e-01 7.57201487e-05]\n",
            " [3.86059284e-04 8.40127468e-04 2.63589442e-01]\n",
            " [1.59981847e-03 8.41021538e-04 4.65096127e-06]\n",
            " [1.12676353e-04 5.04934788e-03 3.03510427e-02]\n",
            " [7.39408493e-01 1.05687976e-03 3.10740506e-06]\n",
            " [1.47453249e-02 6.74617290e-03 2.44469011e-05]\n",
            " [8.83468986e-03 1.90824270e-03 3.18307519e-01]\n",
            " [2.66765058e-01 1.26546323e-02 1.42088851e-07]\n",
            " [3.03883553e-02 9.70518589e-03 2.86089420e-01]\n",
            " [2.99066305e-04 1.38461590e-04 2.81808674e-01]\n",
            " [3.57295752e-01 5.67108393e-03 9.16403951e-06]\n",
            " [9.86549377e-01 2.23205370e-06 1.67030782e-06]\n",
            " [6.80092573e-02 1.11842155e-03 4.03970480e-04]\n",
            " [6.68413937e-02 1.07042789e-02 3.51642668e-02]\n",
            " [3.01444709e-01 6.29195571e-03 1.75733632e-07]\n",
            " [2.38925219e-04 1.90985203e-03 6.55055046e-04]\n",
            " [2.62197852e-03 3.51375341e-03 2.06351280e-04]\n",
            " [5.08494675e-01 7.27681909e-05 3.07049390e-06]\n",
            " [2.17434347e-01 2.67058611e-04 4.61475647e-05]\n",
            " [2.09806859e-01 1.86840594e-02 3.34177911e-02]\n",
            " [3.40658426e-03 4.45723534e-04 5.48771322e-02]\n",
            " [3.58751416e-03 8.60214233e-04 3.54040861e-01]\n",
            " [4.43136692e-03 1.45018101e-04 4.07419801e-02]\n",
            " [2.90617347e-03 1.30232751e-01 1.32232904e-04]\n",
            " [5.25981188e-04 1.22472644e-02 2.70932913e-04]\n",
            " [1.09634064e-04 7.20390081e-02 1.55049562e-03]\n",
            " [5.42914867e-03 7.08526969e-02 1.55934691e-03]\n",
            " [4.35894728e-03 4.54026461e-03 2.72237718e-01]\n",
            " [3.07573676e-02 4.08086300e-01 1.47823457e-05]\n",
            " [1.15254581e-01 1.74131989e-03 2.41426460e-05]\n",
            " [1.05658770e-01 4.11357578e-05 1.41036510e-03]\n",
            " [4.21235412e-01 8.82083696e-05 1.21068442e-04]\n",
            " [8.41910422e-01 1.78188086e-04 4.64078624e-07]\n",
            " [2.09173560e-02 5.80039123e-05 1.54563785e-02]\n",
            " [5.36045432e-02 2.72045434e-02 4.84651464e-05]\n",
            " [1.91264749e-02 5.05984545e-01 9.31527381e-07]\n",
            " [3.11194122e-01 3.14742327e-04 9.96190310e-03]\n",
            " [2.77353644e-01 1.37470663e-02 4.87161878e-06]\n",
            " [4.53584880e-01 9.69946384e-04 2.95549631e-04]\n",
            " [1.99389160e-02 2.70923972e-03 1.01295114e-03]\n",
            " [4.12523746e-04 1.71151757e-03 3.41688938e-05]\n",
            " [2.86182463e-02 4.23255563e-03 4.87736725e-05]\n",
            " [9.99190807e-01 2.00285035e-06 3.93644939e-08]\n",
            " [2.52267450e-01 1.86616182e-03 2.25755794e-05]\n",
            " [9.94384468e-01 4.10355653e-07 3.92086122e-07]\n",
            " [1.34515166e-02 2.55185366e-02 2.22723429e-05]\n",
            " [1.17941499e-02 1.02077880e-04 5.69558144e-03]\n",
            " [6.17251217e-01 7.05242157e-04 1.97678804e-04]\n",
            " [3.82550955e-02 7.42934135e-05 5.99059463e-03]\n",
            " [2.03173757e-02 4.91476059e-03 1.79780818e-05]\n",
            " [2.20823288e-03 2.90602982e-01 2.02168867e-05]\n",
            " [2.20388174e-04 3.92398238e-03 2.96959281e-03]\n",
            " [8.17103982e-02 1.38914585e-03 7.89085971e-06]\n",
            " [6.75106049e-03 1.00517273e-03 3.30394214e-05]\n",
            " [1.39623880e-04 5.46813011e-01 4.08567439e-06]\n",
            " [9.80079174e-04 2.65321796e-05 1.29054159e-01]\n",
            " [1.86145306e-04 4.34228182e-02 1.06766951e-04]\n",
            " [5.34831882e-02 9.22441483e-04 3.41630876e-02]\n",
            " [2.99125910e-04 1.19994283e-02 3.61165404e-03]\n",
            " [2.99125910e-04 1.19994283e-02 3.61165404e-03]\n",
            " [2.97078103e-01 1.15978718e-03 7.35372305e-04]\n",
            " [4.96447086e-04 4.39639688e-02 3.79866362e-03]\n",
            " [4.34595078e-01 6.93318248e-03 4.14731003e-05]\n",
            " [7.76380301e-03 2.13801861e-04 2.02387571e-03]\n",
            " [1.60017908e-02 3.27083908e-05 5.01854702e-05]\n",
            " [2.10787654e-02 5.89263439e-03 1.15788102e-01]\n",
            " [1.19020045e-02 1.00031495e-03 3.14027071e-04]\n",
            " [1.47614181e-02 5.63973188e-03 4.95640052e-05]\n",
            " [3.93456221e-03 2.89991498e-03 1.25388010e-06]\n",
            " [1.32341683e-02 6.55758381e-02 2.22265720e-04]\n",
            " [3.56239885e-01 5.98222017e-03 3.29237878e-02]\n",
            " [6.22716069e-01 1.29133463e-04 1.66342943e-06]\n",
            " [1.15000039e-01 3.27885151e-03 2.37920929e-07]\n",
            " [3.01459186e-05 1.26957893e-04 4.94334102e-03]\n",
            " [1.63378984e-01 5.47111034e-04 2.41265893e-02]\n",
            " [1.63922906e-02 4.38421965e-04 2.48777866e-03]\n",
            " [3.71399522e-03 3.33011150e-04 8.10520351e-02]\n",
            " [8.13495517e-02 1.37322545e-02 1.55379951e-01]\n",
            " [1.68535113e-03 1.06999278e-03 1.82605624e-01]\n",
            " [4.80410963e-05 2.73770094e-03 4.10395861e-03]\n",
            " [3.04669142e-04 1.35430574e-01 3.73452902e-04]\n",
            " [8.50545883e-01 3.89307737e-03 3.94259757e-07]\n",
            " [1.70320272e-04 6.61885023e-01 2.86936760e-04]\n",
            " [1.29401684e-04 1.06318155e-04 1.31627917e-03]\n",
            " [5.60054183e-03 2.07126141e-04 1.71494484e-03]\n",
            " [4.72682953e-01 2.74956226e-04 3.65445999e-07]\n",
            " [1.19943023e-02 1.82792544e-03 2.38120556e-04]\n",
            " [4.59271431e-01 1.69488788e-03 5.69409132e-03]\n",
            " [5.90309501e-03 1.00752562e-01 7.12999827e-05]\n",
            " [1.06376410e-03 1.79866850e-02 4.15008763e-05]\n",
            " [3.66783142e-02 3.98175985e-01 6.73621893e-04]\n",
            " [1.79940462e-03 8.77261162e-04 4.06817235e-05]\n",
            " [4.27699089e-03 6.66359961e-02 4.47809696e-04]\n",
            " [2.76296139e-02 1.13009512e-02 7.92972605e-06]\n",
            " [2.10266590e-01 8.50588083e-04 1.17975473e-03]\n",
            " [9.25723791e-01 2.34663486e-04 6.82917516e-07]\n",
            " [1.25359327e-01 4.54028777e-05 5.39928675e-04]\n",
            " [5.47883391e-01 8.91953707e-04 7.92010451e-06]\n",
            " [3.82751822e-02 8.77144933e-03 1.84482894e-06]\n",
            " [4.31090593e-03 1.50450766e-02 3.75770901e-06]\n",
            " [2.02924311e-02 1.48818493e-02 5.16742468e-04]\n",
            " [3.91572714e-04 6.06238842e-04 2.15709209e-04]\n",
            " [3.10652405e-01 7.76287913e-03 2.44594485e-05]\n",
            " [6.99959993e-02 4.31742668e-02 5.32274044e-06]\n",
            " [3.17878723e-02 5.99826574e-02 1.86393099e-05]\n",
            " [6.56112461e-05 1.11663342e-03 3.39143044e-05]\n",
            " [2.34776735e-03 2.07060575e-03 9.53334570e-03]\n",
            " [1.31756067e-04 2.50547826e-02 3.87015734e-06]\n",
            " [1.27524137e-03 1.36372447e-03 9.31242704e-02]\n",
            " [6.32314980e-02 2.07167864e-03 3.54161859e-03]\n",
            " [1.29706860e-02 5.58532774e-02 1.34630501e-02]\n",
            " [1.32916570e-02 6.26531546e-05 1.74531251e-01]\n",
            " [1.01269782e-02 1.96030736e-03 2.43175030e-03]\n",
            " [1.04871324e-05 4.51019406e-03 4.37065959e-03]\n",
            " [7.78496265e-04 7.68645108e-02 6.03377819e-04]\n",
            " [2.14498341e-02 1.90009475e-02 1.08497143e-02]\n",
            " [4.24218178e-03 6.98654652e-02 7.20152366e-06]\n",
            " [7.65074492e-01 8.92370939e-04 1.84088945e-04]\n",
            " [1.06351363e-05 8.53393674e-02 2.69128359e-05]\n",
            " [1.87781453e-03 6.58065081e-04 1.07345215e-06]\n",
            " [1.92365060e-05 6.78610742e-01 1.47693390e-05]\n",
            " [7.68098235e-02 1.75553560e-03 1.35073066e-03]\n",
            " [3.10810208e-02 2.06839144e-02 3.22790742e-02]\n",
            " [1.04707680e-04 9.22039628e-01 2.68743232e-08]\n",
            " [1.42289579e-01 1.11544132e-03 2.16710567e-03]\n",
            " [7.54415989e-04 8.22693110e-04 7.76500965e-05]\n",
            " [1.81329250e-03 1.04704499e-03 2.37328947e-01]\n",
            " [7.68651366e-01 2.30497753e-05 5.57857020e-05]\n",
            " [1.33160055e-02 1.59205347e-01 3.34152719e-05]\n",
            " [2.84433365e-04 1.71250761e-01 1.58339739e-04]\n",
            " [2.94404626e-02 6.49334192e-01 4.95464701e-05]\n",
            " [7.97009826e-01 4.72635031e-04 3.59892845e-04]\n",
            " [1.30057335e-04 8.64475965e-04 9.39279795e-04]\n",
            " [9.96409655e-01 1.21691903e-06 4.33350863e-07]\n",
            " [1.30006671e-03 8.85186195e-01 6.20929422e-05]\n",
            " [5.20990034e-05 5.69140613e-02 3.50795381e-05]\n",
            " [1.56253576e-04 3.41552138e-01 7.62811032e-06]\n",
            " [9.32202399e-01 1.76380399e-05 1.62232277e-06]\n",
            " [2.29741782e-01 9.61968303e-03 1.60107738e-05]\n",
            " [1.49130821e-04 9.88668203e-03 9.03065848e-06]\n",
            " [1.69091403e-01 2.87014246e-03 4.03523445e-04]\n",
            " [6.69628382e-04 2.15913057e-02 1.34955347e-02]\n",
            " [4.89935368e-01 2.89815664e-03 9.71240979e-07]\n",
            " [6.85975850e-02 7.48753548e-04 2.10711187e-06]\n",
            " [3.55808496e-01 6.37501478e-04 2.58356333e-04]\n",
            " [1.54272437e-01 1.10569596e-03 1.03569031e-02]\n",
            " [2.75731087e-04 4.68128085e-01 4.24712896e-04]\n",
            " [4.84526157e-04 7.33353518e-05 8.60821307e-02]\n",
            " [5.93353450e-01 1.03724735e-04 2.15336445e-06]\n",
            " [8.02463412e-01 3.02053450e-05 8.68233110e-06]\n",
            " [2.93232858e-01 3.09744477e-03 8.59993037e-08]\n",
            " [2.86489725e-03 1.30973458e-02 5.80731539e-05]\n",
            " [6.44967258e-02 4.89205122e-04 1.39617823e-05]\n",
            " [7.43617117e-02 8.88526440e-04 9.75698531e-02]\n",
            " [3.15632224e-01 7.53343105e-04 7.04199010e-06]\n",
            " [2.89342999e-02 4.44577336e-02 1.59581304e-02]\n",
            " [2.32547522e-04 5.39422035e-04 3.49361897e-02]\n",
            " [8.91658664e-03 1.65235996e-03 2.47320771e-01]\n",
            " [7.25682676e-02 5.38402796e-03 9.45047418e-08]\n",
            " [6.64510727e-02 1.00884140e-02 8.59736901e-05]\n",
            " [8.87964666e-02 7.68346786e-02 2.90176149e-06]\n",
            " [1.15206838e-02 6.11272454e-03 1.47432089e-03]\n",
            " [6.63339496e-02 2.98085809e-03 1.04445219e-03]\n",
            " [2.01272368e-02 3.12513769e-01 1.48766758e-05]\n",
            " [9.26858187e-03 4.56589769e-05 2.02896595e-02]\n",
            " [7.48813152e-04 3.00616026e-04 2.64047086e-02]\n",
            " [2.64492542e-01 8.64863396e-04 1.63922608e-02]\n",
            " [5.07503748e-04 5.43475151e-04 1.01831228e-01]\n",
            " [4.33292896e-01 3.36170197e-04 2.13325024e-04]\n",
            " [9.69753027e-01 5.95117808e-06 6.89115723e-07]\n",
            " [7.05582619e-01 9.41157341e-04 8.66299342e-06]\n",
            " [6.43648386e-01 9.48867202e-03 5.94373375e-07]\n",
            " [5.74737787e-04 4.65485454e-03 4.95463610e-04]\n",
            " [1.50641531e-01 8.67277384e-04 4.26335901e-05]\n",
            " [1.71989202e-02 1.56846732e-01 3.23832035e-04]\n",
            " [1.03362734e-04 4.90020186e-01 6.78797323e-06]\n",
            " [3.39500904e-01 9.65416431e-04 3.64047289e-03]\n",
            " [9.92717862e-01 6.74140756e-06 4.90154434e-07]\n",
            " [6.76840544e-04 9.07918811e-03 5.12273402e-07]\n",
            " [5.62492609e-02 1.64180994e-04 2.42621827e-05]\n",
            " [3.50241661e-02 3.57081592e-02 7.72356987e-04]\n",
            " [1.60515308e-03 7.88954020e-01 1.74185570e-05]\n",
            " [1.25277042e-01 8.94689560e-03 1.06136158e-05]\n",
            " [8.55318785e-01 1.86877951e-05 5.39598113e-06]\n",
            " [4.65795696e-02 2.73022056e-03 1.05042785e-01]\n",
            " [9.43347812e-01 3.42547894e-04 1.71050692e-06]\n",
            " [3.50362062e-03 7.36257434e-03 6.89518750e-02]\n",
            " [1.17345750e-02 1.07342005e-03 8.93500447e-03]\n",
            " [4.98798108e-05 5.99324703e-04 9.42200422e-04]\n",
            " [3.62416685e-01 1.64121389e-04 1.04910135e-03]\n",
            " [7.72483885e-01 1.02704763e-03 5.76014736e-06]\n",
            " [3.50385308e-02 1.77833438e-03 2.62140930e-01]\n",
            " [6.12861986e-05 9.18596983e-03 8.28913617e-05]\n",
            " [1.81022882e-02 1.08399987e-03 2.15709209e-04]\n",
            " [7.31251538e-02 3.16375196e-02 1.26433372e-02]\n",
            " [1.67608261e-04 1.53809786e-04 7.35565722e-02]\n",
            " [4.43735719e-03 3.35609913e-02 3.06548063e-05]\n",
            " [1.85507238e-02 8.33380222e-03 8.08811223e-04]\n",
            " [1.34310767e-01 5.18979691e-03 1.11777093e-02]\n",
            " [1.80107988e-02 5.02657937e-03 1.63907956e-04]]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 2. 0. 0. 1. 1. 1. 0. 1. 2. 2. 0. 2. 1. 1. 2. 0. 2. 2. 0.\n",
            " 0. 1. 2. 0. 2. 0. 1. 0. 2. 2. 1. 2. 0. 0. 0. 0. 2. 1. 1. 2. 1. 1. 2. 0.\n",
            " 0. 2. 0. 1. 2. 0. 1. 0. 0. 0. 0. 2. 0. 1. 2. 0. 2. 0. 0. 0. 2. 1. 0. 1.\n",
            " 1. 0. 1. 0. 2. 0. 2. 0. 1. 2. 0. 2. 0. 0. 2. 2. 1. 2. 2. 2. 1. 1. 0. 1.\n",
            " 2. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 2.\n",
            " 1. 2. 2. 1. 2. 0. 2. 0. 0. 1. 0. 0. 0. 1. 1. 2. 1. 2. 0. 2. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 2. 0. 2. 0. 1. 2. 1. 2. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 2. 0. 1. 2.\n",
            " 1. 1. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1. 2. 0. 2. 0. 1. 0. 2. 0. 0. 0. 0.\n",
            " 1. 0. 2. 0. 0. 2. 0. 2. 1. 0. 0. 2. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 2. 0. 0. 1. 0. 0. 0. 1. 1. 2. 0. 2. 0. 0. 2. 0. 2. 2. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 2. 1. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 2. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 2. 2. 2. 2. 1. 0. 1.\n",
            " 2. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 2.\n",
            " 1. 2. 0. 1. 2. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 2. 1. 0. 1. 2. 0. 1. 1. 1.\n",
            " 0. 2. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 2. 0. 0. 0. 1. 0. 2. 0.\n",
            " 1. 2. 2. 0. 0. 0. 0. 0. 1. 2. 2. 0. 2. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 2. 0. 2. 0. 2. 0. 0. 2. 1. 0. 0. 2. 1. 0. 0. 0.]\n",
            "0.5227231898954542\n",
            "0.537072248773775\n",
            "0.5200983993410361\n",
            "0.5719298245614035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfWdJs5a-YK6",
        "colab_type": "code",
        "outputId": "6ff2349b-063e-4a39-b12c-d8eb61357b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# for Target 4\n",
        "\n",
        "\n",
        "target4_train_data=[]\n",
        "for i in range(target1_train_len+target2_train_len+target3_train_len,target1_train_len+target2_train_len+target3_train_len+target4_train_len):\n",
        "    target4_train_data.append(data_train_target4[\"Tweet\"][i])\n",
        "    \n",
        "    \n",
        "print(len(target4_train_data))\n",
        "\n",
        "target4_train_data=convert_lowercase(target4_train_data)\n",
        "target4_train_data=remove_digits(target4_train_data)\n",
        "target4_train_data=remove_punctuations(target4_train_data)\n",
        "target4_train_data=tokenize_data(target4_train_data)\n",
        "target4_train_data=remove_stopwords(target4_train_data)\n",
        "target4_train_data=lemmatize(target4_train_data)\n",
        "target4_train_data=make_string(target4_train_data)\n",
        "\n",
        "\n",
        "target4_test_data=[]\n",
        "for i in range(target1_test_len+target2_test_len+target3_test_len,target1_test_len+target2_test_len+target3_test_len+target4_test_len):\n",
        "    target4_test_data.append(data_test_target4[\"Tweet\"][i])\n",
        "    \n",
        "target4_test_data=convert_lowercase(target4_test_data)\n",
        "target4_test_data=remove_digits(target4_test_data)\n",
        "target4_test_data=remove_punctuations(target4_test_data)\n",
        "target4_test_data=tokenize_data(target4_test_data)\n",
        "target4_test_data=remove_stopwords(target4_test_data)\n",
        "target4_test_data=lemmatize(target4_test_data)\n",
        "target4_test_data=make_string(target4_test_data)\n",
        "\n",
        "\n",
        "y1=[]\n",
        "for i in range(target1_train_len+target2_train_len+target3_train_len,target1_train_len+target2_train_len+target3_train_len+target4_train_len):\n",
        "    y1.append(data_train_target4[\"Stance\"][i])\n",
        "  \n",
        "print(\"Y1: \",len(y1))\n",
        "\n",
        "target4_full_data=[]\n",
        "target4_full_data.extend(target4_train_data)\n",
        "target4_full_data.extend(target4_test_data)\n",
        "\n",
        "\n",
        "# tokenize the words in the texts\n",
        "max_nb_words=2000\n",
        "tokenizer = Tokenizer(num_words = max_nb_words) \n",
        "tokenizer.fit_on_texts(target4_full_data) \n",
        "# convert each review text into a sequence of word-indices\n",
        "matrix_word_indices = tokenizer.texts_to_sequences(target4_full_data)\n",
        "# the dictionary for mapping a word to an index\n",
        "dictionary_word_index = tokenizer.word_index\n",
        "\n",
        "print(len(dictionary_word_index))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# pad each review text to a fixed length of word sequence\n",
        "num_words_per_review=20\n",
        "matrix_word_indices_fixed_length = pad_sequences(matrix_word_indices, maxlen = num_words_per_review)\n",
        "# convert to numpy arrays \n",
        "data = np.array(matrix_word_indices_fixed_length)\n",
        "\n",
        "print(matrix_word_indices_fixed_length.shape)\n",
        "\n",
        "# allocation of training data and validation data\n",
        "x_train = data[:len(data_train_target4)]\n",
        "x_test = data[len(data_train_target4):]\n",
        "\n",
        "y_train=np.zeros(shape=(target4_train_len,3))\n",
        "\n",
        "print(\"y_train: \",len(y_train))\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  if(y1[i]=='AGAINST'):\n",
        "    y_train[i][0]=1;\n",
        "  elif(y1[i]=='FAVOR'):\n",
        "    y_train[i][1]=1;\n",
        "  else:\n",
        "    y_train[i][2]=1;\n",
        "\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "\n",
        "\n",
        "# prepare embedding matrix\n",
        "num_words = len(dictionary_word_index)\n",
        "# embedding_matrix[0] is a all-zero vector representing no word\n",
        "embedding_matrix = np.zeros((num_words+1, 300)) \n",
        "\n",
        "init_vector=np.zeros(300)\n",
        "\n",
        "\n",
        "unknown_words=[]\n",
        "for word, index in dictionary_word_index.items():\n",
        "    if index > max_nb_words:\n",
        "        continue \n",
        "    # get the glove vector for the word\n",
        "    try:\n",
        "      word_vector = word2vec.wv[word]\n",
        "      if word_vector is not None: \n",
        "          embedding_matrix[index] = word_vector\n",
        "    except:\n",
        "      unknown_words.append(word)\n",
        "      #print(word)\n",
        "      embedding_matrix[index] = init_vector\n",
        "  \n",
        "print(\"The no. of unknown words: \", len(unknown_words))\n",
        "\n",
        "print(len(embedding_matrix))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "639\n",
            "Y1:  639\n",
            "3353\n",
            "(934, 20)\n",
            "y_train:  639\n",
            "639\n",
            "295\n",
            "The no. of unknown words:  470\n",
            "3354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWh2SYA4_Q9z",
        "colab_type": "code",
        "outputId": "82a0a730-6c1c-4868-8af3-45e14bcf2bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define the model\n",
        "# layer 0: the input layer\n",
        "num_words_per_tweet=20\n",
        "sequence_input = Input(shape=(num_words_per_tweet,), dtype='int32')\n",
        "# layer-1: the embedding layer\n",
        "embedding_layer = Embedding(num_words+1, 300, weights=[embedding_matrix], input_length=num_words_per_tweet, trainable=True)\n",
        "embedded_output = embedding_layer(sequence_input)\n",
        "# layer-2: the first convolution layer\n",
        "x = Conv1D(nb_filter=128, filter_length=2, activation='relu')(embedded_output)\n",
        "# layer-3: the first pooling layer\n",
        "x = MaxPooling1D(pool_length=2)(x)\n",
        "# layer-4: the second convolution layer\n",
        "x = Conv1D(128, 2, activation='relu')(x)\n",
        "# layer-5: the second pooling layer\n",
        "x = MaxPooling1D(pool_length = 2)(x)\n",
        "# flatten layer\n",
        "x = Flatten()(x)\n",
        "# layer-6: the first dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-7: the second dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-8: the output layer\n",
        "final_output = Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "# define the model\n",
        "model2 = Model(input=sequence_input, output=final_output)\n",
        "\n",
        "#view model\n",
        "print(model2.summary())\n",
        "\n",
        "# compile the model\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
        "# training and validation\n",
        "print('Training the model ...')\n",
        "model2.fit(x=x_train, y=y_train, nb_epoch=15, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 20, 300)           1006200   \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 19, 128)           76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 8, 128)            32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,198,587\n",
            "Trainable params: 1,198,587\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "639/639 [==============================] - 0s 597us/step - loss: 1.0403 - acc: 0.4898\n",
            "Epoch 2/15\n",
            "639/639 [==============================] - 0s 382us/step - loss: 0.9292 - acc: 0.5649\n",
            "Epoch 3/15\n",
            "639/639 [==============================] - 0s 407us/step - loss: 0.8379 - acc: 0.5477\n",
            "Epoch 4/15\n",
            "639/639 [==============================] - 0s 391us/step - loss: 0.6219 - acc: 0.6886\n",
            "Epoch 5/15\n",
            "639/639 [==============================] - 0s 386us/step - loss: 0.5667 - acc: 0.7919\n",
            "Epoch 6/15\n",
            "639/639 [==============================] - 0s 384us/step - loss: 0.2079 - acc: 0.9703\n",
            "Epoch 7/15\n",
            "639/639 [==============================] - 0s 394us/step - loss: 0.2395 - acc: 0.9171\n",
            "Epoch 8/15\n",
            "639/639 [==============================] - 0s 401us/step - loss: 0.0444 - acc: 0.9937\n",
            "Epoch 9/15\n",
            "639/639 [==============================] - 0s 396us/step - loss: 0.0148 - acc: 0.9984\n",
            "Epoch 10/15\n",
            "639/639 [==============================] - 0s 387us/step - loss: 0.0088 - acc: 0.9984\n",
            "Epoch 11/15\n",
            "639/639 [==============================] - 0s 405us/step - loss: 0.0091 - acc: 0.9953\n",
            "Epoch 12/15\n",
            "639/639 [==============================] - 0s 391us/step - loss: 0.0048 - acc: 0.9984\n",
            "Epoch 13/15\n",
            "639/639 [==============================] - 0s 398us/step - loss: 0.0038 - acc: 0.9984\n",
            "Epoch 14/15\n",
            "639/639 [==============================] - 0s 399us/step - loss: 0.0032 - acc: 0.9984\n",
            "Epoch 15/15\n",
            "639/639 [==============================] - 0s 420us/step - loss: 0.0027 - acc: 0.9984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f557c08e048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GztixKvs_ZIA",
        "colab_type": "code",
        "outputId": "21567715-1c74-4895-c31a-c1b5f115dcff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_test_answers=pd.read_csv('drive/My Drive/dataset_test_answers.csv')\n",
        "data_test_target4_answers=data_test_answers[data_test_answers[\"Target\"]==\"Hillary Clinton\"]\n",
        "y_ground_truth=data_test_target4_answers[\"Stance\"].values;\n",
        "\n",
        "\n",
        "y_test=np.zeros(len(data_test_target4))\n",
        "\n",
        "for i in range(len(y_ground_truth)):\n",
        "  if(y_ground_truth[i]=='AGAINST'):\n",
        "    y_test[i]=0;\n",
        "  elif(y_ground_truth[i]=='FAVOR'):\n",
        "    y_test[i]=1;\n",
        "  else:\n",
        "    y_test[i]=2;\n",
        "\n",
        "\n",
        "y_pred=model2.predict(x_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y=np.zeros(len(y_pred))\n",
        "for i in range(len(y_pred)):\n",
        "  y[i]=np.argmax(y_pred[i])\n",
        "\n",
        "print(y_test)\n",
        "print(y)\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "print(f1_score(y,y_test,average='macro'))\n",
        "print(precision_score(y,y_test,average='macro'))\n",
        "print(recall_score(y,y_test,average='macro'))\n",
        "print(accuracy_score(y,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.99502778e-01 1.82311339e-08 5.62471740e-08]\n",
            " [1.94254458e-01 5.73747456e-02 2.07147062e-01]\n",
            " [1.96396261e-01 4.82699275e-03 1.33617687e-05]\n",
            " [1.59476995e-02 1.36827528e-02 6.67095184e-04]\n",
            " [7.53741145e-01 4.19823045e-05 5.87811301e-05]\n",
            " [7.76960254e-01 1.16473362e-04 1.81505004e-06]\n",
            " [5.38189411e-02 8.87878414e-05 1.77936256e-02]\n",
            " [2.60030031e-02 5.19543886e-04 1.11278445e-01]\n",
            " [8.42754722e-01 9.12444739e-06 1.02768026e-05]\n",
            " [9.62349057e-01 5.93464320e-05 8.40666053e-06]\n",
            " [9.77709055e-01 6.75407227e-06 2.59505050e-05]\n",
            " [2.75975764e-02 1.94840133e-02 1.03854179e-01]\n",
            " [8.47435474e-01 1.14238262e-03 4.87139141e-06]\n",
            " [9.02150571e-02 2.56031752e-03 1.03523880e-01]\n",
            " [4.96215492e-01 1.19725764e-02 2.84077068e-05]\n",
            " [7.82671452e-01 4.34726477e-04 2.43127346e-04]\n",
            " [9.99438643e-01 6.55187335e-08 1.78836963e-08]\n",
            " [8.55516851e-01 1.08624808e-05 1.44944661e-05]\n",
            " [9.99605656e-01 3.88435240e-08 3.88094570e-08]\n",
            " [6.91772997e-02 2.34286994e-01 7.79062520e-06]\n",
            " [2.95582414e-03 1.05902851e-04 6.51378577e-05]\n",
            " [8.83823097e-01 2.58583214e-06 2.75801824e-07]\n",
            " [3.10257077e-03 1.54982507e-02 4.52369452e-04]\n",
            " [5.71673334e-01 4.25866246e-03 9.34489508e-05]\n",
            " [9.99366403e-01 2.33041149e-07 2.94676738e-07]\n",
            " [3.78963351e-03 1.25885010e-03 1.51854272e-06]\n",
            " [7.85595179e-03 4.75415587e-03 5.17055511e-01]\n",
            " [9.93745565e-01 5.50054779e-07 1.94374297e-06]\n",
            " [3.56900692e-01 2.19172239e-03 2.38506198e-02]\n",
            " [1.41219007e-05 3.38419378e-01 1.24394894e-04]\n",
            " [1.00189149e-02 6.48830175e-01 1.39601179e-05]\n",
            " [1.10724568e-03 1.88989937e-01 7.69166800e-05]\n",
            " [8.07611763e-01 2.31117010e-04 3.34434844e-05]\n",
            " [6.77156448e-03 1.14913553e-01 1.64130452e-05]\n",
            " [8.81308556e-01 7.75814056e-04 1.70515563e-07]\n",
            " [8.34603310e-01 9.55804535e-06 8.12838334e-05]\n",
            " [6.96170509e-01 3.63594881e-05 1.06469335e-04]\n",
            " [9.87335801e-01 4.33125715e-05 3.75581549e-05]\n",
            " [6.87547326e-01 1.02509558e-02 3.73363495e-04]\n",
            " [1.72372162e-02 7.07298517e-04 5.58614731e-02]\n",
            " [9.40031409e-02 1.02162317e-04 3.72141600e-04]\n",
            " [9.09728050e-01 5.63500253e-05 2.77268391e-05]\n",
            " [1.53991580e-03 1.40303373e-03 4.75993752e-03]\n",
            " [9.94574189e-01 4.90369018e-07 1.02003675e-07]\n",
            " [1.39127165e-01 1.57588720e-03 1.67563558e-03]\n",
            " [1.86884999e-02 1.81859732e-03 1.71905458e-01]\n",
            " [7.80352950e-03 1.39445066e-04 7.15109706e-03]\n",
            " [1.13834769e-01 2.35968828e-03 7.33800530e-02]\n",
            " [6.58498526e-01 2.27928162e-04 3.33963144e-05]\n",
            " [1.22575380e-04 1.10010642e-05 3.79417717e-01]\n",
            " [1.37647718e-01 1.34709477e-03 1.97231770e-04]\n",
            " [8.66546035e-02 1.82619691e-03 6.83605671e-04]\n",
            " [9.99251604e-01 3.57846055e-08 1.95942304e-10]\n",
            " [2.49882936e-02 5.36382198e-04 2.63479501e-01]\n",
            " [2.23636627e-04 9.91731882e-04 1.22991860e-01]\n",
            " [3.25258851e-01 4.97844815e-03 3.28115490e-09]\n",
            " [1.87152624e-03 9.37402248e-04 5.80172241e-02]\n",
            " [5.25653660e-02 7.58588314e-04 1.10829431e-04]\n",
            " [9.12924170e-01 6.08243727e-06 7.19129775e-06]\n",
            " [7.87065864e-01 3.70909365e-05 1.26779079e-04]\n",
            " [1.57561898e-03 2.47055292e-03 3.02347362e-01]\n",
            " [8.04361582e-01 9.11829338e-05 2.28881836e-03]\n",
            " [1.07862294e-01 1.42939261e-05 1.95344090e-02]\n",
            " [9.48788643e-01 1.15941509e-06 6.55993574e-07]\n",
            " [7.07247794e-01 8.62424640e-05 4.79423704e-07]\n",
            " [8.56995583e-04 1.10182256e-04 6.77858651e-01]\n",
            " [6.40004277e-02 2.24143267e-04 1.72065198e-02]\n",
            " [6.48671091e-02 3.62545252e-03 6.20901585e-04]\n",
            " [6.58529997e-03 3.30885649e-02 1.81141496e-03]\n",
            " [5.58531284e-03 3.70952184e-05 4.18646276e-01]\n",
            " [1.30247951e-01 6.90793991e-03 8.07404518e-04]\n",
            " [2.82375216e-02 1.19161606e-03 9.63389874e-02]\n",
            " [9.22368944e-01 4.56701900e-06 1.88096635e-07]\n",
            " [9.06443000e-01 3.36468838e-05 1.32530928e-04]\n",
            " [7.58257747e-01 8.12848448e-05 7.61073625e-06]\n",
            " [8.12839866e-01 4.04527464e-06 1.36464834e-04]\n",
            " [9.95140672e-01 7.00167675e-06 1.47692972e-05]\n",
            " [7.13261962e-03 4.77596819e-02 2.25305557e-04]\n",
            " [7.64778256e-01 8.04388110e-05 1.80721283e-04]\n",
            " [9.98593867e-02 2.70259082e-02 8.46016407e-03]\n",
            " [1.35805309e-02 1.31725639e-01 5.21050394e-02]\n",
            " [2.95026302e-02 5.54164350e-02 1.44183636e-04]\n",
            " [9.47954178e-01 1.68211245e-05 3.99244382e-05]\n",
            " [6.06414139e-01 8.72164965e-04 3.74108553e-04]\n",
            " [2.32416481e-01 3.10733914e-03 9.75725055e-03]\n",
            " [4.44577336e-02 2.87270099e-01 2.07578887e-05]\n",
            " [9.90023673e-01 8.72857345e-06 1.94003724e-06]\n",
            " [2.94647515e-02 2.02208757e-04 6.38684630e-03]\n",
            " [7.39286959e-01 2.02894211e-04 1.41280694e-07]\n",
            " [8.38136673e-01 7.77307796e-05 7.83752876e-06]\n",
            " [4.66734171e-04 5.76733053e-02 5.68509102e-04]\n",
            " [1.16196665e-04 9.77903605e-04 4.09603626e-01]\n",
            " [8.22561502e-01 9.08598849e-06 2.51561403e-04]\n",
            " [4.21986073e-01 7.23332167e-04 1.25458837e-03]\n",
            " [1.28828347e-01 4.98682261e-04 3.61108780e-03]\n",
            " [4.93323803e-03 6.78232312e-01 6.59227808e-05]\n",
            " [2.93219268e-01 1.29067898e-03 6.33603334e-03]\n",
            " [9.87425864e-01 6.95572135e-06 7.21497941e-07]\n",
            " [1.22741956e-04 3.02544236e-03 7.98404217e-04]\n",
            " [7.73370266e-04 6.23397291e-01 7.17685907e-05]\n",
            " [6.12355471e-02 2.97677755e-01 1.65905654e-02]\n",
            " [1.80885196e-03 1.26922578e-01 3.63433361e-03]\n",
            " [1.89363956e-04 7.55582809e-01 4.90076382e-05]\n",
            " [1.79657847e-01 6.77859783e-03 8.04775937e-06]\n",
            " [9.51430321e-01 3.13818668e-06 8.51506120e-05]\n",
            " [8.80439937e-01 1.39200620e-05 2.00808048e-04]\n",
            " [1.79657847e-01 6.77859783e-03 8.04775937e-06]\n",
            " [4.51206267e-02 1.43125355e-02 2.81279341e-07]\n",
            " [1.84971988e-02 4.82743979e-03 5.46972752e-02]\n",
            " [9.40041006e-01 1.22152178e-05 4.63418282e-09]\n",
            " [9.76795793e-01 5.52029906e-06 7.82379857e-07]\n",
            " [1.19332641e-01 9.83032733e-05 6.65217638e-04]\n",
            " [8.61285746e-01 3.52321877e-05 4.00967583e-05]\n",
            " [3.21036398e-01 1.67983472e-02 5.15612192e-05]\n",
            " [1.63313746e-03 1.08185500e-01 1.36250592e-05]\n",
            " [1.49858534e-01 4.14609909e-03 2.88684678e-05]\n",
            " [9.37048614e-01 7.22914934e-04 2.73585320e-04]\n",
            " [6.05348945e-02 1.55293345e-01 2.95847654e-04]\n",
            " [1.00404501e-01 7.68288970e-03 1.62979156e-01]\n",
            " [7.22486854e-01 5.83529472e-04 8.13739121e-08]\n",
            " [3.26229632e-01 5.93192408e-06 9.75805160e-05]\n",
            " [8.43593001e-01 2.54739025e-05 5.60965673e-05]\n",
            " [1.04532748e-01 2.62134492e-01 5.12702263e-06]\n",
            " [5.60108423e-01 6.20451570e-03 2.19881877e-05]\n",
            " [9.97262955e-01 2.28750582e-06 2.70847123e-10]\n",
            " [1.80155039e-04 3.09386849e-02 1.44259930e-02]\n",
            " [9.98019040e-01 2.46682283e-08 3.65549688e-08]\n",
            " [6.16788864e-04 3.27855349e-04 6.36259065e-05]\n",
            " [1.73535943e-03 1.12308269e-04 3.98633182e-02]\n",
            " [1.53252482e-03 8.13537836e-03 6.04331493e-04]\n",
            " [1.61963999e-02 9.75254807e-06 1.89141838e-06]\n",
            " [1.24897361e-02 5.50995052e-01 3.02326679e-03]\n",
            " [9.99590635e-01 6.33368487e-08 1.46758282e-07]\n",
            " [9.99894559e-01 4.53836480e-09 6.21117380e-10]\n",
            " [4.47240472e-03 1.73621178e-02 9.74299201e-06]\n",
            " [5.56349754e-04 5.24877250e-01 1.06258594e-05]\n",
            " [1.24639273e-01 1.82503462e-03 5.65975904e-03]\n",
            " [8.58634412e-02 1.33451521e-02 1.42888218e-01]\n",
            " [9.90946531e-01 8.50584547e-06 3.75504205e-05]\n",
            " [3.35239768e-01 6.44233823e-03 5.61229499e-05]\n",
            " [1.24437720e-01 1.33395195e-03 8.52959454e-02]\n",
            " [9.79602933e-01 1.02679560e-05 2.21771131e-07]\n",
            " [9.72828031e-01 2.32897182e-05 9.37623659e-11]\n",
            " [7.00458884e-03 7.97376037e-03 1.57117844e-04]\n",
            " [3.23942602e-02 4.31684464e-01 1.14673376e-03]\n",
            " [1.40294433e-03 1.10864937e-02 5.45591116e-04]\n",
            " [7.80125678e-01 1.62054530e-05 6.33776188e-04]\n",
            " [7.34238088e-01 5.69081306e-03 1.53290830e-06]\n",
            " [1.07914686e-01 3.17852795e-02 1.89878106e-01]\n",
            " [9.64885712e-01 3.01570321e-06 1.14131108e-05]\n",
            " [9.83370721e-01 4.28273609e-07 9.59791123e-07]\n",
            " [8.50622296e-01 9.58988749e-05 3.64934380e-07]\n",
            " [9.82643008e-01 2.15916880e-05 9.24413507e-06]\n",
            " [2.37652957e-02 1.96078420e-03 1.57493353e-03]\n",
            " [1.41426474e-01 4.76015806e-02 6.72435164e-02]\n",
            " [5.66083193e-02 2.33423710e-03 8.25027823e-02]\n",
            " [6.13571405e-02 1.83680654e-03 1.73032284e-04]\n",
            " [9.23887849e-01 3.64520997e-06 7.98689434e-05]\n",
            " [5.41507602e-02 1.12538783e-06 2.46927142e-03]\n",
            " [9.64150429e-01 6.73125123e-06 2.65849631e-05]\n",
            " [1.25658214e-01 4.32547033e-02 8.29480588e-02]\n",
            " [9.94259179e-01 1.21866572e-06 3.25893865e-07]\n",
            " [3.20802689e-01 4.35709953e-04 4.81974837e-07]\n",
            " [9.99969363e-01 1.39315684e-10 1.14275568e-10]\n",
            " [4.62603807e-01 5.29184836e-05 2.39756791e-05]\n",
            " [1.69278979e-01 9.35444236e-03 7.69878989e-06]\n",
            " [3.41388583e-03 8.15055246e-05 8.80454779e-02]\n",
            " [1.63522363e-03 1.25807524e-03 6.06650710e-02]\n",
            " [9.41189706e-01 3.25472547e-06 2.60943943e-05]\n",
            " [5.75441420e-01 1.58518553e-04 1.11009992e-08]\n",
            " [1.55215889e-01 1.55151188e-02 8.61361623e-02]\n",
            " [2.26855278e-04 2.24718451e-03 2.41434366e-01]\n",
            " [1.90055907e-01 3.10896337e-02 1.58545256e-01]\n",
            " [1.41405463e-02 2.86936760e-04 2.33654410e-01]\n",
            " [9.99429345e-01 2.43933478e-08 2.31323538e-09]\n",
            " [5.38659096e-01 3.37570906e-04 1.04262014e-07]\n",
            " [9.75394487e-01 5.92538800e-06 1.12398908e-08]\n",
            " [9.04521763e-01 3.37918500e-05 1.70877938e-05]\n",
            " [9.99979019e-01 2.32134464e-10 4.37271434e-11]\n",
            " [9.98969674e-01 4.94097456e-08 1.43857495e-08]\n",
            " [1.45524740e-04 6.49414659e-02 1.35362148e-04]\n",
            " [3.27135026e-02 2.34599393e-05 2.67897546e-02]\n",
            " [5.58531284e-03 3.70952184e-05 4.18646276e-01]\n",
            " [1.06047273e-01 2.57637203e-02 1.73540235e-01]\n",
            " [1.68731809e-03 6.34781420e-02 3.12639786e-05]\n",
            " [1.27496809e-01 6.05711341e-03 1.26722425e-01]\n",
            " [1.11086071e-02 1.11609388e-05 8.73770118e-02]\n",
            " [9.70464230e-01 8.50217106e-08 1.38298644e-08]\n",
            " [9.93937254e-01 7.96295978e-07 3.03387378e-06]\n",
            " [8.10340643e-02 3.79112363e-03 7.16507566e-05]\n",
            " [9.86975729e-01 1.47144169e-06 3.38729308e-07]\n",
            " [7.79062510e-03 9.66173410e-03 5.75560331e-03]\n",
            " [3.04620844e-05 7.63275504e-01 2.58671389e-05]\n",
            " [3.95828485e-03 1.03111595e-01 6.68501854e-03]\n",
            " [9.33355868e-01 7.80612230e-04 1.35210903e-05]\n",
            " [1.52660549e-01 8.15495849e-03 3.15183797e-07]\n",
            " [9.32496846e-01 7.09325075e-04 9.27326037e-05]\n",
            " [1.19098440e-05 4.64242697e-03 2.32309103e-04]\n",
            " [2.25874066e-01 7.61978226e-05 4.16162610e-03]\n",
            " [7.50422239e-01 5.19603491e-04 4.86527881e-07]\n",
            " [8.32262516e-01 1.54763460e-04 3.37928534e-04]\n",
            " [7.75516272e-01 3.31811839e-06 1.44364158e-05]\n",
            " [2.03866035e-01 7.26610422e-04 1.77369782e-06]\n",
            " [9.99881446e-01 1.18772849e-08 5.63280700e-10]\n",
            " [9.89426732e-01 8.15824751e-06 1.14309591e-06]\n",
            " [9.57226753e-01 1.66540813e-05 1.99523788e-06]\n",
            " [9.98474002e-01 5.19461935e-07 3.14624288e-07]\n",
            " [9.30638611e-02 4.99802828e-03 1.71419978e-03]\n",
            " [7.97540903e-01 2.85381079e-03 4.43547964e-04]\n",
            " [5.61736226e-01 6.35653734e-04 2.02326517e-10]\n",
            " [3.44768822e-01 8.21173191e-04 8.52263656e-06]\n",
            " [1.23106539e-02 5.82754612e-04 1.51523650e-01]\n",
            " [9.99969244e-01 4.16840867e-11 8.47723697e-11]\n",
            " [3.81373823e-01 3.46243382e-04 8.36831331e-03]\n",
            " [5.37551939e-02 2.70873308e-04 2.72849202e-03]\n",
            " [1.87560916e-02 9.81770754e-02 1.57296658e-04]\n",
            " [9.61225867e-01 5.32208105e-06 1.59911033e-05]\n",
            " [9.97553170e-01 6.21044620e-08 2.02698693e-08]\n",
            " [9.95476067e-01 7.73382112e-07 3.31943340e-07]\n",
            " [1.61972642e-03 2.30818987e-04 4.25052881e-01]\n",
            " [9.94140267e-01 2.98512191e-07 1.90100891e-09]\n",
            " [5.76379418e-01 2.93850899e-04 6.82482641e-05]\n",
            " [9.85697865e-01 2.47897788e-06 5.01092812e-09]\n",
            " [2.85893679e-04 4.12835181e-02 1.89847451e-05]\n",
            " [7.84128904e-04 7.68004358e-02 1.95036919e-05]\n",
            " [1.17039859e-01 1.88313723e-02 1.39821470e-02]\n",
            " [8.87234569e-01 1.09221692e-05 2.52214363e-07]\n",
            " [4.74256873e-01 7.12857354e-06 3.19540501e-04]\n",
            " [9.63003635e-01 4.76074492e-05 1.33246183e-04]\n",
            " [6.53699994e-01 8.82089138e-04 3.29729915e-03]\n",
            " [2.78329849e-03 3.26688451e-06 1.02063119e-01]\n",
            " [2.40069785e-05 2.88692117e-03 7.50449002e-02]\n",
            " [7.49346614e-01 8.50820561e-06 7.34493369e-06]\n",
            " [8.71316016e-01 1.66466832e-03 5.15858119e-05]\n",
            " [9.77921963e-01 3.31360593e-06 1.63310645e-08]\n",
            " [9.32793736e-01 1.10019391e-06 1.68312897e-06]\n",
            " [5.52806497e-01 7.22825527e-04 1.17629832e-04]\n",
            " [9.53741372e-02 2.90904313e-06 9.16348836e-06]\n",
            " [1.49816275e-04 9.52124596e-04 5.70233524e-01]\n",
            " [9.39577162e-01 2.22623348e-04 1.81186783e-06]\n",
            " [9.77478862e-01 1.82802907e-07 5.17437229e-07]\n",
            " [9.89890695e-01 6.24983250e-06 2.23414077e-06]\n",
            " [9.98784304e-01 2.40180839e-07 8.73842225e-07]\n",
            " [5.49291968e-01 7.00354576e-03 9.60263610e-03]\n",
            " [2.42206722e-01 1.28175318e-02 7.55429268e-03]\n",
            " [9.02321458e-01 7.64455108e-05 7.34441528e-06]\n",
            " [9.80141103e-01 9.73212627e-06 4.90910897e-05]\n",
            " [5.22258878e-03 6.94969296e-01 1.05839331e-06]\n",
            " [5.31414151e-03 6.24674559e-02 3.10087800e-02]\n",
            " [4.73141640e-01 1.01351738e-03 1.64240599e-03]\n",
            " [9.98755515e-01 3.38139614e-07 4.64497019e-09]\n",
            " [9.99378979e-01 3.05984464e-08 5.29056621e-09]\n",
            " [9.90701795e-01 4.17969204e-06 1.13092108e-06]\n",
            " [2.51948833e-04 5.83834827e-01 7.91525690e-06]\n",
            " [4.31597233e-04 1.51710510e-01 7.57919997e-06]\n",
            " [9.26120937e-01 4.33734385e-06 8.59277061e-05]\n",
            " [6.78204000e-02 3.50802839e-01 1.20306962e-04]\n",
            " [6.06843829e-03 2.90468931e-02 7.91043043e-04]\n",
            " [6.52662218e-02 7.70697296e-02 6.24935547e-06]\n",
            " [6.40442252e-01 2.08407640e-03 1.26659870e-04]\n",
            " [5.31804025e-01 2.17962265e-03 4.87621128e-06]\n",
            " [2.75297165e-02 5.64556122e-02 1.73459995e-07]\n",
            " [2.56857276e-03 1.35077298e-01 3.40044498e-04]\n",
            " [8.41091394e-01 2.66671181e-04 5.54259168e-06]\n",
            " [9.55806971e-01 2.84769012e-05 2.34037638e-04]\n",
            " [3.07211280e-01 1.00644784e-05 9.51260328e-04]\n",
            " [3.14587355e-03 3.88629041e-06 2.95174241e-01]\n",
            " [7.68012881e-01 9.49352980e-04 1.05857052e-05]\n",
            " [9.96892810e-01 6.86643830e-07 1.52576014e-08]\n",
            " [1.23576522e-02 1.48359995e-05 1.24414474e-01]\n",
            " [5.58531284e-03 3.70952184e-05 4.18646276e-01]\n",
            " [4.26968932e-02 8.62747431e-04 7.14386106e-02]\n",
            " [1.18679404e-02 1.68323517e-04 3.30853403e-01]\n",
            " [1.82762742e-03 1.05958410e-04 5.48539996e-01]\n",
            " [8.04295659e-01 3.69972622e-06 5.86182239e-07]\n",
            " [1.76979184e-01 7.50067147e-06 3.55780125e-04]\n",
            " [5.63168645e-01 9.45690274e-03 1.01030501e-07]\n",
            " [1.07747316e-03 3.59803438e-04 6.95093036e-01]\n",
            " [3.59832346e-02 9.28945883e-05 7.12985782e-10]\n",
            " [3.54057848e-01 2.31377780e-02 2.00452610e-06]\n",
            " [8.95329714e-02 1.45955682e-02 6.58468434e-06]\n",
            " [8.86672735e-03 2.61217356e-04 3.97407979e-01]\n",
            " [9.93845463e-01 5.29633917e-06 1.31020533e-05]\n",
            " [3.44065994e-01 6.18618727e-03 5.28589189e-02]\n",
            " [1.89774930e-01 9.87726450e-03 5.27318070e-06]\n",
            " [1.37220323e-01 2.98982859e-03 4.08492415e-05]\n",
            " [9.61114168e-02 7.04327226e-03 2.10545977e-07]\n",
            " [3.44818830e-03 3.81373763e-02 7.85085559e-03]\n",
            " [1.34974718e-03 1.78962946e-04 1.10311598e-01]\n",
            " [3.94967198e-03 8.60866904e-03 4.28681014e-05]\n",
            " [5.65887690e-02 8.61257315e-03 9.80198383e-04]\n",
            " [4.54125613e-01 6.00367785e-03 3.64308655e-02]\n",
            " [1.53558403e-01 8.69065523e-04 1.23866294e-05]\n",
            " [9.20482635e-01 5.93569566e-05 3.16155893e-05]\n",
            " [5.32602309e-04 1.18071410e-04 1.31031007e-01]]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
            " 0. 2. 0. 2. 0. 2. 2. 0. 0. 0. 2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 1. 2. 2. 2.\n",
            " 1. 2. 2. 2. 2. 2. 1. 0. 2. 1. 2. 2. 1. 1. 1. 2. 1. 0. 2. 1. 2. 0. 2. 1.\n",
            " 1. 0. 1. 1. 0. 1. 1. 2. 2. 2. 0. 1. 2. 1. 0. 2. 2. 0. 1. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 2. 0. 1. 2. 1. 0. 1. 0. 0. 2. 1. 2. 2. 2. 0. 2. 0. 0. 0.\n",
            " 1. 0. 1. 0. 2. 0. 0. 2. 0. 2. 2. 0. 1. 2. 0. 0. 2. 0. 1. 0. 1. 0. 2. 1.\n",
            " 1. 0. 0. 0. 2. 2. 0. 0. 0. 2. 0. 0. 0. 2. 2. 2. 0. 2. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 2. 1. 2. 0. 2. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 2. 2. 1.\n",
            " 2. 0. 0. 2. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 2. 2. 2. 2. 0. 0. 2. 0. 2. 1. 0. 0. 2. 0. 2. 0. 0. 0. 2.\n",
            " 2. 0. 1. 2. 1. 0. 2.]\n",
            "[0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 2. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 2. 0. 0.\n",
            " 0. 2. 0. 0. 0. 2. 2. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 2. 0. 0. 1. 2. 0. 2.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 2. 0. 0. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 1. 2. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 2. 1. 0. 1. 0. 0. 1. 1. 0. 2. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2.\n",
            " 0. 0. 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 1. 0. 2. 2. 1. 0. 2. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1.\n",
            " 0. 0. 0. 2. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 2. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0.\n",
            " 0. 0. 2. 0. 0. 2. 2. 2. 2. 2. 0. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1.\n",
            " 2. 1. 0. 0. 0. 0. 2.]\n",
            "0.504275585223481\n",
            "0.5026502352083747\n",
            "0.5294209225978949\n",
            "0.5898305084745763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O0VESMCAeTh",
        "colab_type": "code",
        "outputId": "15801a68-30e3-40a4-aa02-6cd14095eeac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# for Target 5\n",
        "\n",
        "\n",
        "target5_train_data=[]\n",
        "for i in range(target1_train_len+target2_train_len+target3_train_len+target4_train_len,target1_train_len+target2_train_len+target3_train_len+target4_train_len+target5_train_len):\n",
        "    target5_train_data.append(data_train_target5[\"Tweet\"][i])\n",
        "    \n",
        "    \n",
        "print(len(target5_train_data))\n",
        "\n",
        "target5_train_data=convert_lowercase(target5_train_data)\n",
        "target5_train_data=remove_digits(target5_train_data)\n",
        "target5_train_data=remove_punctuations(target5_train_data)\n",
        "target5_train_data=tokenize_data(target5_train_data)\n",
        "target5_train_data=remove_stopwords(target5_train_data)\n",
        "target5_train_data=lemmatize(target5_train_data)\n",
        "target5_train_data=make_string(target5_train_data)\n",
        "\n",
        "\n",
        "target5_test_data=[]\n",
        "for i in range(target1_test_len+target2_test_len+target3_test_len+target4_test_len,target1_test_len+target2_test_len+target3_test_len+target4_test_len+target5_test_len):\n",
        "    target5_test_data.append(data_test_target5[\"Tweet\"][i])\n",
        "    \n",
        "target5_test_data=convert_lowercase(target5_test_data)\n",
        "target5_test_data=remove_digits(target5_test_data)\n",
        "target5_test_data=remove_punctuations(target5_test_data)\n",
        "target5_test_data=tokenize_data(target5_test_data)\n",
        "target5_test_data=remove_stopwords(target5_test_data)\n",
        "target5_test_data=lemmatize(target5_test_data)\n",
        "target5_test_data=make_string(target5_test_data)\n",
        "\n",
        "\n",
        "y1=[]\n",
        "for i in range(target1_train_len+target2_train_len+target3_train_len+target4_train_len,target1_train_len+target2_train_len+target3_train_len+target4_train_len+target5_train_len):\n",
        "    y1.append(data_train_target5[\"Stance\"][i])\n",
        "  \n",
        "print(\"Y1: \",len(y1))\n",
        "\n",
        "target5_full_data=[]\n",
        "target5_full_data.extend(target5_train_data)\n",
        "target5_full_data.extend(target5_test_data)\n",
        "\n",
        "\n",
        "# tokenize the words in the texts\n",
        "max_nb_words=2000\n",
        "tokenizer = Tokenizer(num_words = max_nb_words) \n",
        "tokenizer.fit_on_texts(target5_full_data) \n",
        "# convert each review text into a sequence of word-indices\n",
        "matrix_word_indices = tokenizer.texts_to_sequences(target5_full_data)\n",
        "# the dictionary for mapping a word to an index\n",
        "dictionary_word_index = tokenizer.word_index\n",
        "\n",
        "print(len(dictionary_word_index))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# pad each review text to a fixed length of word sequence\n",
        "num_words_per_review=20\n",
        "matrix_word_indices_fixed_length = pad_sequences(matrix_word_indices, maxlen = num_words_per_review)\n",
        "# convert to numpy arrays \n",
        "data = np.array(matrix_word_indices_fixed_length)\n",
        "\n",
        "print(matrix_word_indices_fixed_length.shape)\n",
        "\n",
        "# allocation of training data and validation data\n",
        "x_train = data[:len(data_train_target5)]\n",
        "x_test = data[len(data_train_target5):]\n",
        "\n",
        "y_train=np.zeros(shape=(target5_train_len,3))\n",
        "\n",
        "print(\"y_train: \",len(y_train))\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  if(y1[i]=='AGAINST'):\n",
        "    y_train[i][0]=1;\n",
        "  elif(y1[i]=='FAVOR'):\n",
        "    y_train[i][1]=1;\n",
        "  else:\n",
        "    y_train[i][2]=1;\n",
        "\n",
        "\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "\n",
        "\n",
        "# prepare embedding matrix\n",
        "num_words = len(dictionary_word_index)\n",
        "# embedding_matrix[0] is a all-zero vector representing no word\n",
        "embedding_matrix = np.zeros((num_words+1, 300)) \n",
        "\n",
        "init_vector=np.zeros(300)\n",
        "\n",
        "\n",
        "unknown_words=[]\n",
        "for word, index in dictionary_word_index.items():\n",
        "    if index > max_nb_words:\n",
        "        continue \n",
        "    # get the glove vector for the word\n",
        "    try:\n",
        "      word_vector = word2vec.wv[word]\n",
        "      if word_vector is not None: \n",
        "          embedding_matrix[index] = word_vector\n",
        "    except:\n",
        "      unknown_words.append(word)\n",
        "      #print(word)\n",
        "      embedding_matrix[index] = init_vector\n",
        "  \n",
        "print(\"The no. of unknown words: \", len(unknown_words))\n",
        "\n",
        "print(len(embedding_matrix))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "603\n",
            "Y1:  603\n",
            "3133\n",
            "(883, 20)\n",
            "y_train:  603\n",
            "603\n",
            "280\n",
            "The no. of unknown words:  468\n",
            "3134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c69nb8dUBwS8",
        "colab_type": "code",
        "outputId": "527ce84c-1297-4f9d-ce25-c6ef408b4696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# define the model\n",
        "# layer 0: the input layer\n",
        "num_words_per_tweet=20\n",
        "sequence_input = Input(shape=(num_words_per_tweet,), dtype='int32')\n",
        "# layer-1: the embedding layer\n",
        "embedding_layer = Embedding(num_words+1, 300, weights=[embedding_matrix], input_length=num_words_per_tweet, trainable=True)\n",
        "embedded_output = embedding_layer(sequence_input)\n",
        "# layer-2: the first convolution layer\n",
        "x = Conv1D(nb_filter=128, filter_length=2, activation='relu')(embedded_output)\n",
        "# layer-3: the first pooling layer\n",
        "x = MaxPooling1D(pool_length=2)(x)\n",
        "# layer-4: the second convolution layer\n",
        "x = Conv1D(128, 2, activation='relu')(x)\n",
        "# layer-5: the second pooling layer\n",
        "x = MaxPooling1D(pool_length = 2)(x)\n",
        "# flatten layer\n",
        "x = Flatten()(x)\n",
        "# layer-6: the first dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-7: the second dense layer\n",
        "x = Dense(output_dim = 128, activation='relu')(x)\n",
        "# layer-8: the output layer\n",
        "final_output = Dense(3, activation='sigmoid')(x)\n",
        "\n",
        "# define the model\n",
        "model2 = Model(input=sequence_input, output=final_output)\n",
        "\n",
        "#view model\n",
        "print(model2.summary())\n",
        "\n",
        "# compile the model\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
        "# training and validation\n",
        "print('Training the model ...')\n",
        "model2.fit(x=x_train, y=y_train, nb_epoch=15, batch_size=128, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=2)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 20, 300)           940200    \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 19, 128)           76928     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_13 (MaxPooling (None, 9, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 8, 128)            32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,132,587\n",
            "Trainable params: 1,132,587\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "603/603 [==============================] - 0s 659us/step - loss: 1.0056 - acc: 0.4876\n",
            "Epoch 2/15\n",
            "603/603 [==============================] - 0s 395us/step - loss: 0.9120 - acc: 0.6153\n",
            "Epoch 3/15\n",
            "603/603 [==============================] - 0s 417us/step - loss: 0.6031 - acc: 0.7612\n",
            "Epoch 4/15\n",
            "603/603 [==============================] - 0s 409us/step - loss: 0.5006 - acc: 0.7662\n",
            "Epoch 5/15\n",
            "603/603 [==============================] - 0s 445us/step - loss: 0.3726 - acc: 0.8474\n",
            "Epoch 6/15\n",
            "603/603 [==============================] - 0s 398us/step - loss: 0.1797 - acc: 0.9585\n",
            "Epoch 7/15\n",
            "603/603 [==============================] - 0s 457us/step - loss: 0.0659 - acc: 0.9867\n",
            "Epoch 8/15\n",
            "603/603 [==============================] - 0s 395us/step - loss: 0.3171 - acc: 0.9138\n",
            "Epoch 9/15\n",
            "603/603 [==============================] - 0s 409us/step - loss: 0.0440 - acc: 0.9950\n",
            "Epoch 10/15\n",
            "603/603 [==============================] - 0s 394us/step - loss: 0.0206 - acc: 0.9983\n",
            "Epoch 11/15\n",
            "603/603 [==============================] - 0s 380us/step - loss: 0.0114 - acc: 0.9983\n",
            "Epoch 12/15\n",
            "603/603 [==============================] - 0s 394us/step - loss: 0.0074 - acc: 1.0000\n",
            "Epoch 13/15\n",
            "603/603 [==============================] - 0s 404us/step - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 14/15\n",
            "603/603 [==============================] - 0s 423us/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 15/15\n",
            "603/603 [==============================] - 0s 411us/step - loss: 0.0024 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5587c7ab70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te0s8D5SB2o4",
        "colab_type": "code",
        "outputId": "873d53e5-dc66-4e3a-dc60-46d392748fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_test_answers=pd.read_csv('drive/My Drive/dataset_test_answers.csv')\n",
        "data_test_target5_answers=data_test_answers[data_test_answers[\"Target\"]==\"Legalization of Abortion\"]\n",
        "y_ground_truth=data_test_target5_answers[\"Stance\"].values;\n",
        "\n",
        "\n",
        "y_test=np.zeros(len(data_test_target5))\n",
        "\n",
        "for i in range(len(y_ground_truth)):\n",
        "  if(y_ground_truth[i]=='AGAINST'):\n",
        "    y_test[i]=0;\n",
        "  elif(y_ground_truth[i]=='FAVOR'):\n",
        "    y_test[i]=1;\n",
        "  else:\n",
        "    y_test[i]=2;\n",
        "\n",
        "\n",
        "y_pred=model2.predict(x_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y=np.zeros(len(y_pred))\n",
        "for i in range(len(y_pred)):\n",
        "  y[i]=np.argmax(y_pred[i])\n",
        "\n",
        "print(y_test)\n",
        "print(y)\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "print(f1_score(y,y_test,average='macro'))\n",
        "print(precision_score(y,y_test,average='macro'))\n",
        "print(recall_score(y,y_test,average='macro'))\n",
        "print(accuracy_score(y,y_test))\n",
        "print(confusion_matrix(y,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.95889103e-01 9.92275091e-06 2.89627189e-09]\n",
            " [2.61434436e-01 3.12231779e-02 1.89977884e-03]\n",
            " [9.96533573e-01 3.83648863e-10 1.04108978e-15]\n",
            " [9.58957553e-01 5.22887494e-05 6.55611757e-06]\n",
            " [9.61298347e-01 2.27782394e-07 1.27614003e-10]\n",
            " [1.65843964e-02 9.65031981e-03 3.51621310e-07]\n",
            " [3.61961126e-03 1.42875314e-03 8.48153908e-11]\n",
            " [5.00216186e-01 9.45558204e-05 2.97039747e-03]\n",
            " [9.55698609e-01 2.17379893e-05 2.80488189e-06]\n",
            " [8.49891901e-01 5.51640987e-04 5.96225262e-04]\n",
            " [2.96093434e-01 4.14916873e-03 2.93014348e-02]\n",
            " [1.80780888e-04 6.41381025e-01 2.53260136e-04]\n",
            " [6.70540035e-02 5.71742654e-03 2.77314186e-02]\n",
            " [7.44980574e-03 4.27612662e-03 3.58873358e-08]\n",
            " [1.90931559e-03 3.76043022e-01 4.60415758e-05]\n",
            " [9.90129650e-01 1.26211444e-05 3.11858548e-06]\n",
            " [9.83592629e-01 2.17172146e-06 2.20324779e-07]\n",
            " [9.64424670e-01 5.21762968e-06 1.75594828e-08]\n",
            " [5.80915809e-03 1.94353521e-01 6.20573759e-04]\n",
            " [5.67663789e-01 4.01631551e-05 3.65610708e-06]\n",
            " [2.61793554e-01 1.12536550e-03 4.35829163e-04]\n",
            " [9.98694539e-01 1.29624630e-10 8.23887603e-15]\n",
            " [9.95329261e-01 1.58672210e-05 4.70056466e-06]\n",
            " [1.66469812e-03 6.45262182e-01 2.63988972e-03]\n",
            " [5.74499369e-04 8.81910324e-04 9.50432122e-01]\n",
            " [2.88668275e-03 3.30393225e-01 7.49304891e-03]\n",
            " [3.19749117e-04 4.36088383e-01 2.65368108e-05]\n",
            " [5.97408414e-03 2.00066268e-02 3.42388153e-01]\n",
            " [2.29052693e-01 2.56585326e-06 7.12499764e-12]\n",
            " [5.29706478e-04 2.85506248e-04 9.61341977e-01]\n",
            " [2.04483695e-05 1.77681446e-04 9.64896798e-01]\n",
            " [3.16003621e-01 5.57681918e-02 3.58887613e-02]\n",
            " [2.32891560e-01 1.22978091e-02 2.22668052e-03]\n",
            " [1.02170110e-02 6.37066960e-02 7.47538143e-05]\n",
            " [9.91838455e-01 6.58999522e-09 7.88792453e-14]\n",
            " [6.12550974e-01 7.70360231e-04 9.18916048e-05]\n",
            " [2.96318650e-01 5.63794374e-03 4.30231630e-05]\n",
            " [3.35886836e-01 5.10132313e-03 3.04001805e-05]\n",
            " [9.99526203e-01 3.77972995e-08 9.82436132e-10]\n",
            " [3.62863839e-02 2.14835405e-02 4.63145077e-02]\n",
            " [7.69561529e-01 1.39743090e-04 6.55994825e-07]\n",
            " [3.55625153e-03 8.53023231e-02 2.44901180e-02]\n",
            " [6.14950538e-01 5.56737185e-04 3.77520905e-06]\n",
            " [9.07402575e-01 5.33868078e-05 1.27626627e-05]\n",
            " [2.99094617e-02 5.33509254e-03 5.76133430e-02]\n",
            " [2.16389298e-02 1.04576349e-03 9.35295224e-03]\n",
            " [9.67528343e-01 4.17335315e-07 4.71264983e-09]\n",
            " [6.69438601e-01 8.01250339e-03 2.24119425e-03]\n",
            " [5.88639379e-01 1.54861808e-03 1.25774145e-02]\n",
            " [1.16065145e-03 9.78299975e-02 4.98211648e-06]\n",
            " [8.03966045e-01 2.29212642e-03 1.01006031e-03]\n",
            " [6.13035858e-01 3.74001265e-03 4.01186943e-03]\n",
            " [1.60227120e-02 3.55220318e-01 3.56164575e-03]\n",
            " [1.54315829e-02 3.05872738e-01 9.08705592e-03]\n",
            " [8.40732038e-01 3.85493040e-04 2.01438306e-05]\n",
            " [7.76329517e-01 5.87511063e-03 3.52573395e-03]\n",
            " [4.59343195e-04 4.68507707e-02 1.54613554e-01]\n",
            " [3.59504521e-02 1.97808236e-01 4.39733267e-03]\n",
            " [8.28318000e-02 4.56653106e-06 7.37863156e-12]\n",
            " [6.78220391e-03 2.98424184e-01 3.17484140e-04]\n",
            " [5.19369543e-02 6.71954751e-02 3.76483083e-01]\n",
            " [9.38019156e-01 4.08491042e-06 1.94349714e-09]\n",
            " [1.79588795e-04 5.14337540e-01 1.44511461e-04]\n",
            " [1.27884746e-03 7.31523335e-02 9.71617699e-02]\n",
            " [9.99725282e-01 1.40180367e-10 6.94089968e-15]\n",
            " [9.99953389e-01 1.07148221e-10 7.64191431e-14]\n",
            " [7.36171007e-03 3.89352441e-03 3.36267948e-01]\n",
            " [5.97200632e-01 1.02098286e-02 2.64787674e-03]\n",
            " [1.67376041e-01 2.87398934e-01 2.72555351e-01]\n",
            " [7.37686038e-01 7.27940132e-05 3.53025456e-07]\n",
            " [2.70278342e-05 7.35680580e-01 4.03773774e-05]\n",
            " [4.91030782e-01 2.91526318e-04 5.84424207e-08]\n",
            " [1.43209994e-02 1.81816071e-01 1.85316801e-03]\n",
            " [1.75039768e-02 3.78737748e-02 4.49529290e-03]\n",
            " [9.87108231e-01 2.73053558e-07 1.73179887e-10]\n",
            " [8.85000348e-01 2.40755544e-05 4.02253484e-08]\n",
            " [5.10474920e-01 1.22241090e-05 3.29619665e-09]\n",
            " [1.64580345e-03 3.45185399e-03 2.00450033e-01]\n",
            " [2.56097138e-01 4.83503938e-03 2.87520252e-05]\n",
            " [2.55234063e-01 5.06937504e-04 2.70058145e-08]\n",
            " [2.88951397e-03 4.55638766e-03 8.91422808e-01]\n",
            " [2.29728818e-02 5.93841076e-04 1.25629365e-01]\n",
            " [1.45551562e-03 1.23932958e-03 9.40173745e-01]\n",
            " [3.61165166e-01 8.04007053e-04 8.65199979e-07]\n",
            " [2.78174877e-03 3.61125171e-02 8.03712510e-07]\n",
            " [8.93577754e-01 2.33370301e-05 2.71069105e-08]\n",
            " [2.94501990e-01 1.09090507e-02 4.45765257e-03]\n",
            " [9.33890820e-01 8.63926107e-05 7.85440170e-06]\n",
            " [6.24530613e-02 3.52385640e-03 3.82661819e-04]\n",
            " [3.04341316e-04 1.08102739e-01 7.04016984e-02]\n",
            " [9.96667862e-01 4.49338671e-07 3.05220138e-09]\n",
            " [9.66398239e-01 1.00760508e-05 1.17056913e-07]\n",
            " [5.39451838e-04 4.99066710e-03 2.19956398e-01]\n",
            " [8.07646334e-01 5.82523717e-05 6.27711529e-07]\n",
            " [7.07091093e-01 1.28090382e-04 2.33008251e-07]\n",
            " [5.16861677e-03 4.89335179e-01 2.40501761e-03]\n",
            " [9.99925375e-01 3.01940517e-09 3.27092901e-11]\n",
            " [4.12368774e-02 4.13421149e-05 6.85815513e-02]\n",
            " [8.68993998e-03 4.04835045e-02 9.55059826e-02]\n",
            " [1.58370137e-02 3.20150852e-02 5.34195306e-06]\n",
            " [1.58488750e-03 5.32028079e-03 1.36661530e-03]\n",
            " [5.44053257e-01 2.99949348e-02 1.80392563e-02]\n",
            " [6.49696290e-02 1.82068348e-03 1.31285250e-01]\n",
            " [4.36430275e-02 1.33785605e-03 1.70207649e-01]\n",
            " [5.44076085e-01 1.02058947e-02 3.33467126e-03]\n",
            " [1.49348378e-03 8.64699483e-03 4.30524025e-08]\n",
            " [4.81903553e-04 1.01530552e-03 9.23509717e-01]\n",
            " [1.62771667e-05 5.09041201e-05 9.74880457e-01]\n",
            " [2.42791772e-02 7.35402107e-04 5.35652816e-01]\n",
            " [9.72985387e-01 5.30835678e-05 9.70828478e-06]\n",
            " [7.52215862e-01 1.67489052e-04 5.65474295e-07]\n",
            " [8.50700259e-01 2.54433362e-05 7.43392263e-08]\n",
            " [7.54854679e-02 1.46944374e-01 2.83280015e-01]\n",
            " [7.56106257e-01 1.64979696e-03 9.43869352e-04]\n",
            " [2.42471695e-04 1.09032393e-01 5.81562519e-04]\n",
            " [5.44440746e-01 6.21661820e-05 4.35407870e-08]\n",
            " [9.90480185e-04 1.41727924e-03 1.44273043e-04]\n",
            " [9.96802926e-01 4.02960154e-07 4.25941682e-09]\n",
            " [9.69277740e-01 1.08459190e-05 3.54961713e-08]\n",
            " [5.92211604e-01 4.89598215e-02 6.46506548e-02]\n",
            " [4.66726065e-01 4.90248203e-04 4.48163291e-06]\n",
            " [4.32448179e-01 3.06722522e-03 1.93729997e-02]\n",
            " [1.17967427e-02 1.05615705e-01 3.54080856e-01]\n",
            " [2.61628628e-03 1.12061858e-01 1.07215492e-04]\n",
            " [3.56653571e-01 4.74818647e-02 1.44522369e-01]\n",
            " [3.16551328e-03 1.23620033e-04 3.53122741e-01]\n",
            " [9.95483756e-01 1.44999888e-08 1.49679151e-12]\n",
            " [1.96069479e-04 5.92032447e-05 9.60236728e-01]\n",
            " [8.71828616e-01 4.26631368e-06 2.10226747e-09]\n",
            " [9.96629715e-01 2.06042569e-06 2.04166270e-07]\n",
            " [2.51027942e-02 1.55381888e-01 5.69462776e-04]\n",
            " [9.66155529e-03 2.59076655e-02 5.93224104e-06]\n",
            " [3.76150012e-03 5.04051447e-02 2.22544491e-01]\n",
            " [7.22971678e-01 5.23418188e-04 5.75125217e-04]\n",
            " [2.22612798e-05 7.36264883e-06 3.36948156e-01]\n",
            " [5.96243262e-01 2.07214762e-05 1.32717005e-07]\n",
            " [7.66556514e-06 8.84218693e-01 7.23147168e-05]\n",
            " [9.70737755e-01 4.24643986e-06 1.78953989e-08]\n",
            " [7.35709369e-02 1.38585001e-01 9.37253237e-03]\n",
            " [1.72802806e-03 6.95554435e-01 7.09113479e-03]\n",
            " [4.26762700e-02 3.06144357e-03 5.03073488e-06]\n",
            " [1.77765787e-02 7.11673498e-03 4.68074590e-01]\n",
            " [7.38968849e-02 1.47859454e-02 2.26378441e-04]\n",
            " [3.51071358e-04 3.67403030e-04 9.18286085e-01]\n",
            " [1.08171821e-01 3.10549140e-03 2.55317882e-05]\n",
            " [9.43011045e-03 8.62754583e-02 3.92569564e-05]\n",
            " [8.98241997e-04 2.64537334e-03 9.08088326e-01]\n",
            " [3.47822905e-04 1.34567708e-01 4.87706065e-03]\n",
            " [8.84619367e-05 3.07513177e-02 7.08396684e-08]\n",
            " [7.68482447e-01 3.31193209e-04 1.02510152e-04]\n",
            " [1.77552164e-01 2.39671469e-02 4.19909656e-02]\n",
            " [5.82268536e-02 4.29234505e-02 1.01602077e-03]\n",
            " [2.58629858e-01 1.45411491e-03 1.04719663e-06]\n",
            " [7.90169239e-02 3.00586224e-03 1.87696594e-06]\n",
            " [2.13829577e-02 7.30341673e-03 2.38394259e-05]\n",
            " [2.53768951e-01 1.57988071e-03 1.39169094e-06]\n",
            " [5.62310219e-04 2.46974826e-03 2.16238316e-09]\n",
            " [8.19486320e-01 4.95439768e-03 1.26311183e-03]\n",
            " [8.05959046e-01 1.82306767e-03 1.06939673e-03]\n",
            " [4.98771667e-04 8.57973397e-02 9.62722301e-03]\n",
            " [3.43823731e-02 3.94935608e-02 1.65581703e-04]\n",
            " [2.08243728e-03 1.04359984e-02 3.61342268e-06]\n",
            " [1.69672057e-05 6.84940457e-01 1.73214685e-05]\n",
            " [4.27533090e-02 2.77028139e-05 2.87840529e-10]\n",
            " [2.30009556e-02 1.67611748e-01 1.77610934e-01]\n",
            " [9.30276453e-01 3.29047441e-04 4.96784778e-05]\n",
            " [8.14812303e-01 1.37507915e-04 1.17382842e-04]\n",
            " [2.54221797e-01 9.14952159e-03 2.23129988e-04]\n",
            " [4.29284871e-02 3.32358479e-03 3.96043718e-01]\n",
            " [9.95429635e-01 2.38684859e-08 6.36680222e-11]\n",
            " [6.60420192e-05 7.30603933e-04 9.22857165e-01]\n",
            " [1.58926845e-03 2.37223506e-03 8.58591735e-01]\n",
            " [9.88382936e-01 4.81615984e-07 6.43375075e-10]\n",
            " [5.02818823e-03 1.42252743e-02 7.72629142e-01]\n",
            " [1.59475923e-01 2.08994970e-05 1.82632642e-11]\n",
            " [3.11519086e-01 1.16243769e-04 1.07061702e-08]\n",
            " [2.06001699e-02 2.20539272e-02 5.36719143e-01]\n",
            " [9.98054504e-01 8.97662318e-08 1.01100128e-10]\n",
            " [4.69419986e-01 1.93000305e-05 3.74198089e-10]\n",
            " [9.75161314e-01 1.40905380e-04 9.52482806e-05]\n",
            " [9.99614537e-01 2.05847840e-07 5.07145828e-08]\n",
            " [7.28577375e-04 6.06602132e-02 1.34177753e-07]\n",
            " [2.93067098e-03 4.55096662e-02 2.57533202e-07]\n",
            " [1.67376041e-01 2.87398934e-01 2.72555351e-01]\n",
            " [4.68159914e-02 8.03610682e-03 7.11609973e-05]\n",
            " [1.71619654e-03 2.87322998e-02 2.07587007e-07]\n",
            " [1.80292130e-03 7.64131546e-03 6.67605460e-01]\n",
            " [7.30426669e-01 7.28905201e-04 5.81234694e-04]\n",
            " [1.29501164e-01 2.63244808e-02 1.73419714e-04]\n",
            " [2.84731388e-04 1.70609355e-03 2.73531973e-01]\n",
            " [1.11667335e-01 6.22051954e-03 1.19247670e-05]\n",
            " [2.68218815e-02 1.19322807e-01 7.98839331e-03]\n",
            " [1.61496282e-01 1.26183033e-03 3.25857036e-06]\n",
            " [9.24736381e-01 1.28090382e-04 4.74397129e-05]\n",
            " [9.54091787e-01 1.30176544e-04 2.34388954e-05]\n",
            " [7.51500845e-01 8.78339779e-05 8.41932106e-08]\n",
            " [1.36097014e-01 7.85768032e-04 3.46830831e-07]\n",
            " [5.15581667e-02 5.32507896e-04 1.55861830e-08]\n",
            " [1.30164623e-03 1.59610510e-02 1.00358683e-07]\n",
            " [3.96901369e-03 2.43548155e-02 3.11388540e-05]\n",
            " [2.79153705e-01 1.28690600e-02 1.97463930e-02]\n",
            " [8.70232582e-01 7.45832920e-04 2.89499760e-04]\n",
            " [8.49515200e-04 2.45785713e-03 6.24966919e-01]\n",
            " [7.87898898e-03 2.25043595e-02 2.27405369e-01]\n",
            " [9.91926312e-01 4.49170701e-09 2.45255341e-14]\n",
            " [9.13390756e-01 1.41829252e-04 1.52448110e-05]\n",
            " [1.89428031e-02 1.48445368e-03 1.11142784e-01]\n",
            " [9.84200478e-01 1.38509113e-05 4.47981038e-05]\n",
            " [4.07394767e-03 1.30277872e-03 8.59319925e-01]\n",
            " [9.69996154e-02 2.46905774e-01 1.32030278e-01]\n",
            " [3.83662991e-05 3.61970067e-03 5.95118284e-01]\n",
            " [5.71478188e-01 3.12864780e-04 1.42629888e-05]\n",
            " [7.52206445e-01 1.47792697e-03 1.64827704e-03]\n",
            " [1.54911995e-01 5.54522872e-03 2.74284482e-01]\n",
            " [6.95231557e-02 2.25213170e-03 2.84789110e-07]\n",
            " [5.59666753e-03 4.62941766e-01 5.99858165e-03]\n",
            " [7.54489660e-01 1.32890940e-02 1.08618438e-02]\n",
            " [9.88832176e-01 9.68758059e-07 4.79283813e-09]\n",
            " [4.73320484e-04 7.11092353e-03 7.17690527e-01]\n",
            " [5.76085210e-01 7.82015122e-05 2.42657343e-08]\n",
            " [9.42850113e-01 5.01245260e-04 1.32918358e-04]\n",
            " [1.08569562e-02 1.70749038e-01 1.96230412e-03]\n",
            " [4.49517369e-03 2.55665183e-03 7.83563495e-01]\n",
            " [2.32028276e-01 2.06494331e-03 3.46668959e-02]\n",
            " [1.24603510e-04 1.62576437e-02 8.03453872e-08]\n",
            " [6.98924959e-02 1.59307718e-02 3.47932458e-01]\n",
            " [6.58986747e-01 6.09278679e-04 2.76707069e-05]\n",
            " [3.71095538e-02 7.87794590e-04 3.40268480e-09]\n",
            " [9.87778187e-01 6.12611575e-06 7.05047705e-06]\n",
            " [1.48321211e-01 4.41735983e-03 2.83701138e-06]\n",
            " [9.90496278e-01 2.79176504e-08 5.48486083e-12]\n",
            " [5.29098809e-02 7.41720200e-04 1.40218481e-06]\n",
            " [9.39859986e-01 1.41123292e-05 4.05554559e-08]\n",
            " [6.46322966e-04 5.90995587e-05 3.97482665e-13]\n",
            " [3.67193818e-02 1.55413151e-03 5.03315032e-02]\n",
            " [5.82164526e-03 7.22452998e-03 7.28722572e-01]\n",
            " [7.40045011e-02 1.00728869e-03 6.63966537e-02]\n",
            " [9.99383330e-01 2.46332945e-08 1.02558784e-09]\n",
            " [1.22833252e-03 4.03285027e-04 6.91922665e-01]\n",
            " [7.90778518e-01 2.43380666e-03 9.40263271e-04]\n",
            " [8.40632141e-01 9.46163491e-05 3.26984559e-06]\n",
            " [1.47908062e-01 1.08343363e-03 1.44033208e-06]\n",
            " [9.68022048e-01 5.21732591e-06 1.38359066e-08]\n",
            " [9.31907058e-01 9.14986558e-08 4.68813790e-13]\n",
            " [6.36750758e-02 2.78267264e-03 1.15527229e-07]\n",
            " [9.92672205e-01 1.03204343e-06 3.53594885e-07]\n",
            " [9.96527076e-01 1.90744959e-06 9.84102940e-07]\n",
            " [9.66724038e-01 1.59472227e-04 2.81490011e-05]\n",
            " [1.23287141e-02 5.16418815e-02 1.10256672e-03]\n",
            " [9.12923157e-01 1.72305107e-03 9.66459513e-04]\n",
            " [8.68821144e-03 3.16214859e-02 5.63702042e-06]\n",
            " [1.70803070e-03 3.42142582e-03 1.84718192e-01]\n",
            " [1.67043805e-02 9.83915925e-02 3.15915677e-05]\n",
            " [1.89889818e-01 7.03904033e-03 1.92105770e-04]\n",
            " [3.40074301e-03 1.18897259e-02 4.91035621e-08]\n",
            " [9.87858176e-01 2.00698605e-06 2.42013929e-08]\n",
            " [9.98531818e-01 3.30245200e-07 5.12178122e-09]\n",
            " [4.82126117e-01 6.89080358e-03 1.95747614e-03]\n",
            " [7.11802363e-01 5.68777323e-04 5.65883511e-06]\n",
            " [4.61301506e-02 1.83890760e-02 6.13753627e-06]\n",
            " [2.11990595e-01 4.28507626e-02 1.53985620e-03]\n",
            " [9.79367852e-01 1.46822060e-06 1.52994128e-09]\n",
            " [2.16823518e-02 1.02286667e-01 2.09169984e-02]\n",
            " [5.41345060e-01 5.05083799e-03 9.88632441e-04]\n",
            " [1.36733055e-04 7.39554942e-01 1.03134786e-04]\n",
            " [1.95899606e-03 2.74023771e-01 3.14831734e-04]\n",
            " [9.88460422e-01 6.15774525e-08 3.17221666e-11]\n",
            " [1.15364790e-03 4.83741787e-05 3.40736240e-01]\n",
            " [4.18633223e-04 6.26431704e-02 9.97491441e-08]\n",
            " [2.53024697e-01 4.91049886e-03 1.87136175e-05]\n",
            " [3.06871533e-03 1.20639503e-02 2.68704923e-07]\n",
            " [8.51817608e-01 1.45813823e-03 1.59621239e-03]\n",
            " [2.85080075e-03 3.42908502e-03 8.82372260e-01]\n",
            " [1.89544261e-02 4.48307395e-03 1.07558626e-05]\n",
            " [9.85488713e-01 9.60658326e-07 2.63627586e-09]\n",
            " [4.64775503e-01 4.29716706e-03 5.81264496e-04]\n",
            " [8.80849957e-01 9.75489616e-04 9.11772251e-04]\n",
            " [9.39404488e-01 4.83972035e-05 5.69580095e-07]\n",
            " [9.76147056e-01 2.35992775e-06 7.33379011e-08]\n",
            " [8.93105567e-01 1.47670507e-04 1.17919274e-06]]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 2. 1. 1. 2. 0. 2. 2. 2. 2. 1. 0. 0. 2. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n",
            " 1. 2. 2. 1. 2. 2. 0. 1. 0. 0. 1. 1. 2. 0. 2. 0. 2. 1. 2. 1. 0. 2. 1. 2.\n",
            " 0. 1. 2. 1. 1. 1. 2. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 2. 0. 0. 0.\n",
            " 2. 0. 1. 0. 0. 2. 0. 0. 2. 0. 1. 0. 0. 1. 1. 2. 1. 1. 0. 2. 1. 0. 0. 1.\n",
            " 1. 0. 0. 0. 2. 1. 1. 0. 0. 0. 1. 0. 0. 1. 2. 0. 0. 2. 0. 0. 2. 2. 0. 2.\n",
            " 0. 0. 2. 1. 0. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1. 0. 2. 2.\n",
            " 1. 1. 0. 2. 1. 2. 0. 2. 2. 0. 0. 2. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 2. 1. 1. 2. 0. 2. 2. 0. 0. 1. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 2. 0. 0. 0.\n",
            " 0. 1. 0. 0. 1. 1. 0. 0. 2. 1. 0. 1. 2. 0. 1. 2. 0. 0. 2. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 2. 0. 0. 2. 2. 2. 0. 1. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 1.\n",
            " 0. 2. 2. 1. 1. 0. 2. 2. 0. 1. 2. 2. 2. 0. 0. 0. 2. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 2. 1. 0. 2. 0. 2. 0. 0. 1. 1. 2. 0. 2. 0. 1. 0. 1. 1. 0. 2. 0. 2.\n",
            " 0. 1. 2. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 2. 0. 0. 0.\n",
            " 2. 0. 2. 2. 0. 2. 0. 0. 2. 0. 0. 0. 0. 1. 1. 1. 0. 1. 2. 0. 0. 2. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 2. 2. 0. 0. 2. 0. 2. 1. 2. 0. 0. 2. 0. 1.\n",
            " 0. 0. 2. 0. 0. 1. 2. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 2. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 2. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 2. 1. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0.5451009340459249\n",
            "0.5679165708151216\n",
            "0.5321880113044771\n",
            "0.6321428571428571\n",
            "[[131  19  16]\n",
            " [ 29  24   7]\n",
            " [ 29   3  22]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}