{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DetectingStanceWithBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd8c104b325e4e06b6a3574dfafac7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_974e5ad28b9744989a033e0df297a8a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_853c66a0f6794f0a845676ea68b27d28",
              "IPY_MODEL_449ec1eef21047bfa6add6ee7f602dbe"
            ]
          }
        },
        "974e5ad28b9744989a033e0df297a8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "853c66a0f6794f0a845676ea68b27d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84f887b781a5405f985031e0c551c3dc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ead0d9332d434bd1a3ea60ee6472e5f3"
          }
        },
        "449ec1eef21047bfa6add6ee7f602dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a483c4ee6024b4496843744433e94e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 542kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d4253eb6b6a4c3080a8a9e14244fcc0"
          }
        },
        "84f887b781a5405f985031e0c551c3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ead0d9332d434bd1a3ea60ee6472e5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a483c4ee6024b4496843744433e94e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d4253eb6b6a4c3080a8a9e14244fcc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3be8331abc474edd920f6fce4bcb0479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6bf8deef5dfe405f8ba13dd6f6db65d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_30c126ee6ae94f1291b4ad56711a7330",
              "IPY_MODEL_3aeab0bb0e5745c5a942a440bb9c4eae"
            ]
          }
        },
        "6bf8deef5dfe405f8ba13dd6f6db65d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30c126ee6ae94f1291b4ad56711a7330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f01ff65f77bf4b878152de3503718cf9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d277a3a9b3614f59ac9b35f3c1313724"
          }
        },
        "3aeab0bb0e5745c5a942a440bb9c4eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee7ef4bb78e24dcca626e3fa4aece066",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 521B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4901136166c34488a66373181051993d"
          }
        },
        "f01ff65f77bf4b878152de3503718cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d277a3a9b3614f59ac9b35f3c1313724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee7ef4bb78e24dcca626e3fa4aece066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4901136166c34488a66373181051993d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d684c06520214509a88e14750bbec517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08789defdf094c2685340341236cb7ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3cec0eaf6184a79980d0317d5226ed8",
              "IPY_MODEL_573d37942b4645a59ab293953433d15d"
            ]
          }
        },
        "08789defdf094c2685340341236cb7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3cec0eaf6184a79980d0317d5226ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84fbe21506f6422aa2413d351520cd16",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_009b35a21f394d64bc7e9f2b96a690cf"
          }
        },
        "573d37942b4645a59ab293953433d15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d37e9b9b6e2f41069491cc9b80e1b38c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [01:12&lt;00:00, 6.02MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_238067af685c489ab19ec9d06e4cb6b5"
          }
        },
        "84fbe21506f6422aa2413d351520cd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "009b35a21f394d64bc7e9f2b96a690cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d37e9b9b6e2f41069491cc9b80e1b38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "238067af685c489ab19ec9d06e4cb6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXMIWvmy_kaz",
        "colab_type": "code",
        "outputId": "ece71320-c72e-4566-846e-bcaf7f76c40e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 8.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 60.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=5610bcc8f2bcd52cf7cc79aa9655740f497fbce76a8e3fa85167213d21f8b64f\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHAPozBB_x28",
        "colab_type": "code",
        "outputId": "61651af8-bd46-404f-b94a-22fff13415ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding, Conv2D, MaxPool2D\n",
        "from keras.models import Model\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "\n",
        "import keras.regularizers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbe6uWQh_3lg",
        "colab_type": "code",
        "outputId": "70f3096a-3a12-4ad4-82e4-d7340990a3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbRx89t4_6vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuations(docs): #list of strings\n",
        "    punctuations = '''!()[]{};:\"\\,<>'./?@#$%^&*_~-'''\n",
        "    docs2=[];\n",
        "    i=0;\n",
        "    for sent in docs:\n",
        "        s=\"\"\n",
        "        for x in sent:\n",
        "            if(x not in punctuations):\n",
        "                s=s+x;\n",
        "        docs2.append(s);\n",
        "\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def convert_lowercase(docs): #list of strings\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        sent=sent.lower()\n",
        "        docs2.append(sent);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_data(docs): #list of strings\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        sent=word_tokenize(sent)\n",
        "        docs2.append(sent);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "def remove_stopwords(docs): #list of list of words as param\n",
        "    stop_words=set(stopwords.words(\"english\"));\n",
        "\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        s=[];\n",
        "        for word in sent:\n",
        "            if(word not in stop_words):\n",
        "                s.append(word);\n",
        "        docs2.append(s);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def make_string(docs): #list of list of words as param\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        s=\"\"\n",
        "        s=' '.join(sent)\n",
        "        docs2.append(s);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def lemmatize(docs): #list of list of words as param\n",
        "    lemmatizer=WordNetLemmatizer();\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        s=[];\n",
        "        for word in sent:\n",
        "            s.append(lemmatizer.lemmatize(word));\n",
        "        docs2.append(s);\n",
        "\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n",
        "\n",
        "\n",
        "def remove_digits(docs): #list of strings\n",
        "    docs2=[]\n",
        "    for sent in docs:\n",
        "        sent2=sent.split(' ');\n",
        "        words=[]\n",
        "        for x in sent2:\n",
        "            flag=0;\n",
        "            for c in x:\n",
        "                if(c>='0' and c<='9'):\n",
        "                    flag=1;\n",
        "                    break;\n",
        "                else:\n",
        "                    pass;\n",
        "            if(flag==0):\n",
        "                words.append(x);\n",
        "        words=' '.join(words);\n",
        "        docs2.append(words)\n",
        "    docs=docs2;\n",
        "    docs2=[]\n",
        "    return docs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-twhjGhcL9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train=pd.read_csv('drive/My Drive/dataset_train.csv',encoding = \"ISO-8859-1\")\n",
        "data_train_target1=data_train[data_train[\"Target\"]==\"Atheism\"]\n",
        "data_train_target2=data_train[data_train[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "data_train_target3=data_train[data_train[\"Target\"]==\"Feminist Movement\"]\n",
        "data_train_target4=data_train[data_train[\"Target\"]==\"Hillary Clinton\"]\n",
        "data_train_target5=data_train[data_train[\"Target\"]==\"Legalization of Abortion\"]\n",
        "\n",
        "data_test=pd.read_csv('drive/My Drive/dataset_test.csv',encoding = \"ISO-8859-1\")\n",
        "data_test_target1=data_test[data_test[\"Target\"]==\"Atheism\"]\n",
        "data_test_target2=data_test[data_test[\"Target\"]==\"Climate Change is a Real Concern\"]\n",
        "data_test_target3=data_test[data_test[\"Target\"]==\"Feminist Movement\"]\n",
        "data_test_target4=data_test[data_test[\"Target\"]==\"Hillary Clinton\"]\n",
        "data_test_target5=data_test[data_test[\"Target\"]==\"Legalization of Abortion\"]\n",
        "\n",
        "\n",
        "at=len(data_test_target1)\n",
        "bt=len(data_test_target2)\n",
        "ct=len(data_test_target3)\n",
        "dt=len(data_test_target4)\n",
        "et=len(data_test_target5)\n",
        "\n",
        "a=len(data_train_target1)\n",
        "b=len(data_train_target2)\n",
        "c=len(data_train_target3)\n",
        "d=len(data_train_target4)\n",
        "e=len(data_train_target5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p3Peikn_-Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train=pd.read_csv('drive/My Drive/dataset_train.csv',encoding = \"ISO-8859-1\")\n",
        "data_train_target1=data_train[data_train[\"Target\"]==\"Atheism\"]\n",
        "\n",
        "data_test=pd.read_csv('drive/My Drive/dataset_test.csv',encoding = \"ISO-8859-1\")\n",
        "data_test_target1=data_test[data_test[\"Target\"]==\"Atheism\"]\n",
        "\n",
        "target1_train_len=len(data_train_target1)\n",
        "\n",
        "target1_train_data=[]\n",
        "for i in range(0,a): # a to a+b range for next target and so on...\n",
        "    target1_train_data.append(data_train_target1[\"Tweet\"][i])\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "target1_train_data=convert_lowercase(target1_train_data)\n",
        "target1_train_data=remove_digits(target1_train_data)\n",
        "target1_train_data=remove_punctuations(target1_train_data)\n",
        "target1_train_data=tokenize_data(target1_train_data)\n",
        "target1_train_data=remove_stopwords(target1_train_data)\n",
        "target1_train_data=lemmatize(target1_train_data)\n",
        "target1_train_data=make_string(target1_train_data)\n",
        "\n",
        "\n",
        "target1_test_len=len(data_test_target1)\n",
        "\n",
        "target1_test_data=[]\n",
        "for i in range(0,at):\n",
        "    target1_test_data.append(data_test_target1[\"Tweet\"][i])\n",
        "    \n",
        "target1_test_data=convert_lowercase(target1_test_data)\n",
        "target1_test_data=remove_digits(target1_test_data)\n",
        "target1_test_data=remove_punctuations(target1_test_data)\n",
        "target1_test_data=tokenize_data(target1_test_data)\n",
        "target1_test_data=remove_stopwords(target1_test_data)\n",
        "target1_test_data=lemmatize(target1_test_data)\n",
        "target1_test_data=make_string(target1_test_data)\n",
        "\n",
        "\n",
        "y1=[]\n",
        "for i in range(0,a):\n",
        "    y1.append(data_train_target1[\"Stance\"][i])\n",
        "    \n",
        "\n",
        "target1_full_data=[]\n",
        "target1_full_data.extend(target1_train_data)\n",
        "target1_full_data.extend(target1_test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhkcudaqAi_n",
        "colab_type": "code",
        "outputId": "c9d26cb0-5371-49a1-8111-fc6c0e92944f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDRtK1x9BabV",
        "colab_type": "text"
      },
      "source": [
        "#### BERT has maximum input limit of 512 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RxR8uzeBSJq",
        "colab_type": "code",
        "outputId": "48ff6f07-cb52-4f1f-9ee8-394ac87f9960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "dd8c104b325e4e06b6a3574dfafac7c4",
            "974e5ad28b9744989a033e0df297a8a2",
            "853c66a0f6794f0a845676ea68b27d28",
            "449ec1eef21047bfa6add6ee7f602dbe",
            "84f887b781a5405f985031e0c551c3dc",
            "ead0d9332d434bd1a3ea60ee6472e5f3",
            "3a483c4ee6024b4496843744433e94e6",
            "0d4253eb6b6a4c3080a8a9e14244fcc0"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "print(\"Loading...\")\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd8c104b325e4e06b6a3574dfafac7c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAa59Pf7CN4c",
        "colab_type": "code",
        "outputId": "c58a20f8-f676-4fe6-f1b3-b85b9e66c74d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=target1_full_data[0]\n",
        "tokens=tokenizer.tokenize(text)\n",
        "print(len(tokens))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJK480rYDCO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "input_ids=[]\n",
        "lengths=[]\n",
        "for tweet in target1_train_data:\n",
        "  encoded_sent=tokenizer.encode(tweet,add_special_tokens=True)\n",
        "  input_ids.append(encoded_sent)\n",
        "  lengths.append(len(encoded_sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Rl1t1HEAHl",
        "colab_type": "code",
        "outputId": "c117c98d-eb64-44fa-f2b3-04ac70b5f6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(input_ids[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 19387, 3729, 2121, 12155, 21885, 17060, 2460, 5656, 2442, 2173, 4785, 2689, 3034, 3000, 2285, 2583, 2290, 7367, 5244, 2102, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiFg9bNYEG72",
        "colab_type": "code",
        "outputId": "06f0e550-faf1-4528-f546-87d380215a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y1=list(y1)\n",
        "print(y1)\n",
        "y_train=[]\n",
        "for i in range(len(target1_train_data)):\n",
        "  if(y1[i]=='AGAINST'):\n",
        "    y_train.append(0)\n",
        "  elif(y1[i]=='FAVOR'):\n",
        "    y_train.append(1)\n",
        "  else:\n",
        "    y_train.append(2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'FAVOR', 'NONE', 'AGAINST', 'FAVOR', 'FAVOR', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'FAVOR', 'NONE', 'FAVOR', 'AGAINST', 'NONE', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'NONE', 'FAVOR', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'FAVOR', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'FAVOR', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'NONE', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'FAVOR', 'FAVOR', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'NONE', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'NONE', 'AGAINST', 'NONE', 'NONE', 'NONE', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', 'FAVOR', 'AGAINST', 'FAVOR', 'FAVOR', 'AGAINST', 'FAVOR', 'NONE', 'NONE', 'FAVOR', 'FAVOR', 'NONE', 'NONE', 'NONE', 'NONE', 'FAVOR', 'NONE', 'NONE', 'FAVOR', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'NONE', 'NONE', 'FAVOR', 'FAVOR', 'NONE', 'NONE', 'FAVOR', 'FAVOR', 'FAVOR', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'NONE', 'NONE', 'NONE', 'NONE', 'AGAINST', 'NONE', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'NONE', 'NONE', 'NONE', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'FAVOR', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'NONE', 'FAVOR', 'NONE', 'FAVOR', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'NONE', 'FAVOR', 'FAVOR', 'NONE', 'FAVOR', 'FAVOR', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'NONE', 'FAVOR', 'AGAINST', 'FAVOR', 'AGAINST', 'NONE', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'NONE', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'NONE', 'FAVOR', 'FAVOR', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'NONE', 'FAVOR', 'FAVOR', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'FAVOR', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'AGAINST', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'FAVOR', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'NONE', 'NONE', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST', 'AGAINST']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPxqUEnkJ2-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-wRWu0REQGj",
        "colab_type": "code",
        "outputId": "d0d9b832-31fd-429e-9684-80b4239cea14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(max(lengths))\n",
        "print(min(lengths))\n",
        "print(np.median(lengths))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "7\n",
            "20.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQkatoy2GQLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN=40\n",
        "input_ids=pad_sequences(input_ids,maxlen=MAX_LEN,dtype='long',value=0, truncating='post',padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIYR7bn5HeCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create attention masks\n",
        "#if token id is 0, then its padded, set the mask to 0\n",
        "attention_masks=[]\n",
        "for tweet in input_ids:\n",
        "  att_mask=[int(token_id >0) for token_id in tweet]\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsRjp86WIIkQ",
        "colab_type": "code",
        "outputId": "cd3c122c-535f-47b4-e9e3-3ca231f62b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(attention_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw7uaevqIRca",
        "colab_type": "code",
        "outputId": "6f1d8252-237e-470b-c8eb-818096eba95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(input_ids))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbjStzplJjTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using 90% train and 10% test set\n",
        "# also for the masks\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,labels, random_state=42, test_size=0.1)\n",
        "train_masks, validation_masks,_,_=train_test_split(attention_masks,labels, random_state=42, test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmTDYAAOMY86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "import torch\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ10WDLGKZfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to pyTorch data types\n",
        "\n",
        "from torch.utils.data import TensorDataset , DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "train_data=TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler=RandomSampler(train_data)\n",
        "train_dataloader=DataLoader(train_data,sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data=TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler=SequentialSampler(validation_data)\n",
        "validation_dataloader=DataLoader(validation_data,sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxhv4MxhMugu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "3be8331abc474edd920f6fce4bcb0479",
            "6bf8deef5dfe405f8ba13dd6f6db65d1",
            "30c126ee6ae94f1291b4ad56711a7330",
            "3aeab0bb0e5745c5a942a440bb9c4eae",
            "f01ff65f77bf4b878152de3503718cf9",
            "d277a3a9b3614f59ac9b35f3c1313724",
            "ee7ef4bb78e24dcca626e3fa4aece066",
            "4901136166c34488a66373181051993d",
            "d684c06520214509a88e14750bbec517",
            "08789defdf094c2685340341236cb7ad",
            "f3cec0eaf6184a79980d0317d5226ed8",
            "573d37942b4645a59ab293953433d15d",
            "84fbe21506f6422aa2413d351520cd16",
            "009b35a21f394d64bc7e9f2b96a690cf",
            "d37e9b9b6e2f41069491cc9b80e1b38c",
            "238067af685c489ab19ec9d06e4cb6b5"
          ]
        },
        "outputId": "73d6ef5a-2497-4865-e752-cd30e361de14"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model=BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=3,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3be8331abc474edd920f6fce4bcb0479",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d684c06520214509a88e14750bbec517",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=435779157, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKf0gZFQTEUy",
        "colab_type": "code",
        "outputId": "e67f808a-2d34-4565-a3cb-b9e1e40f23c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH3cUg5RNqMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initial learning rate, adam_epsilon\n",
        "optimizer=AdamW(model.parameters(), lr=0.0001, eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0cYUyJCOBqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs=4\n",
        "\n",
        "total_steps=len(train_dataloader)*epochs\n",
        "scheduler=get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2DWQ_GZOvDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(preds)\n",
        "    print(labels)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE6-UWhEOxpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVngElcAT9s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugCGSwOO6TW",
        "colab_type": "code",
        "outputId": "e09cb834-e170-4d60-f6a0-6dcc03095349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        #if step % 40 == 0 and not step == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch     0  of     29.    Elapsed: 0:00:00.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch     1  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     2  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     3  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     4  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     5  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     6  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     7  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     8  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     9  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    11  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    12  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    13  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    14  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    15  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    16  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    17  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    18  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    19  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    20  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    21  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    22  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    23  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    24  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    25  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    26  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    27  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    28  of     29.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.93\n",
            "  Training epcoh took: 0:00:03\n",
            "\n",
            "Running Validation...\n",
            "[[ 2.0014298  -0.37097767 -1.2946645 ]\n",
            " [ 1.048215   -0.04883013 -1.0709957 ]\n",
            " [ 0.7297822  -0.3896337  -0.31747895]\n",
            " [ 0.66531914  0.04101851 -0.9228964 ]\n",
            " [ 1.2234242  -0.60667187 -0.4258849 ]\n",
            " [ 1.8320667  -0.41246468 -1.1607403 ]\n",
            " [ 0.804644   -0.09034869 -0.7355706 ]\n",
            " [ 1.8743441  -0.34766507 -1.2742126 ]\n",
            " [ 0.9084523  -0.02037833 -0.9399975 ]\n",
            " [ 1.7158716  -0.30747402 -1.0367059 ]\n",
            " [ 1.3205916  -0.15116522 -1.1781132 ]\n",
            " [ 0.8395459  -0.02325151 -0.94525874]\n",
            " [ 1.0835896  -0.07454214 -1.0951709 ]\n",
            " [ 1.0025753  -0.58994555 -0.47827625]\n",
            " [ 1.1046321  -0.08557853 -1.0113488 ]\n",
            " [ 0.8113552   0.02211496 -0.9865715 ]]\n",
            "[0 0 0 1 2 0 2 0 2 2 0 2 0 0 1 1]\n",
            "[[ 0.77594924  0.04602709 -0.9981456 ]\n",
            " [ 1.689306   -0.28160688 -1.3413092 ]\n",
            " [ 1.7090213  -0.6002097  -0.8766828 ]\n",
            " [ 1.9002286  -0.46681505 -1.2730328 ]\n",
            " [ 0.02394144 -0.3750697   0.3871012 ]\n",
            " [ 0.3904016   0.0103108  -0.58298844]\n",
            " [ 0.37586302  0.00688967 -0.46709442]\n",
            " [ 1.2752903  -0.14554146 -1.1271377 ]\n",
            " [ 0.72385633  0.05048725 -0.9038088 ]\n",
            " [ 0.90721154 -0.17473945 -0.79635364]\n",
            " [ 0.77670103 -0.00616727 -0.9372374 ]\n",
            " [ 2.0295079  -0.4620675  -1.2538326 ]\n",
            " [ 1.5321741  -0.21381685 -1.1825012 ]\n",
            " [ 0.33951512 -0.23986772 -0.09523562]\n",
            " [ 0.2640016   0.0128366  -0.4091468 ]\n",
            " [ 1.8757427  -0.2854593  -1.3529916 ]]\n",
            "[1 0 2 0 2 2 2 0 2 2 2 0 2 2 2 0]\n",
            "[[ 1.9106781  -0.50585675 -1.0688974 ]\n",
            " [ 0.50974935 -0.045966   -0.6885312 ]\n",
            " [ 0.7231068   0.04018768 -0.8623658 ]\n",
            " [ 0.60681504  0.05545964 -0.85093385]\n",
            " [ 1.9636697  -0.40841714 -1.274045  ]\n",
            " [ 1.2414927  -0.14429441 -1.1372923 ]\n",
            " [ 0.9257577  -0.01718495 -1.021109  ]\n",
            " [ 2.0488162  -0.39890337 -1.3105297 ]\n",
            " [ 1.4377741  -0.11917648 -1.2405555 ]\n",
            " [ 2.0681605  -0.5446781  -1.1479875 ]\n",
            " [ 0.9704773  -0.02698324 -1.0004671 ]\n",
            " [ 1.7676862  -0.39998022 -1.028119  ]\n",
            " [ 0.62985206  0.04473391 -0.8530148 ]\n",
            " [ 1.871417   -0.4271638  -1.082585  ]\n",
            " [ 0.6964846   0.06123939 -0.9696728 ]\n",
            " [ 0.8316046  -0.00371942 -0.93909365]]\n",
            "[0 2 0 0 0 0 0 2 0 0 0 2 0 0 1 2]\n",
            "[[ 1.237538   -0.11934046 -1.0944016 ]\n",
            " [ 0.14801937 -0.07193066 -0.20617324]\n",
            " [ 0.59858286 -0.0348305  -0.64287573]\n",
            " [ 1.3843571  -0.13271496 -1.1891428 ]]\n",
            "[0 0 2 1]\n",
            "  Accuracy: 0.52\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch     0  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     1  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     2  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     3  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     4  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     5  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     6  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     7  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     8  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     9  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    11  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    12  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    13  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    14  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    15  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    16  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    17  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    18  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    19  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    20  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    21  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    22  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    23  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    24  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    25  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    26  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    27  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    28  of     29.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:00:03\n",
            "\n",
            "Running Validation...\n",
            "[[ 2.5252662  -1.1375118  -1.3803483 ]\n",
            " [ 0.13144445  1.0387591  -1.4231603 ]\n",
            " [ 1.1914967  -0.95961845 -0.4810964 ]\n",
            " [-0.5524752   1.2970529  -1.2733787 ]\n",
            " [ 0.40976527 -1.6482788   1.828698  ]\n",
            " [ 2.4889143  -1.5200319  -0.8506074 ]\n",
            " [-0.5695837  -1.6528172   2.4141037 ]\n",
            " [ 2.2962494  -1.2399217  -1.1764976 ]\n",
            " [-0.04628336 -1.7438807   2.11457   ]\n",
            " [ 0.30486825 -1.639219    1.8454529 ]\n",
            " [ 1.2036241   0.21711963 -1.6694638 ]\n",
            " [ 0.5735196   0.487266   -1.3735691 ]\n",
            " [ 0.886812    0.42036134 -1.5832286 ]\n",
            " [ 2.033654   -1.3839309  -0.7567668 ]\n",
            " [-0.02021218 -0.13969505 -0.34311146]\n",
            " [-0.4371014   1.1476691  -1.1224512 ]]\n",
            "[0 0 0 1 2 0 2 0 2 2 0 2 0 0 1 1]\n",
            "[[-0.16270277  1.1577445  -1.3518143 ]\n",
            " [ 2.3558502  -0.75065994 -1.7575802 ]\n",
            " [ 0.56474435 -1.7279936   1.6387125 ]\n",
            " [ 2.4933844  -1.5237131  -0.88154906]\n",
            " [-0.5646825  -1.8057973   2.4870188 ]\n",
            " [-0.24944738  0.38044327 -0.7413352 ]\n",
            " [-0.40231317 -0.43928644  0.06927663]\n",
            " [ 1.7262553  -1.3377204  -0.579805  ]\n",
            " [-0.04412168  0.79039025 -1.1190879 ]\n",
            " [-0.7416934  -1.4548395   2.2312477 ]\n",
            " [ 0.17353481 -0.64603466 -0.04631391]\n",
            " [ 2.6771135  -1.4504691  -1.194131  ]\n",
            " [ 1.0561     -1.5971036   1.0222219 ]\n",
            " [-0.4021618  -1.7006521   2.4201577 ]\n",
            " [-0.82760334 -0.7629913   1.1210674 ]\n",
            " [ 2.457027   -1.3622077  -1.1593171 ]]\n",
            "[1 0 2 0 2 2 2 0 2 2 2 0 2 2 2 0]\n",
            "[[ 2.0064445  -1.4045426  -0.6675691 ]\n",
            " [-0.20170909  0.4590112  -0.87361056]\n",
            " [ 0.10818348  0.58641577 -1.1177926 ]\n",
            " [-0.2573949   0.6758131  -0.96116674]\n",
            " [ 2.6078992  -1.1171023  -1.5655891 ]\n",
            " [ 1.2969264  -0.03779256 -1.5598334 ]\n",
            " [ 0.36517462 -0.05170983 -0.8141468 ]\n",
            " [ 2.0227332  -1.5585063  -0.22876343]\n",
            " [ 0.47485045  0.7729014  -1.4890158 ]\n",
            " [ 1.7415379  -1.4835408  -0.04510063]\n",
            " [-0.3156288  -0.5012791   0.21044011]\n",
            " [ 0.5830775  -1.4983449   1.5352273 ]\n",
            " [-0.6140822   0.33930272 -0.27322188]\n",
            " [ 2.648871   -1.6203051  -1.00093   ]\n",
            " [-0.9472555  -0.38300452  0.80885243]\n",
            " [-0.40897664 -1.1968486   1.157832  ]]\n",
            "[0 2 0 0 0 0 0 2 0 0 0 2 0 0 1 2]\n",
            "[[ 0.6462665   0.5793987  -1.5518855 ]\n",
            " [-0.45863074 -1.5819848   2.051887  ]\n",
            " [ 0.11976231 -1.7113684   1.8363663 ]\n",
            " [-0.1838299   1.2128109  -1.4360063 ]]\n",
            "[0 0 2 1]\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch     0  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     1  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     2  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     3  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     4  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     5  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     6  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     7  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     8  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     9  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    11  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    12  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    13  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    14  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    15  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    16  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    17  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    18  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    19  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    20  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    21  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    22  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    23  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    24  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    25  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    26  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    27  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    28  of     29.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:00:03\n",
            "\n",
            "Running Validation...\n",
            "[[ 3.7427437  -1.4968412  -2.3095806 ]\n",
            " [ 0.52491295  1.0348413  -1.8732193 ]\n",
            " [ 2.7301626  -1.6521267  -1.1763258 ]\n",
            " [-1.0257845   2.281072   -1.6609384 ]\n",
            " [-0.26935107 -1.6439669   2.1792219 ]\n",
            " [ 3.664184   -1.5316749  -2.1572356 ]\n",
            " [-1.0343436  -1.6638316   2.7717526 ]\n",
            " [ 3.4230595  -1.6500767  -1.8281158 ]\n",
            " [-1.2030761  -1.7199442   2.9148421 ]\n",
            " [ 0.03160588 -1.8992215   2.1635838 ]\n",
            " [ 3.4842865  -1.221878   -2.3863893 ]\n",
            " [ 2.639873   -1.8287168  -0.6707937 ]\n",
            " [ 3.6573193  -1.4119414  -2.3312397 ]\n",
            " [ 2.6696758  -1.9901315  -0.42392376]\n",
            " [-0.19497545  0.22576106 -0.43556523]\n",
            " [-1.3020544   0.13690548  0.3412814 ]]\n",
            "[0 0 0 1 2 0 2 0 2 2 0 2 0 0 1 1]\n",
            "[[-0.7670336   1.6253716  -1.4691194 ]\n",
            " [ 3.7214794  -1.4987675  -2.1836007 ]\n",
            " [ 1.1647037  -2.2935703   1.5810108 ]\n",
            " [ 3.3929958  -1.5362228  -1.8065829 ]\n",
            " [-1.3928865  -1.5842353   2.8483627 ]\n",
            " [-1.5567849  -1.5589272   2.9988027 ]\n",
            " [-0.91005844 -1.8770226   2.7044382 ]\n",
            " [ 3.1351342  -1.2707186  -2.0473485 ]\n",
            " [-0.6641894   0.85553074 -0.83333534]\n",
            " [-1.207795   -1.3978775   2.5297487 ]\n",
            " [ 1.5244772  -1.2477354  -0.69273466]\n",
            " [ 3.554784   -1.6887316  -1.6735699 ]\n",
            " [ 0.8239134  -2.1488018   1.806362  ]\n",
            " [-1.4556563  -1.5569867   2.9478674 ]\n",
            " [-1.3661343  -1.5482247   2.950768  ]\n",
            " [ 3.633126   -1.5618939  -2.0395155 ]]\n",
            "[1 0 2 0 2 2 2 0 2 2 2 0 2 2 2 0]\n",
            "[[ 3.5569818  -1.7711768  -1.8821596 ]\n",
            " [-1.5778159  -1.0423404   1.9559869 ]\n",
            " [ 1.1220804  -0.3253568  -1.2757442 ]\n",
            " [-1.5149169  -1.4319229   2.5935845 ]\n",
            " [ 3.7509286  -1.5395633  -2.2095366 ]\n",
            " [ 1.3896499   0.28475124 -2.0539083 ]\n",
            " [ 2.1893618  -1.2128118  -1.3103296 ]\n",
            " [ 3.400171   -1.6316736  -1.6532307 ]\n",
            " [ 3.2259896  -1.074511   -2.2748833 ]\n",
            " [ 2.6883218  -1.8767837  -0.35414934]\n",
            " [ 0.215904   -1.1453208   0.5635753 ]\n",
            " [-0.25688666 -1.8136384   2.4239304 ]\n",
            " [-1.4649762  -1.1895593   2.4091568 ]\n",
            " [ 3.366167   -1.6764047  -1.5210384 ]\n",
            " [-1.854905   -0.7823645   2.5533628 ]\n",
            " [-1.4129521  -1.4466976   2.893746  ]]\n",
            "[0 2 0 0 0 0 0 2 0 0 0 2 0 0 1 2]\n",
            "[[ 2.5906608  -1.0446103  -1.9067432 ]\n",
            " [-1.3383756  -1.5216995   2.8918893 ]\n",
            " [-0.46808952 -2.0838149   2.4679208 ]\n",
            " [-0.53171664  2.020104   -1.8217539 ]]\n",
            "[0 0 2 1]\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch     0  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     1  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     2  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     3  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     4  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     5  of     29.    Elapsed: 0:00:00.\n",
            "  Batch     6  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     7  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     8  of     29.    Elapsed: 0:00:01.\n",
            "  Batch     9  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    11  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    12  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    13  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    14  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    15  of     29.    Elapsed: 0:00:01.\n",
            "  Batch    16  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    17  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    18  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    19  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    20  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    21  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    22  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    23  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    24  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    25  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    26  of     29.    Elapsed: 0:00:02.\n",
            "  Batch    27  of     29.    Elapsed: 0:00:03.\n",
            "  Batch    28  of     29.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:00:03\n",
            "\n",
            "Running Validation...\n",
            "[[ 4.1724253  -1.6716084  -2.5424325 ]\n",
            " [-1.4173385   2.7978203  -1.5542043 ]\n",
            " [ 3.3533008  -1.562962   -2.0255573 ]\n",
            " [-1.5724572   2.6127088  -0.8506486 ]\n",
            " [ 1.6392034  -2.2481177   1.2364563 ]\n",
            " [ 4.1720734  -1.7295079  -2.451442  ]\n",
            " [-0.50515926 -2.342306    3.0405152 ]\n",
            " [ 4.137121   -1.7815316  -2.3407428 ]\n",
            " [-0.8622624  -2.1065724   2.6968496 ]\n",
            " [ 2.4623053  -2.095712    0.13034698]\n",
            " [ 4.0420136  -1.563818   -2.612951  ]\n",
            " [ 3.5306191  -1.8081013  -1.841594  ]\n",
            " [ 4.131567   -1.6350551  -2.592565  ]\n",
            " [ 3.8661094  -1.9233849  -1.9270431 ]\n",
            " [ 0.10163665  1.3567511  -1.7125273 ]\n",
            " [-2.2558355   2.7024682  -1.1246585 ]]\n",
            "[0 0 0 1 2 0 2 0 2 2 0 2 0 0 1 1]\n",
            "[[-2.141299    2.872773   -0.9589193 ]\n",
            " [ 4.2039833  -1.7261353  -2.386429  ]\n",
            " [ 3.3445728  -2.0261729  -1.2436285 ]\n",
            " [ 4.1342278  -1.8038545  -2.2947693 ]\n",
            " [-1.6829865  -1.7928329   3.358602  ]\n",
            " [-2.189812    0.21923673  1.4453855 ]\n",
            " [ 0.84337395 -0.8619891  -0.62460935]\n",
            " [ 4.0141115  -1.52931    -2.5455444 ]\n",
            " [-1.3064091   2.7139041  -1.8278852 ]\n",
            " [-1.338178   -1.8250408   3.0209818 ]\n",
            " [ 2.5211928  -1.1213019  -1.913916  ]\n",
            " [ 4.18827    -1.874134   -2.1183832 ]\n",
            " [ 3.6298063  -2.1451008  -1.2837915 ]\n",
            " [-1.8794407  -1.7349935   3.489127  ]\n",
            " [-2.014726   -1.2255552   3.1559834 ]\n",
            " [ 4.1929502  -1.7224388  -2.4328682 ]]\n",
            "[1 0 2 0 2 2 2 0 2 2 2 0 2 2 2 0]\n",
            "[[ 4.112661   -1.840669   -2.360191  ]\n",
            " [-1.9972497   1.3085927  -0.3828138 ]\n",
            " [ 0.38510588  1.2411637  -2.0972784 ]\n",
            " [-2.1850677   1.7702024  -0.38836983]\n",
            " [ 4.2004085  -1.7409215  -2.4159424 ]\n",
            " [ 1.1266513   0.7420516  -2.3414242 ]\n",
            " [ 1.6422812   0.37952524 -2.4840558 ]\n",
            " [ 4.1442347  -1.7932867  -2.3004453 ]\n",
            " [ 4.1405954  -1.640655   -2.493698  ]\n",
            " [ 3.983145   -1.9694183  -1.7800975 ]\n",
            " [ 1.7003006  -0.5098735  -1.7660716 ]\n",
            " [ 1.9796816  -2.196629    0.65145016]\n",
            " [-1.1197171   0.7244338  -0.23373473]\n",
            " [ 4.1049967  -1.8664999  -2.1721864 ]\n",
            " [-2.1441972   0.8072164   1.3206594 ]\n",
            " [-1.838334   -1.4573507   3.039265  ]]\n",
            "[0 2 0 0 0 0 0 2 0 0 0 2 0 0 1 2]\n",
            "[[ 2.9741685  -0.80578035 -2.5641453 ]\n",
            " [-1.5888852  -1.7706407   3.3990486 ]\n",
            " [ 1.1745644  -1.9436297   0.51367307]\n",
            " [-1.4351379   2.6335728  -1.0168309 ]]\n",
            "[0 0 2 1]\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgOqZzP9VBub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "input_ids=[]\n",
        "lengths=[]\n",
        "for tweet in target1_test_data:\n",
        "  encoded_sent=tokenizer.encode(tweet,add_special_tokens=True)\n",
        "  input_ids.append(encoded_sent)\n",
        "  lengths.append(len(encoded_sent))\n",
        "\n",
        "\n",
        "data_test_answers=pd.read_csv('drive/My Drive/dataset_test_answers.csv')\n",
        "data_test_target1_answers=data_test_answers[data_test_answers[\"Target\"]==\"Atheism\"]\n",
        "y_ground_truth=data_test_target1_answers[\"Stance\"].values;\n",
        "\n",
        "\n",
        "y_test=[]\n",
        "for i in range(len(y_ground_truth)):\n",
        "  if(y_ground_truth[i]=='AGAINST'):\n",
        "    y_test.append(0)\n",
        "  elif(y_ground_truth[i]=='FAVOR'):\n",
        "    y_test.append(1)\n",
        "  else:\n",
        "    y_test.append(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXV_VXD0VvZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN=40\n",
        "input_ids=pad_sequences(input_ids,maxlen=MAX_LEN,dtype='long',value=0, truncating='post',padding='post')\n",
        "\n",
        "\n",
        "# create attention masks\n",
        "#if token id is 0, then its padded, set the mask to 0\n",
        "attention_masks=[]\n",
        "for tweet in input_ids:\n",
        "  att_mask=[int(token_id >0) for token_id in tweet]\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5X2QzVfV6U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "import torch\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVVWDYyVWTIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q3OJZnBWJK0",
        "colab_type": "code",
        "outputId": "46b55e9c-190e-4111-9688-1489630961ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 220 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVI9qeaXWfKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=[]\n",
        "for i in predictions:\n",
        "  for k in i:\n",
        "    y_pred.append(np.argmax(k))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT6132MvXofR",
        "colab_type": "code",
        "outputId": "a6acb21f-1e08-46bf-ed3e-d4b2025f3870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "print(f1_score(y_pred,y_test,average='macro'))\n",
        "print(precision_score(y_pred,y_test,average='macro'))\n",
        "print(recall_score(y_pred,y_test,average='macro'))\n",
        "print(accuracy_score(y_pred,y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6037704371037705\n",
            "0.6145833333333334\n",
            "0.59949553370606\n",
            "0.7318181818181818\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}